<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapitre 1 L’approche bayésienne | Statistique bayésienne avec R</title>
<meta name="author" content="Olivier Gimenez">
<meta name="description" content="1.1 Introduction Dans ce chapitre, on pose les bases en faisant quelques rappels de probabilité utiles pour la suite. J’introduis les notions clés de la statistique bayésienne à travers un exemple...">
<meta name="generator" content="bookdown 0.43 with bs4_book()">
<meta property="og:title" content="Chapitre 1 L’approche bayésienne | Statistique bayésienne avec R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://oliviergimenez.github.io/statistique-bayes/principes.html">
<meta property="og:description" content="1.1 Introduction Dans ce chapitre, on pose les bases en faisant quelques rappels de probabilité utiles pour la suite. J’introduis les notions clés de la statistique bayésienne à travers un exemple...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapitre 1 L’approche bayésienne | Statistique bayésienne avec R">
<meta name="twitter:description" content="1.1 Introduction Dans ce chapitre, on pose les bases en faisant quelques rappels de probabilité utiles pour la suite. J’introduis les notions clés de la statistique bayésienne à travers un exemple...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Roboto-0.4.10/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><!-- Langue française --><script src="assets/lang-fr.js"></script><!-- Google tag (gtag.js) --><script async src="https://www.googletagmanager.com/gtag/js?id=G-MTKSQWQE5K"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-MTKSQWQE5K');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Statistique bayésienne avec R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li><a class="active" href="principes.html"><span class="header-section-number">1</span> L’approche bayésienne</a></li>
<li><a class="" href="mcmc.html"><span class="header-section-number">2</span> Les méthodes MCMC</a></li>
<li><a class="" href="logiciels.html"><span class="header-section-number">3</span> Mise en oeuvre pratique</a></li>
<li><a class="" href="prior.html"><span class="header-section-number">4</span> Les distributions a priori</a></li>
<li><a class="" href="lms.html"><span class="header-section-number">5</span> La régression</a></li>
<li><a class="" href="glms.html"><span class="header-section-number">6</span> Modèles linéaires généralisés, et généralisés mixtes</a></li>
<li><a class="" href="conclusions.html">Conclusions</a></li>
<li><a class="" href="r%C3%A9f%C3%A9rences.html">Références</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/oliviergimenez/statistique-bayes-quae">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="principes" class="section level1" number="1">
<h1>
<span class="header-section-number">Chapitre 1</span> L’approche bayésienne<a class="anchor" aria-label="anchor" href="#principes"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-1" class="section level2" number="1.1">
<h2>
<span class="header-section-number">1.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-1"><i class="fas fa-link"></i></a>
</h2>
<p>Dans ce chapitre, on pose les bases en faisant quelques rappels de probabilité utiles pour la suite. J’introduis les notions clés de la statistique bayésienne à travers un exemple simple qui permet de fixer les idées, et qu’on utilisera souvent dans le livre. On fera aussi des parallèles entre la statistique classique ou fréquentiste et la statistique bayésienne.</p>
</div>
<div id="le-théorème-de-bayes" class="section level2" number="1.2">
<h2>
<span class="header-section-number">1.2</span> Le théorème de Bayes<a class="anchor" aria-label="anchor" href="#le-th%C3%A9or%C3%A8me-de-bayes"><i class="fas fa-link"></i></a>
</h2>
<p>Ne tardons plus et entrons dans le vif du sujet. La statistique bayésienne repose sur le théorème de Bayes (ou formule, ou loi, selon ce que vous préférez), nommé d’après le révérend Thomas Bayes. Ce théorème a été publié en 1763, deux ans après la mort de Bayes grâce aux efforts de son ami Richard Price, et a été découvert indépendamment par Pierre-Simon Laplace.</p>
<p>Comme nous allons le voir dans un instant, le théorème de Bayes porte sur les probabilités conditionnelles, qui sont parfois un peu délicates à comprendre. La probabilité conditionnelle d’un événement A sachant un événement B, que l’on note <span class="math inline">\(\Pr(A \mid B)\)</span>, est la probabilité que A se produise, révisée en tenant compte de l’information supplémentaire que l’événement B s’est produit. Par exemple, imaginez qu’un de vos amis lance un dé (équilibré) et vous demande la probabilité que le résultat soit un six (A). Votre réponse est 1/6 car chaque face du dé a la même chance d’apparaître. Maintenant, imaginez que l’on vous dise que le nombre obtenu est pair (B) avant de répondre. Comme il n’y a que trois nombres pairs, dont un seul est six, vous pouvez réviser votre réponse : <span class="math inline">\(\Pr(A \mid B) = 1/3\)</span>.</p>
<!-- L'ordre des événements A et B est important, veillez à ne pas confondre $\Pr(A \mid B)$ et $\Pr(B \mid A)$. -->
<p>Vous voyez comment l’information supplémentaire (ici, savoir que le nombre est pair) change l’estimation ? C’est exactement ce type de raisonnement que le théorème de Bayes formalise et généralise : il permet de calculer la probabilité d’un événement A sachant qu’un autre événement B s’est produit. Plus précisément, le théorème de Bayes vous donne <span class="math inline">\(\Pr(A \mid B)\)</span> en utilisant les probabilités marginales <span class="math inline">\(\Pr(A)\)</span> et <span class="math inline">\(\Pr(B)\)</span> et la probabilité <span class="math inline">\(\Pr(B \mid A)\)</span> :</p>
<p><span class="math display">\[\Pr(A \mid B) = \displaystyle{\frac{ \Pr(B \mid A) \; \Pr(A)}{\Pr(B)}}.\]</span></p>
<p>On parle de probabilité marginale quand on s’intéresse à la probabilité d’un événement « tout seul », sans condition particulière. Par exemple, <span class="math inline">\(\Pr(A)\)</span> ou <span class="math inline">\(\Pr(B)\)</span>, ce sont les chances globales de A ou de B, sans tenir compte d’autre chose. On dit « marginale » parce que, si vous faisiez un tableau avec toutes les combinaisons possibles (par exemple les résultats d’un dé classés en pair/impair et en “six/pas six”), alors <span class="math inline">\(\Pr(A)\)</span> et <span class="math inline">\(\Pr(B)\)</span> s’obtiennent en additionnant les cases d’une ligne ou d’une colonne, autrement dit ce qu’on lit en marge du tableau.</p>
<p>Le théorème de Bayes est souvent considéré comme un moyen de remonter d’un effet B à une cause A inconnue, en connaissant la probabilité de l’effet B sachant la cause A. Pensez, par exemple, à une situation où un diagnostic médical est requis, avec A une maladie inconnue et B des symptômes ; la médecin connaît les chances d’avoir certains symptômes en fonction de plusieurs maladies ou <span class="math inline">\(\Pr(\text{symptômes}|\text{maladie})\)</span>, et souhaite déduire la probabilité d’avoir une maladie connaissant les symptômes ou <span class="math inline">\(\Pr(\text{maladie}|\text{symptômes})\)</span>. Cette manière de renverser <span class="math inline">\(\Pr(B \mid A)\)</span> en <span class="math inline">\(\Pr(A \mid B)\)</span> explique pourquoi le raisonnement bayésien est parfois appelé “probabilité inverse”.</p>
<p>Plutôt que d’utiliser des lettres au risque de s’embrouiller, je trouve plus facile de retenir le théorème de Bayes écrit ainsi :</p>
<p><span class="math display">\[\Pr(\text{hypothèse} \mid \text{données}) = \frac{ \Pr(\text{données} \mid \text{hypothèse}) \; \Pr(\text{hypothèse})}{\Pr(\text{données})}.\]</span></p>
<p>L’hypothèse peut être un paramètre comme la probabilité d’apparition d’une maladie, ou des coefficients de régression liant cette probabilité à des facteurs de risque (e.g., lieu de vie, tabagisme). Le théorème de Bayes nous dit comment obtenir la probabilité d’une hypothèse à partir des données disponibles. Le théorème de Bayes nous dit comment obtenir la probabilité d’une hypothèse à partir des données disponibles.</p>
<p>C’est pertinent car, réfléchissez-y, c’est exactement ce que fait la méthode scientifique. Nous voulons savoir à quel point une hypothèse est plausible à partir de données que nous avons collectées, et peut-être comparer plusieurs hypothèses entre elles. De ce point de vue, le raisonnement bayésien s’accorde avec le raisonnement scientifique, ce qui explique probablement pourquoi le cadre bayésien est si naturel pour faire et comprendre la statistique.</p>
<p>Vous pourriez alors demander pourquoi la statistique bayésienne n’est-elle pas la norme ? Pendant longtemps, la mise en œuvre du théorème de Bayes a été limitée par des difficultés de calcul, comme nous le verrons au chapitre suivant. Fort heureusement, l’amélioration de la puissance de calcul de nos ordinateurs et le développement de nouveaux algorithmes ont entraîné un essor marqué de l’approche bayésienne au cours des trente dernières années.</p>
</div>
<div id="statbayes" class="section level2" number="1.3">
<h2>
<span class="header-section-number">1.3</span> Qu’est-ce que la statistique bayésienne ?<a class="anchor" aria-label="anchor" href="#statbayes"><i class="fas fa-link"></i></a>
</h2>
<p>Les problèmes statistiques typiques consistent à estimer un paramètre (ou plusieurs) à partir de données disponibles. On va noter ce ou ces paramètres de manière générique, disons <span class="math inline">\(\theta\)</span>. Pour estimer <span class="math inline">\(\theta\)</span>, vous êtes sûrement plus familier de l’approche fréquentiste que de l’approche bayésienne. L’approche fréquentiste, en particulier l’estimation par maximum de vraisemblance, suppose que les paramètres sont fixes, et de valeurs inconnues. Les estimateurs classiques sont donc en général des valeurs ponctuelles ; par exemple, un estimateur de la probabilité d’obtenir une face d’un dé est le nombre de fois qu’on a obtenu cette face, divisé par le nombre de fois qu’on a lancé ce dé. L’approche bayésienne suppose que les paramètres ne sont pas fixes et suivent une distribution inconnue. Une distribution de probabilité est une expression mathématique qui donne la probabilité qu’une variable aléatoire prenne certaines valeurs. Elle peut être discrète (par exemple Bernoulli, Binomiale ou Poisson) ou continue (par exemple la loi normale ou gaussienne).</p>
<p>L’approche bayésienne repose sur l’idée que vous commencez avec certaines connaissances sur le système avant même de l’étudier vous-même. Ensuite, vous collectez des données et mettez à jour ces connaissances a priori en fonction des observations. Ces observations peuvent venir du terrain, du laboratoire ou de l’expertise de collègues. Ce processus de mise à jour repose sur le théorème de Bayes. De façon simplifiée, si l’on prend <span class="math inline">\(A = \theta\)</span> et <span class="math inline">\(B = \text{données}\)</span>, alors le théorème de Bayes permet d’estimer le paramètre <span class="math inline">\(\theta\)</span> à partir des données comme suit :</p>
<p><span class="math display">\[\Pr(\theta \mid \text{données}) = \frac{\Pr(\text{données} \mid \theta) \times \Pr(\theta)}{\Pr(\text{données})}.\]</span></p>
<p>Prenons un peu de temps pour passer en revue chaque terme de cette formule.</p>
<p>À gauche, nous avons <span class="math inline">\(\Pr(\theta \mid \text{données})\)</span> la distribution a posteriori. La probabilité de <span class="math inline">\(\theta\)</span> sachant les données. Elle représente ce que vous savez de <span class="math inline">\(\theta\)</span> après avoir vu les données. C’est la base de l’inférence et c’est précisément ce que vous cherchez : une distribution, possiblement multivariée si vous avez plusieurs paramètres.</p>
<p>À droite, on trouve <span class="math inline">\({\Pr(\text{données} \mid \theta)}\)</span> la vraisemblance (ou likelihood en anglais). La probabilité des données sachant <span class="math inline">\(\theta\)</span>. Cette quantité est la même que dans l’approche classique ou fréquentiste. Car oui, les approches bayésienne et fréquentiste partagent la même composante, la vraisemblance, ce qui explique pourquoi leurs résultats sont souvent proches. La vraisemblance exprime l’information que contiennent vos données, étant donné un modèle paramétré par <span class="math inline">\(\theta\)</span>. On en reparle à la Section <a href="principes.html#maxvrais">1.5</a>.</p>
<p>Ensuite, nous avons <span class="math inline">\(\Pr(\theta)\)</span> la distribution a priori. Cette quantité représente ce que vous savez sur <span class="math inline">\(\theta\)</span> avant de voir les données. Cette distribution a priori ne doit pas dépendre des données, autrement dit on ne devrait pas utiliser les données pour la construire. Elle peut être vague ou non-informative si vous ne savez rien sur <span class="math inline">\(\theta\)</span>. Souvent, vous ne partez jamais de zéro, et dans l’idéal vous souhaiteriez que votre a priori reflète les connaissances existantes. Je vous parlerai plus en détails des priors au Chapitre <a href="prior.html#prior">4</a>.</p>
<p>Enfin, il y a le dénominateur <span class="math inline">\(\Pr(\text{données})\)</span>, parfois appelée vraisemblance moyenne (average likelihood), moyenne par rapport au prior, car il s’obtient en intégrant la vraisemblance selon la loi a priori <span class="math inline">\({\Pr(\text{données}) = \int{\Pr(\text{données} \mid \theta) \times \Pr(\theta) \, d\theta}}\)</span>. Cette quantité permet de normaliser la distribution a posteriori pour qu’elle intègre à 1. Autrement dit, comme <span class="math inline">\(\int{\Pr(\theta \mid \text{données}) \, d\theta} = 1\)</span> puisque l’intégrale d’une densité de probabilité vaut 1, on a que <span class="math inline">\(\displaystyle \int{\frac{\Pr(\text{données} \mid \theta) \times \Pr(\theta)}{\Pr(\text{données})} \, d\theta} = 1\)</span>. Et puisque <span class="math inline">\(\Pr(\text{données})\)</span> ne dépend pas de <span class="math inline">\(\theta\)</span>, on a que <span class="math inline">\(\Pr(\text{données}) = \int{\Pr(\text{données} \mid \theta) \times \Pr(\theta) \, d\theta}\)</span>. C’est une intégrale de dimension égale au nombre de paramètres <span class="math inline">\(\theta\)</span> à estimer : pour 2 paramètres, une intégrale double, pour 3 paramètres une intégrale triple, etc. Or, au-delà de 3 dimensions, il devient difficile, voire impossible, de calculer cette intégrale. C’est l’une des raisons pour lesquelles l’approche bayésienne n’a pas été utilisée plus tôt, et pourquoi on a besoin d’algorithmes pour estimer les distributions a posteriori, comme je l’explique dans le Chapitre <a href="mcmc.html#mcmc">2</a>. En attendant, on va dérouler un exemple relativement simple dans lequel la distribution a posteriori a une forme explicite.</p>
</div>
<div id="un-exemple-fil-rouge" class="section level2" number="1.4">
<h2>
<span class="header-section-number">1.4</span> Un exemple fil rouge<a class="anchor" aria-label="anchor" href="#un-exemple-fil-rouge"><i class="fas fa-link"></i></a>
</h2>
<p>Prenons un exemple concret pour fixer les idées. Je travaille sur le ragondin (<em>Myocastor coypus</em>) (Figure <a href="principes.html#fig:ragondinos">1.1</a>), un rongeur semi-aquatique originaire d’Amérique du Sud, introduit en Europe pour l’élevage de fourrure. Il est aujourd’hui considéré comme une espèce invasive, en raison des dégâts qu’il occasionne dans les milieux humides (érosion des berges, destruction de la végétation) et de son rôle possible dans la transmission à l’humain de la leptospirose, une infection bactérienne potentiellement sévère, transmise par l’eau. Grâce à sa forte fécondité et à sa bonne adaptation aux climats tempérés, le ragondin a proliféré rapidement.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ragondinos"></span>
<img src="images/ragondin2.jpg" alt="Cliché de ragondins (Myocastor coypus) pris sur le bassin versant du Lez dans les environs de Montpellier. Crédits : Yann Raulet." width="90%"><p class="caption">
Figure 1.1: Cliché de ragondins (Myocastor coypus) pris sur le bassin versant du Lez dans les environs de Montpellier. Crédits : Yann Raulet.
</p>
</div>
<p>Une des questions qui m’intéressent est d’estimer la probabilité de survivre à l’hiver, les ragondins étant particulièrement sensibles au froid. Pour cela, on équipe plusieurs individus d’une balise GPS au début de l’hiver, disons ici <span class="math inline">\(n = 57\)</span>. A la fin de l’hiver, on observe que <span class="math inline">\(y = 19\)</span> ragondins sont encore vivants. L’objectif est d’estimer la probabilité de survie hivernale, que l’on notera <span class="math inline">\(\theta\)</span>. Voici les données :</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fl">19</span> <span class="co"># nombre d'individus ayant survécu à l'hiver</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">57</span> <span class="co"># nombre d'individus suivis au début de l'hiver</span></span></code></pre></div>
<p>Vous vous dites sûrement qu’avec ces éléments, on peut déjà estimer une probabilité de survie. Intuitivement, on pense à la proportion d’individus ayant survécu, soit <span class="math inline">\(19/57\)</span>. Et vous n’avez pas tort. C’est une estimation raisonnable de <span class="math inline">\(\theta\)</span>, la probabilité de survie hivernale. Essayons maintenant de formaliser cette intuition, afin de mieux comprendre ce qu’elle représente, et ce qu’elle suppose.</p>
<p>Comme mentionné plus haut, la vraisemblance est une idée centrale qu’on retrouve dans les approches fréquentiste et bayésienne. Commençons donc par construire cette vraisemblance. Pour cela, il nous faut poser quelques hypothèses.</p>
<p>Premièrement, nous supposons que les individus sont indépendants, c’est-à-dire que la survie d’un ragondin n’influence pas la survie des autres ragondins. C’est une hypothèse forte, surtout quand on sait qu’une femelle peut se reproduire 2 à 3 fois par an et donner naissance à jusqu’à 10 petits dépendants d’elle au début de leur vie. Mais en modélisation, il vaut souvent mieux commencer simplement.</p>
<p>Deuxièmement, nous supposons que tous les individus ont la même probabilité de survie. Là encore, c’est une simplification : on sait, par exemple, que la mortalité des jeunes est plus élevée que celle des adultes.</p>
<p>Sous ces deux hypothèses, le nombre <span class="math inline">\(y\)</span> d’animaux encore vivants à la fin de l’hiver suit une loi binomiale, avec <span class="math inline">\(\theta\)</span> comme probabilité de succès (survie), et <span class="math inline">\(n\)</span> comme nombre d’essais (individus suivis). On notera <span class="math inline">\(y \sim \text{Bin}(n, \theta)\)</span>. La loi binomiale est en fait la somme de plusieurs épreuves de Bernoulli indépendantes, comme dans l’exemple classique du pile ou face. À chaque lancé, ici le relâché d’un ragondin équipé d’un GPS en début d’hiver, on suppose une probabilité <span class="math inline">\(\theta\)</span> de succès, c’est-à-dire de survivre à l’hiver, et d’échec, c’est-à-dire de mourir de froid. Si toutes ces épreuves sont indépendantes et ont la même probabilité de succès (nos hypothèses), alors le nombre de succès ou de ragondins vivants en sortie d’hiver suit une loi binomiale (voir aussi le Chapitre <a href="glms.html#glms">6</a>). Je donne des exemples de tirages Bernoulli et binomiaux dans la Figure <a href="principes.html#fig:bernoulli-binomiale">1.2</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:bernoulli-binomiale"></span>
<img src="01-principes_files/figure-html/bernoulli-binomiale-1.png" alt=" Distributions de probabilité discrètes, Bernoulli et binomiale, illustrées avec 100 simulations (des tirages aléatoires générés par ordinateur). On représente sur la ligne du haut la fréquence observée d'un tirage Bernoulli pour différentes valeurs de probabilité de survie \(\theta\). Sur la ligne du bas, on a les histogrammes pour un tirage binomial avec 50 tentatives et différentes valeurs de probabilité de survie \(\theta\)." width="90%"><p class="caption">
Figure 1.2:  Distributions de probabilité discrètes, Bernoulli et binomiale, illustrées avec 100 simulations (des tirages aléatoires générés par ordinateur). On représente sur la ligne du haut la fréquence observée d’un tirage Bernoulli pour différentes valeurs de probabilité de survie <span class="math inline">\(\theta\)</span>. Sur la ligne du bas, on a les histogrammes pour un tirage binomial avec 50 tentatives et différentes valeurs de probabilité de survie <span class="math inline">\(\theta\)</span>.
</p>
</div>
<p>Au passage, il est facile de s’embrouiller entre tous les termes utilisés pour décrire une Bernoulli et une binomiale (et la normale) : vous pouvez retenir qu’une probabilité est un nombre, une distribution est une loi, une densité est la fonction qui la représente.</p>
</div>
<div id="maxvrais" class="section level2" number="1.5">
<h2>
<span class="header-section-number">1.5</span> Le maximum de vraisemblance<a class="anchor" aria-label="anchor" href="#maxvrais"><i class="fas fa-link"></i></a>
</h2>
<p>Dans l’approche classique (ou fréquentiste), on estime la probabilité de survie <span class="math inline">\(\theta\)</span> en utilisant la méthode du maximum de vraisemblance. Mais qu’est-ce que cela signifie concrètement ? Il s’agit de trouver la valeur de <span class="math inline">\(\theta\)</span> qui rend les données observées les plus probables. Autrement dit, puisque les données sont ce qu’elles sont — elles ont été observées — on cherche la valeur de <span class="math inline">\(\theta\)</span> qui maximise la probabilité que cet ensemble de données ait été produit.</p>
<p>Comment justifie-t-on mathématiquement cette idée plutôt intuitive ? Relisez bien la fin du paragraphe précédent. L’idée de chercher la valeur qui donne la plus grande probabilité revient à maximiser quelque chose. Mais quoi exactement ? La probabilité des données, étant donné un certain modèle paramétré par <span class="math inline">\(\theta\)</span>, autrement dit la vraisemblance ou <span class="math inline">\(\Pr(\text{données}|\theta)\)</span> qu’on a vue à la Section <a href="principes.html#statbayes">1.3</a>. L’estimation classique repose donc sur la maximisation de la vraisemblance, ou plutôt la fonction de vraisemblance, c’est-à-dire la vraisemblance considérée comme une fonction de <span class="math inline">\(\theta\)</span>.</p>
<p>Dans notre cas, on est face à une expérience binomiale : on suit <span class="math inline">\(n\)</span> ragondins à travers l’hiver, chacun ayant une probabilité <span class="math inline">\(\theta\)</span> de survivre. On connaît la probabilité de chaque issue possible (ou fonction de masse). Par exemple, la probabilité qu’aucun ragondin ne survive est <span class="math inline">\((1-\theta)^n\)</span>, car chacun des <span class="math inline">\(n\)</span> individus meurt avec une probabilité <span class="math inline">\(1-\theta\)</span>. Si on prend par exemple une probabilité de survie de 0.5, on a <span class="math inline">\((1-0.5)^{57} \approx 0\)</span>. On peut calculer cette probabilité dans <code>R</code> avec la fonction <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> :</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0</span>, size <span class="op">=</span> <span class="fl">57</span>, prob <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 6.938894e-18</span></span></code></pre></div>
<p>où le premier argument <code>x = 0</code> est pour aucun ragondin vivant. À l’inverse, la probabilité que tous survivent est <span class="math inline">\(\theta^n\)</span> qui vaut la même chose. Vous pouvez vérifier avec <code>R</code> et la ligne de commande <code>dbinom(x = 57, size = 57, prob = 0.5)</code>. Si un seul ragondin survit, il faut que l’un des <span class="math inline">\(n\)</span> survive avec probabilité <span class="math inline">\(\theta\)</span>, et que les <span class="math inline">\(n-1\)</span> autres meurent, avec probabilité <span class="math inline">\((1-\theta)^{n-1}\)</span>. Comme n’importe lequel des <span class="math inline">\(n\)</span> ragondins peut être celui qui survit, on obtient une probabilité totale de <span class="math inline">\(n \theta (1-\theta)^{n-1}\)</span>. On peut calculer cette probabilité avec <code>dbinom(x = 1, size = 57, prob = 0.5)</code>. Plus généralement, la probabilité que <span class="math inline">\(y\)</span> individus survivent est donnée par <span class="math inline">\(\displaystyle \binom{n}{y}\theta^y(1-\theta)^{n-y}\)</span>. Si l’on considère cette expression comme une fonction de <span class="math inline">\(\theta\)</span> (et non de <span class="math inline">\(y\)</span>), on obtient la fonction de vraisemblance <span class="math inline">\(\displaystyle \mathcal{L}(\theta) = \binom{n}{y} \theta^y (1 - \theta)^{n - y}\)</span>. Le terme <span class="math inline">\(\displaystyle \binom{n}{y}\)</span> est appelé coefficient binomial. Il correspond au nombre de façons différentes de choisir <span class="math inline">\(y\)</span> survivants parmi les <span class="math inline">\(n\)</span> ragondins, sans tenir compte de leur ordre.</p>
<p>On peut représenter cette vraisemblance dans <code>R</code> comme dans la Figure <a href="principes.html#fig:survie-vraisemblance-mle">1.3</a> :</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:survie-vraisemblance-mle"></span>
<img src="01-principes_files/figure-html/survie-vraisemblance-mle-1.png" alt="Fonction de vraisemblance pour la probabilité de survie hivernale du ragondin, calculée à partir de $y=19$ survivants sur $n=57$ individus suivis par GPS. Le maximum de vraisemblance est indiqué par une ligne pointillée rouge." width="90%"><p class="caption">
Figure 1.3: Fonction de vraisemblance pour la probabilité de survie hivernale du ragondin, calculée à partir de <span class="math inline">\(y=19\)</span> survivants sur <span class="math inline">\(n=57\)</span> individus suivis par GPS. Le maximum de vraisemblance est indiqué par une ligne pointillée rouge.
</p>
</div>
<p>Notre objectif est de trouver la valeur de <span class="math inline">\(\theta\)</span> qui maximise cette fonction. Autrement dit, on cherche la valeur de survie (sur l’axe des abscisses dans la Figure <a href="principes.html#fig:survie-vraisemblance-mle">1.3</a>) qui maximise la vraisemblance (sur l’axe des ordonnées). Cette valeur correspond à l’estimateur du maximum de vraisemblance, souvent noté <span class="math inline">\(\hat{\theta}\)</span>. Pour ce faire, il est souvent plus pratique de travailler avec le logarithme de la vraisemblance (la log-vraisemblance) car les sommes sont plus stables numériquement et plus faciles à dériver que les produits :</p>
<p><span class="math display">\[
\ell(\theta) = \log \mathcal{L}(\theta) = \log \binom{n}{y} + y \log \theta + (n - y) \log (1 - \theta).
\]</span>
Le premier terme, <span class="math inline">\(\displaystyle \log \binom{n}{y}\)</span>, ne dépend pas de <span class="math inline">\(\theta\)</span>, on peut donc l’ignorer pour la suite. On dérive alors la log-vraisemblance par rapport à <span class="math inline">\(\theta\)</span> :</p>
<p><span class="math display">\[
\displaystyle \frac{d\ell(\theta)}{d\theta} = \frac{y}{\theta} - \frac{n - y}{1 - \theta}.
\]</span></p>
<p>On cherche la valeur de <span class="math inline">\(\theta\)</span> qui annule cette dérivée :</p>
<p><span class="math display">\[
\frac{y}{\theta} - \frac{n - y}{1 - \theta} = 0.
\]</span></p>
<p>Après quelques simplifications, on obtient que l’estimateur du maximum de vraisemblance <span class="math inline">\(\hat{\theta}\)</span> est :</p>
<p><span class="math display">\[
\hat{\theta} = \frac{y}{n}.
\]</span></p>
<p>Ce résultat rejoint notre intuition de départ : l’estimateur du maximum de vraisemblance est la proportion d’individus qui ont survécu, soit <span class="math inline">\(19/57 \approx 0.333\)</span>. On peut visualiser ce résultat sur la Figure <a href="principes.html#fig:survie-vraisemblance-mle">1.3</a>, où le maximum de vraisemblance est indiqué par une ligne pointillée rouge.</p>
<p>En pratique, les modèles contiennent plusieurs paramètres, des dizaines voire des centaines, et on ne peut pas appliquer la même méthode pour maximiser la vraisemblance et trouver les estimateurs du maximum de vraisemblance. On utilise plutôt des algorithmes itératifs d’optimisation qui vont résoudre le problème pour nous, en ajustant pas à pas une valeur initiale jusqu’à trouver celle qui maximise la vraisemblance. Par exemple, dans <code>R</code>, on peut obtenir exactement ce même résultat en utilisant une régression logistique sans covariable (voir Chapitre <a href="glms.html#glms">6</a>) :</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">n</span> <span class="op">-</span> <span class="va">y</span><span class="op">)</span> <span class="op">~</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="va">theta_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html">plogis</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">theta_hat</span></span>
<span><span class="co">#&gt; (Intercept) </span></span>
<span><span class="co">#&gt;   0.3333333</span></span></code></pre></div>
<p>Le calcul direct <span class="math inline">\(\hat{\theta}=y/n\)</span> et le résultat de l’appel à la fonction <code>glm</code> sont cohérents, ils donnent la même valeur.</p>
</div>
<div id="et-en-bayésien" class="section level2" number="1.6">
<h2>
<span class="header-section-number">1.6</span> Et en bayésien?<a class="anchor" aria-label="anchor" href="#et-en-bay%C3%A9sien"><i class="fas fa-link"></i></a>
</h2>
<p>Dans l’approche bayésienne, on commence par exprimer nos connaissances a priori sur la quantité que l’on souhaite estimer. Ici, la probabilité de survie hivernale <span class="math inline">\(\theta\)</span>. On sait que <span class="math inline">\(\theta\)</span> est une variable continue comprise entre 0 et 1. Une distribution a priori naturelle dans ce cas est la distribution bêta. La distribution bêta est définie par deux paramètres <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> qui en contrôlent la forme :</p>
<p><span class="math display">\[
q(\theta \mid a, b) = \frac{1}{\text{Beta}(a, b)}{\theta^{a - 1}} {(1-\theta)^{b - 1}}
\]</span></p>
<p>avec :</p>
<p><span class="math display">\[
\text{Beta}(a, b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}, \quad \Gamma(n) = (n-1)!
\]</span>
Vous pouvez oublier ces équations si vous n’êtes pas à l’aise avec. Essayons plutôt de visualiser cette distribution comme dans la Figure <a href="principes.html#fig:beta-exemples">1.4</a>:</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:beta-exemples"></span>
<img src="01-principes_files/figure-html/beta-exemples-1.png" alt="Exemples de lois bêta pour différentes valeurs des paramètres $a$ et $b$. Dans chaque panneau, les zones ombrées illustrent la probabilité d'observer une valeur dans un intervalle donné." width="90%"><p class="caption">
Figure 1.4: Exemples de lois bêta pour différentes valeurs des paramètres <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span>. Dans chaque panneau, les zones ombrées illustrent la probabilité d’observer une valeur dans un intervalle donné.
</p>
</div>
<p>Chaque panneau de la figure montre la forme d’une loi bêta pour un couple de paramètres <span class="math inline">\((a, b)\)</span> donné. On peut y observer plusieurs comportements caractéristiques.</p>
<ul>
<li>Beta(1,1) (en haut à gauche) correspond à une loi uniforme : toutes les valeurs de <span class="math inline">\(\theta\)</span> entre 0 et 1 sont considérées comme également probables. La densité est constante, ce qui signifie que la probabilité d’observer une valeur entre 0.1 et 0.2 est la même que celle d’en observer une entre 0.8 et 0.9. Cette probabilité est l’aire du rectangle délimité par le trait rouge et les lignes verticales calées à 0.1 et 0.2 ou 0.8 et 0.9 (les zones ombrées en rouge). On a une situation d’absence de connaissance a priori.</li>
<li>Beta(2,1) et Beta(1,2) représentent des connaissances asymétriques : la première est biaisée vers des valeurs proches de 1, la seconde vers des valeurs proches de 0. La probabilité d’observer une valeur entre 0.1 et 0.2 est plus petite que celle d’en observer une entre 0.8 et 0.9, et vice-versa.</li>
<li>Beta(2,2) est symétrique, mais donne plus de poids aux valeurs centrales qu’une loi uniforme. La probabilité d’observer une valeur entre 0.1 et 0.2 est plus petite que celle d’en observer une entre 0.5 et 0.6.</li>
<li>Beta(10,10) représente une connaissance très concentrée autour de 0.5 : c’est un prior très informatif. La probabilité d’observer une valeur entre 0.2 et 0.3 est beaucoup plus petite que celle d’en observer une entre 0.5 et 0.6.</li>
<li>Beta(0.8,0.8) illustre une distribution en forme de U ou de baignoire, qui favorise les valeurs extrêmes (proches de 0 ou de 1). Les probabilités d’observer une valeur entre 0 et 0.1 et entre 0.9 et 1 sont plus grandes que celle d’en observer une entre 0.45 et 0.55.</li>
</ul>
<p>Ces exemples permettent de visualiser comment les paramètres <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> influencent la forme du prior. Comment passe-t-on de ce prior à la distribution a posteriori ?</p>
<p>On suppose que <span class="math inline">\(\theta \sim \text{Beta}(a, b)\)</span> et on a observé <span class="math inline">\(y = 19\)</span> survivants parmi <span class="math inline">\(n = 57\)</span> individus. La vraisemblance est <span class="math inline">\(\displaystyle \binom{n}{y}\theta^y(1 - \theta)^{n - y}\)</span>. Pour l’instant, on va ignorer le dénominateur <span class="math inline">\(\Pr(y)\)</span> dans le théorème de Bayes, on verra dans le chapitre suivant pourquoi. On a donc que l’a posteriori est proportionnel au produit de la vraisemblance et de l’a priori : <span class="math inline">\(\Pr(\theta \mid y) \propto \Pr(y \mid \theta) \times \Pr(\theta)\)</span>. Dans notre cas, on multiplie terme à terme la vraisemblance et le prior, et en réarrangeant les termes en <span class="math inline">\(\theta\)</span> et <span class="math inline">\(1-\theta\)</span>, on a :</p>
<p><span class="math display">\[
\begin{aligned}
\Pr(\theta \mid y) &amp;\propto \underbrace{\theta^y (1 - \theta)^{n - y}}_{\text{vraisemblance binomiale}} \times \underbrace{\theta^{a - 1} (1 - \theta)^{b - 1}}_{\text{a priori bêta}} \\
&amp;\propto \underbrace{\theta^{a + y - 1} (1 - \theta)^{b + n - y - 1}}_{\text{forme d'une loi bêta}}
\end{aligned}
\]</span></p>
<p>Autrement dit, on retrouve donc une loi bêta, avec des paramètres mis à jour <span class="math inline">\(a + y\)</span> et <span class="math inline">\(b + n - y\)</span>. On dit que la loi binomiale et la loi bêta sont conjuguées : lorsque l’on utilise une loi bêta comme distribution a priori pour un paramètre de probabilité dans un modèle binomial, la loi a posteriori obtenue est également une loi bêta. Si on utilise une loi uniforme a priori (i.e. Beta(1,1)), on obtient que la distribution a posteriori de la survie hivernale est une <span class="math inline">\(\text{Beta}(1+19, 1+57-19) = \text{Beta}(20, 39)\)</span>. Au passage, la distribution a posteriori est connue, ce qui facilite grandement les calculs et leur interprétation. Par exemple, on sait que la moyenne de la <span class="math inline">\(\text{Beta}(a, b)\)</span> est <span class="math inline">\(\displaystyle \frac{a}{a+b}\)</span>, soit <span class="math inline">\(\frac{20}{59} \approx 0.339\)</span>. On peut comparer cette valeur à l’estimateur du maximum de vraisemblance <span class="math inline">\(19/57 \approx 0.333\)</span>. On peut également visualiser la distribution a posteriori comme dans la Figure <a href="principes.html#fig:posterior-survie">1.5</a>, puisqu’on connait l’équation de la densité d’une loi Bêta :</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:posterior-survie"></span>
<img src="01-principes_files/figure-html/posterior-survie-1.png" alt="Distribution a priori uniforme (rouge) et distribution a posteriori (noire) de la probabilité de survie hivernale du ragondin. La ligne bleue pointillée correspond à l'estimateur du maximum de vraisemblance." width="90%"><p class="caption">
Figure 1.5: Distribution a priori uniforme (rouge) et distribution a posteriori (noire) de la probabilité de survie hivernale du ragondin. La ligne bleue pointillée correspond à l’estimateur du maximum de vraisemblance.
</p>
</div>
<p>Plus généralement, lorsque l’on dispose de suffisamment de données, les estimateurs bayésien et fréquentiste ont tendance à être très proches. Intuitivement, les données finissent par « dominer » l’information a priori. Grossièrement, le mode de la distribution a posteriori (la valeur pour laquelle la densité est maximale) correspond exactement à l’estimateur du maximum de vraisemblance.</p>
<p>C’est une illustration du lien entre les deux approches, et du rôle central que joue la vraisemblance en statistique : elle constitue le point commun fondamental entre les approches bayésienne et fréquentiste.</p>
</div>
<div id="en-résumé" class="section level2" number="1.7">
<h2>
<span class="header-section-number">1.7</span> En résumé<a class="anchor" aria-label="anchor" href="#en-r%C3%A9sum%C3%A9"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Le théorème de Bayes est un outil de mise à jour des connaissances.</li>
<li>La statistique bayésienne repose sur la vraisemblance et une loi a priori pour les paramètres du modèle.</li>
<li>La statistique fréquentiste fournit un estimateur ponctuel quand la statistique bayésienne estime une distribution pour chaque paramètre.</li>
<li>Souvent, les approches classique et bayésienne donnent des estimations proches.</li>
<li>Dans certains cas, la loi a posteriori est explicite (ex : conjugaison bêta/binomiale).</li>
<li>Dans la plupart des cas, il nous faudra utiliser des simulations pour obtenir la distribution a posteriori, comme on va le voir dans le Chapitre <a href="mcmc.html#mcmc">2</a>.</li>
</ul>
<!-- - On peut fournir une comparaison des approches fréquentiste et bayésienne sur la base de quelques critères importants : --><!-- | Critère         | Statistique fréquentiste | Statistique bayésienne | --><!-- |----------------|------------------------|------------------------| --><!-- | Nature des paramètres | Fixes mais inconnus | Variables aléatoires avec une distribution | --><!-- | Estimation | Estimateur ponctuel (maximum de vraisemblance) | Distribution *a posteriori* | --><!-- | Intervalle de confiance | Intervalle de confiance basé sur des hypothèses asymptotiques | Intervalle de crédibilité basé sur la distribution *a posteriori* | --><!-- | Intégration des connaissances préalables | Non | Oui, via la distribution *a priori* | --><!-- | Interprétation de la probabilité | Fréquence sur un grand nombre d’essais | Degré de croyance basé sur l’information disponible | -->
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="index.html">Introduction</a></div>
<div class="next"><a href="mcmc.html"><span class="header-section-number">2</span> Les méthodes MCMC</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#principes"><span class="header-section-number">1</span> L’approche bayésienne</a></li>
<li><a class="nav-link" href="#introduction-1"><span class="header-section-number">1.1</span> Introduction</a></li>
<li><a class="nav-link" href="#le-th%C3%A9or%C3%A8me-de-bayes"><span class="header-section-number">1.2</span> Le théorème de Bayes</a></li>
<li><a class="nav-link" href="#statbayes"><span class="header-section-number">1.3</span> Qu’est-ce que la statistique bayésienne ?</a></li>
<li><a class="nav-link" href="#un-exemple-fil-rouge"><span class="header-section-number">1.4</span> Un exemple fil rouge</a></li>
<li><a class="nav-link" href="#maxvrais"><span class="header-section-number">1.5</span> Le maximum de vraisemblance</a></li>
<li><a class="nav-link" href="#et-en-bay%C3%A9sien"><span class="header-section-number">1.6</span> Et en bayésien?</a></li>
<li><a class="nav-link" href="#en-r%C3%A9sum%C3%A9"><span class="header-section-number">1.7</span> En résumé</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/oliviergimenez/statistique-bayes-quae/blob/master/01-principes.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/oliviergimenez/statistique-bayes-quae/edit/master/01-principes.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Statistique bayésienne avec R</strong>" a été écrit par Olivier Gimenez. Dernière mise à jour le 2025-09-07.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Ce livre a été généré avec le <a class="text-light" href="https://bookdown.org">package R bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
