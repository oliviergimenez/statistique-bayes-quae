[{"path":"index.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":"retrouve la statistique bayésienne un peu partout en sciences. Par exemple, en épidémiologie pour prédire la circulation des virus, en écologie pour expliquer l’extinction des espèces végétales et animales ou encore en informatique pour filtrer les courriels nuisibles. Si l’utilisation de la statistique bayésienne explosé au cours des dernières années, c’est grâce au progrès de nos ordinateurs. C’est aussi grâce à la nature même de l’approche qui permet de coller à notre façon d’apprendre, de raisonner et d’accumuler des connaissances.Dans ce livre, je vous propose une introduction à la statistique bayésienne. Ce livre est en français parce que c’est plus facile à écrire pour moi, et parce que j’aurais aimé avoir plus d’ouvrages dans ma langue maternelle lorsque j’étais étudiant.Je suis fixé comme objectifs de ) synthétiser les aspects méthodologiques à bien comprendre et ii) fournir les moyens pratiques pour utiliser vous-mêmes la statistique. Parce qu’comprend mieux en faisant, nous utiliserons un logiciel pour pratiquer la statistique bayésienne. Ce logiciel c’est R, un logiciel libre pour faire des statistiques et de la science des données. En français, je recommande l’excellent manuel de Julien Barnier, Introduction à R et au tidyverse disponible en ligne via https://juba.github.io/tidyverse et le site du projet collaboratif Analyse-R, disponible aussi en ligne à https://larmarange.github.io/analyse-R/. Pour la statistique bayésienne en particulier, je présente brms, un package qui propose une syntaxe simple et familière, proche de celle utilisée pour les régressions dans R. Dans la version enrichie du livre disponible en ligne à https://oliviergimenez.github.io/statistique-bayes/, je présente aussi NIMBLE, un package qui nécessite de programmer (écrire des boucles par exemple), mais offre en contrepartie une grande flexibilité.Plutôt que dans un style académique, j’ai choisi d’écrire un peu comme si nous étions ensemble dans la même pièce ou en visio-conférence, et que je devais vous expliquer de vive voix la statistique bayésienne. Ainsi, je ferai parfois (souvent en fait) des abus de langage et des approximations mathématiques. Vous ne m’en voudrez pas j’espère.","code":""},{"path":"index.html","id":"pourquoi-sintéresser-à-la-statistique-bayésienne","chapter":"Introduction","heading":"Pourquoi s’intéresser à la statistique bayésienne ?","text":"La statistique bayésienne est une approche pour analyser les données et prendre des décisions en présence d’incertitude, comme lorsqu’lance un dé ou qu’prévoit la météo : ne peut pas savoir exactement ce qui va se passer, mais peut estimer les chances des différents résultats. Pourquoi adopter cette approche ? Plusieurs raisons peuvent motiver son utilisation :une interprétation naturelle des probabilités : en statistique bayésienne, une probabilité représente un degré de confiance dans une hypothèse ou un paramètre, ce qui correspond bien à notre manière intuitive de raisonner face à l’incertitude ;une grande flexibilité : le cadre bayésien s’adapte bien à des données incomplètes, hétérogènes ou rares, ainsi qu’à des modèles complexes (hiérarchiques, non linéaires, dynamiques, etc.) ;la possibilité d’intégrer des connaissances préalables : peut capitaliser sur des résultats d’études précédentes ou des avis d’expert.e.s de manière transparente et formalisée ;une gestion rigoureuse de l’incertitude : la statistique bayésienne fournit non seulement une estimation des paramètres, mais aussi une mesure directe de l’incertitude associée.","code":""},{"path":"index.html","id":"ce-que-nous-allons-voir-dans-ce-livre","chapter":"Introduction","heading":"Ce que nous allons voir dans ce livre","text":"J’aimerais vous guider dans l’apprentissage de la statistique bayésienne. J’ai rassemblé le matériel qui m’paru essentiel pour la comprendre et l’appliquer. L’objectif est que vous soyez à l’aise avec l’approche bayésienne et que vous puissiez l’appliquer à vos propres données. Les objectifs sont de :démystifier la statistique bayésienne et les méthodes de Monte Carlo par chaînes de Markov (MCMC) ;comprendre les différences entre approche bayésienne et approche fréquentiste ;lire et comprendre les sections “méthodes” des articles scientifiques utilisant l’approche bayésienne ;savoir mettre en oeuvre vos analyses avec la statistique bayésienne dans R.Le Chapitre 1 pose les bases en revenant sur quelques rappels de probabilité utiles pour la suite. Ce sera aussi l’occasion d’introduire les notions clés de la statistique bayésienne, à travers un exemple simple qui permettra de fixer les idées.Dans le Chapitre 2, nous passerons dans les coulisses de la statistique bayésienne, avec les méthodes de Monte Carlo par chaînes de Markov (MCMC), qui rendent l’inférence possible en pratique. mettra un peu la main à la pâte en codant nous-mêmes une analyse bayésienne.Le Chapitre 3 présentera brms un outil très utile pour faire de la statistique bayésienne sans trop d’efforts. Dans la version enrichie du livre disponible en ligne à https://oliviergimenez.github.io/statistique-bayes/, je présenterai aussi NIMBLE. Grâce à ces outils, plus besoin de tout faire soi-même.Le Chapitre 4 sera consacré aux distributions priori. verra comment bien les choisir, comment traduire de l’information existante sous forme de prior, et les pièges à éviter.Dans le Chapitre 5, nous verrons comment faire une régression linéaire en statistique bayésienne. Nous en profiterons pour illustrer la comparaison et la validation des modèles. Nous utiliserons brms (et NIMBLE dans la version enrichie en ligne) et comparerons à l’approche fréquentiste.Le Chapitre 6 nous emmènera vers les modèles linéaires généralisés, avec ou sans effets aléatoires - des modèles très utilisés en pratique. s’appuiera sur la simulation de données, un outil précieux pour bien comprendre ce que fait un modèle. Je vous montrerai comment faire ces analyses avec brms (et avec NIMBLE dans la version enrichie en ligne) et comparera à l’analyse fréquentiste.Enfin, un dernier chapitre viendra résumer les messages clés du livre et proposer quelques conseils pour appliquer la statistique bayésienne de manière rigoureuse et éclairée.","code":""},{"path":"index.html","id":"comment-lire-ce-livre","chapter":"Introduction","heading":"Comment lire ce livre ?","text":"Je n’ai pas vraiment de conseil à vous donner sur la meilleure manière de lire ce livre. Personnellement, je trouve toujours difficile d’absorber toute l’information contenue dans un bouquin. Vous pouvez lire en continu ou bien grapiller des éléments de-ci de-là.Le code R est fourni, je l’ai hébergé sur https://github.com/oliviergimenez/statistique-bayes et le mettrai à jour. S’exercer permet de mieux comprendre, et de vérifier qu’bien compris. Si vous lisez la version électronique disponible à https://oliviergimenez.github.io/statistique-bayes, vous pouvez copier les lignes de code puis les coller dans R pour les exécuter. Pour gagner un peu de place, et éviter de perturber trop la lecture, certains codes ne sont pas donnés, en particulier ceux qui permettent de produire les figures, mais ils sont disponibles à https://github.com/oliviergimenez/statistique-bayes.Si vous voulez aller plus loin, je conseille les ouvrages suivants dont la liste n’est bien sûr pas exhaustive. Ces ouvrages ont été une source d’inspiration dans la rédaction de ce livre. J’ai hésité à donner plus de références, et à citer (beaucoup) d’articles scientifiques, mais je ne le ferai pas, les ouvrages ci-dessous sont largement suffisants.Initiation à la Statistique Bayésienne - Bases Théoriques et Applications en Alimentation, Environnement, Epidémiologie et Génétique (BIOBAYES 2015). Si vous cherchez une première approche en français, claire et illustrée par des exemples concrets, ce livre est une très bonne porte d’entrée. Tout est là https://biobayes.mathnum.inrae.fr/ouvrage.Initiation à la Statistique Bayésienne - Bases Théoriques et Applications en Alimentation, Environnement, Epidémiologie et Génétique (BIOBAYES 2015). Si vous cherchez une première approche en français, claire et illustrée par des exemples concrets, ce livre est une très bonne porte d’entrée. Tout est là https://biobayes.mathnum.inrae.fr/ouvrage.Bayesian Methods Ecology (McCarthy 2007). Un petit livre vraiment accessible pour comprendre comment appliquer la statistique bayésienne en écologie, sans se noyer dans les maths. Le site du livre est ici https://bit.ly/4jSlfQL.Bayesian Methods Ecology (McCarthy 2007). Un petit livre vraiment accessible pour comprendre comment appliquer la statistique bayésienne en écologie, sans se noyer dans les maths. Le site du livre est ici https://bit.ly/4jSlfQL.Applied Statistical Modelling Ecologists: Practical Guide Bayesian Likelihood Inference Using R, JAGS, NIMBLE, Stan TMB (Kéry Kellner 2010). Un manuel pratique pour apprendre à modéliser avec les principaux outils bayésiens dans R (JAGS, NIMBLE, Stan ou TMB), à partir d’exemples écologiques concrets et de comparaisons des résultats. Le site du livre avec les codes est ici https://www.elsevier.com/books--journals/book-companion/9780443137150.Applied Statistical Modelling Ecologists: Practical Guide Bayesian Likelihood Inference Using R, JAGS, NIMBLE, Stan TMB (Kéry Kellner 2010). Un manuel pratique pour apprendre à modéliser avec les principaux outils bayésiens dans R (JAGS, NIMBLE, Stan ou TMB), à partir d’exemples écologiques concrets et de comparaisons des résultats. Le site du livre avec les codes est ici https://www.elsevier.com/books--journals/book-companion/9780443137150.Bayes Rules!: Introduction Applied Bayesian Modeling (Johnson, Ott, Dogucu 2022). Un livre très pédagogique pour découvrir les principes et les applications de la statistique bayésienne de manière intuitive et progressive. Le livre est disponible en ligne là https://www.bayesrulesbook.com/.Bayes Rules!: Introduction Applied Bayesian Modeling (Johnson, Ott, Dogucu 2022). Un livre très pédagogique pour découvrir les principes et les applications de la statistique bayésienne de manière intuitive et progressive. Le livre est disponible en ligne là https://www.bayesrulesbook.com/.Bayesian Data Analysis: Tutorial R Bugs (Kruschke 2010). Un tutoriel approfondi et visuel qui accompagne pas à pas l’apprentissage de la statistique bayésienne avec de nombreux exemples pratiques. Tout est là https://sites.google.com/site/doingbayesiandataanalysis/.Bayesian Data Analysis: Tutorial R Bugs (Kruschke 2010). Un tutoriel approfondi et visuel qui accompagne pas à pas l’apprentissage de la statistique bayésienne avec de nombreux exemples pratiques. Tout est là https://sites.google.com/site/doingbayesiandataanalysis/.Bayesian Data Analysis (. Gelman et al. 2013). L’ouvrage de référence pour celles et ceux qui souhaitent acquérir une compréhension théorique et appliquée solide de la statistique bayésienne. Le site du livre est ici https://sites.stat.columbia.edu/gelman/book/.Bayesian Data Analysis (. Gelman et al. 2013). L’ouvrage de référence pour celles et ceux qui souhaitent acquérir une compréhension théorique et appliquée solide de la statistique bayésienne. Le site du livre est ici https://sites.stat.columbia.edu/gelman/book/.Statistical Rethinking: Bayesian Course Examples R Stan (McElreath 2020). Un livre captivant pour apprendre à construire et interpréter des modèles bayésiens en développant d’abord l’intuition statistique. Tous les détails ici https://xcelab.net/rm/, je recommande chaudement le cours en vidéos là https://github.com/rmcelreath/stat_rethinking_2024.Statistical Rethinking: Bayesian Course Examples R Stan (McElreath 2020). Un livre captivant pour apprendre à construire et interpréter des modèles bayésiens en développant d’abord l’intuition statistique. Tous les détails ici https://xcelab.net/rm/, je recommande chaudement le cours en vidéos là https://github.com/rmcelreath/stat_rethinking_2024.","code":""},{"path":"index.html","id":"comment-jai-écrit-ce-livre","chapter":"Introduction","heading":"Comment j’ai écrit ce livre?","text":"J’ai écrit ce livre avec RStudio (http://www.rstudio.com/ide/) en utilisant le package bookdown (http://bookdown.org/). Le site web est hébergé via des GitHub Pages (https://pages.github.com/).J’ai utilisé la version R-4.5.0_2025-04-11 de R et les packages suivants :","code":""},{"path":"index.html","id":"a-propos-de-lauteur","chapter":"Introduction","heading":"A propos de l’auteur","text":"Je m’appelle Olivier Gimenez (https://oliviergimenez.github.io/). Je suis directeur de recherche au CNRS. Après des études universitaires en mathématiques, j’ai fait une thèse en statistique pour l’écologie. J’ai passé mon habilitation à diriger des recherches (HdR) en écologie et évolution. Je suis aussi retourné sur les bancs de l’université pour m’initier à la sociologie.J’ai écrit des articles scientifiques (https://oliviergimenez.github.io/publication/papers/) faisant appel à la statistique bayésienne, et co-écrit avec des collègues des ouvrages (https://oliviergimenez.github.io/publication/books/) dont plusieurs abordent la statistique bayésienne.Vous pouvez retrouver sur BlueSky (oaggimenez.bsky.social) et LinkedIn (olivier-gimenez-545451115/), ou bien contacter via mon adresse email qui s’écrit olivier suivi d’un point puis gimenez, ensuite arobase, puis cefe, suivi d’un point, puis cnrs, suivi d’un point et pour terminer fr.","code":""},{"path":"index.html","id":"remerciements","chapter":"Introduction","heading":"Remerciements","text":"Merci à mon employeur, le Centre National de la Recherche Scientifique (CNRS). Chercheur.e et enseignant.e-chercheur.e sont des beaux métiers. Des métiers utiles. assiste néanmoins à la dégradation des conditions de travail dans le monde académique. Plus de compétition, plus de précarité, moins de postes pérennes. J’ai la chance d’évoluer dans un environnement bienveillant, le Centre d’Ecologie Fonctionnelle et Evolutive (CEFE), dont les personnels résistent en cultivant le collectif et les collaborations. Merci à eux.Mon intérêt pour la statistique bayésienne remonte à mes années en Angleterre et en Ecosse pour un post-doctorat. Merci à Byron Morgan de m’avoir laissé la liberté d’explorer cette voie qui n’était pas encore à la mode. Merci à Ruth King pour nos échanges et ma première expérience d’écriture d’un livre, et à Steve Brooks pour les séances de remue-méninge. C’est avec Byron, Ruth et Steve que nous avons organisé les premières formations (ou workshops) à la statistique bayésienne pour l’écologie. Je remercie également les collègues pour le matériel qu’ils ont mis à disposition et dont je suis inspiré pour écrire ce livre.Je remercie les étudiant.e.s de Master qui subissent mon enseignement depuis plus de 10 ans. Ils ont été mes cobayes et m’ont permis de mûrir (inconsciemment) ce projet de livre. Merci aussi aux étudiant.e.s de Master, aux doctorant.e.s et aux post-doctorant.e.s qui ont partagé un bout de vie avec moi.Merci aux personnes qui ont bien voulu relire des parties de ce livre.Et parce que je ne suis pas grand chose sans eux, ce livre est dédié à Eleni, Gabriel et Mélina.","code":""},{"path":"principes.html","id":"principes","chapter":"Chapitre 1 L’approche bayésienne","heading":"Chapitre 1 L’approche bayésienne","text":"","code":""},{"path":"principes.html","id":"introduction-1","chapter":"Chapitre 1 L’approche bayésienne","heading":"1.1 Introduction","text":"Dans ce chapitre, pose les bases en faisant quelques rappels de probabilité utiles pour la suite. J’introduis les notions clés de la statistique bayésienne à travers un exemple simple qui permet de fixer les idées, et qu’utilisera souvent dans le livre. fera aussi des parallèles entre la statistique classique ou fréquentiste et la statistique bayésienne.","code":""},{"path":"principes.html","id":"le-théorème-de-bayes","chapter":"Chapitre 1 L’approche bayésienne","heading":"1.2 Le théorème de Bayes","text":"Ne tardons plus et entrons dans le vif du sujet. La statistique bayésienne repose sur le théorème de Bayes (ou formule, ou loi, selon ce que vous préférez), nommé d’après le révérend Thomas Bayes. Ce théorème été publié en 1763, deux ans après la mort de Bayes grâce aux efforts de son ami Richard Price, et été découvert indépendamment par Pierre-Simon Laplace.Comme nous allons le voir dans un instant, le théorème de Bayes porte sur les probabilités conditionnelles, qui sont parfois un peu délicates à comprendre. La probabilité conditionnelle d’un événement sachant un événement B, que l’note \\(\\Pr(\\mid B)\\), est la probabilité que se produise, révisée en tenant compte de l’information supplémentaire que l’événement B s’est produit. Par exemple, imaginez qu’un de vos amis lance un dé (équilibré) et vous demande la probabilité que le résultat soit un six (). Votre réponse est 1/6 car chaque face du dé la même chance d’apparaître. Maintenant, imaginez que l’vous dise que le nombre obtenu est pair (B) avant de répondre. Comme il n’y que trois nombres pairs, dont un seul est six, vous pouvez réviser votre réponse : \\(\\Pr(\\mid B) = 1/3\\).Vous voyez comment l’information supplémentaire (ici, savoir que le nombre est pair) change l’estimation ? C’est exactement ce type de raisonnement que le théorème de Bayes formalise et généralise : il permet de calculer la probabilité d’un événement sachant qu’un autre événement B s’est produit. Plus précisément, le théorème de Bayes vous donne \\(\\Pr(\\mid B)\\) en utilisant les probabilités marginales \\(\\Pr()\\) et \\(\\Pr(B)\\) et la probabilité \\(\\Pr(B \\mid )\\) :\\[\\Pr(\\mid B) = \\displaystyle{\\frac{ \\Pr(B \\mid ) \\; \\Pr()}{\\Pr(B)}}.\\]parle de probabilité marginale quand s’intéresse à la probabilité d’un événement « tout seul », sans condition particulière. Par exemple, \\(\\Pr()\\) ou \\(\\Pr(B)\\), ce sont les chances globales de ou de B, sans tenir compte d’autre chose. dit « marginale » parce que, si vous faisiez un tableau avec toutes les combinaisons possibles (par exemple les résultats d’un dé classés en pair/impair et en “six/pas six”), alors \\(\\Pr()\\) et \\(\\Pr(B)\\) s’obtiennent en additionnant les cases d’une ligne ou d’une colonne, autrement dit ce qu’lit en marge du tableau.Le théorème de Bayes est souvent considéré comme un moyen de remonter d’un effet B à une cause inconnue, en connaissant la probabilité de l’effet B sachant la cause . Pensez, par exemple, à une situation où un diagnostic médical est requis, avec une maladie inconnue et B des symptômes ; la médecin connaît les chances d’avoir certains symptômes en fonction de plusieurs maladies ou \\(\\Pr(\\text{symptômes}|\\text{maladie})\\), et souhaite déduire la probabilité d’avoir une maladie connaissant les symptômes ou \\(\\Pr(\\text{maladie}|\\text{symptômes})\\). Cette manière de renverser \\(\\Pr(B \\mid )\\) en \\(\\Pr(\\mid B)\\) explique pourquoi le raisonnement bayésien est parfois appelé “probabilité inverse”.Plutôt que d’utiliser des lettres au risque de s’embrouiller, je trouve plus facile de retenir le théorème de Bayes écrit ainsi :\\[\\Pr(\\text{hypothèse} \\mid \\text{données}) = \\frac{ \\Pr(\\text{données} \\mid \\text{hypothèse}) \\; \\Pr(\\text{hypothèse})}{\\Pr(\\text{données})}.\\]L’hypothèse peut être un paramètre comme la probabilité d’apparition d’une maladie, ou des coefficients de régression liant cette probabilité à des facteurs de risque (e.g., lieu de vie, tabagisme). Le théorème de Bayes nous dit comment obtenir la probabilité d’une hypothèse à partir des données disponibles. Le théorème de Bayes nous dit comment obtenir la probabilité d’une hypothèse à partir des données disponibles.C’est pertinent car, réfléchissez-y, c’est exactement ce que fait la méthode scientifique. Nous voulons savoir à quel point une hypothèse est plausible à partir de données que nous avons collectées, et peut-être comparer plusieurs hypothèses entre elles. De ce point de vue, le raisonnement bayésien s’accorde avec le raisonnement scientifique, ce qui explique probablement pourquoi le cadre bayésien est si naturel pour faire et comprendre la statistique.Vous pourriez alors demander pourquoi la statistique bayésienne n’est-elle pas la norme ? Pendant longtemps, la mise en œuvre du théorème de Bayes été limitée par des difficultés de calcul, comme nous le verrons au chapitre suivant. Fort heureusement, l’amélioration de la puissance de calcul de nos ordinateurs et le développement de nouveaux algorithmes ont entraîné un essor marqué de l’approche bayésienne au cours des trente dernières années.","code":""},{"path":"principes.html","id":"statbayes","chapter":"Chapitre 1 L’approche bayésienne","heading":"1.3 Qu’est-ce que la statistique bayésienne ?","text":"Les problèmes statistiques typiques consistent à estimer un paramètre (ou plusieurs) à partir de données disponibles. va noter ce ou ces paramètres de manière générique, disons \\(\\theta\\). Pour estimer \\(\\theta\\), vous êtes sûrement plus familier de l’approche fréquentiste que de l’approche bayésienne. L’approche fréquentiste, en particulier l’estimation par maximum de vraisemblance, suppose que les paramètres sont fixes, et de valeurs inconnues. Les estimateurs classiques sont donc en général des valeurs ponctuelles ; par exemple, un estimateur de la probabilité d’obtenir une face d’un dé est le nombre de fois qu’obtenu cette face, divisé par le nombre de fois qu’lancé ce dé. L’approche bayésienne suppose que les paramètres ne sont pas fixes et suivent une distribution inconnue. Une distribution de probabilité est une expression mathématique qui donne la probabilité qu’une variable aléatoire prenne certaines valeurs. Elle peut être discrète (par exemple Bernoulli, Binomiale ou Poisson) ou continue (par exemple la loi normale ou gaussienne).L’approche bayésienne repose sur l’idée que vous commencez avec certaines connaissances sur le système avant même de l’étudier vous-même. Ensuite, vous collectez des données et mettez à jour ces connaissances priori en fonction des observations. Ces observations peuvent venir du terrain, du laboratoire ou de l’expertise de collègues. Ce processus de mise à jour repose sur le théorème de Bayes. De façon simplifiée, si l’prend \\(= \\theta\\) et \\(B = \\text{données}\\), alors le théorème de Bayes permet d’estimer le paramètre \\(\\theta\\) à partir des données comme suit :\\[\\Pr(\\theta \\mid \\text{données}) = \\frac{\\Pr(\\text{données} \\mid \\theta) \\times \\Pr(\\theta)}{\\Pr(\\text{données})}.\\]Prenons un peu de temps pour passer en revue chaque terme de cette formule.À gauche, nous avons \\(\\Pr(\\theta \\mid \\text{données})\\) la distribution posteriori. La probabilité de \\(\\theta\\) sachant les données. Elle représente ce que vous savez de \\(\\theta\\) après avoir vu les données. C’est la base de l’inférence et c’est précisément ce que vous cherchez : une distribution, possiblement multivariée si vous avez plusieurs paramètres.À droite, trouve \\({\\Pr(\\text{données} \\mid \\theta)}\\) la vraisemblance (ou likelihood en anglais). La probabilité des données sachant \\(\\theta\\). Cette quantité est la même que dans l’approche classique ou fréquentiste. Car oui, les approches bayésienne et fréquentiste partagent la même composante, la vraisemblance, ce qui explique pourquoi leurs résultats sont souvent proches. La vraisemblance exprime l’information que contiennent vos données, étant donné un modèle paramétré par \\(\\theta\\). en reparle à la Section 1.5.Ensuite, nous avons \\(\\Pr(\\theta)\\) la distribution priori. Cette quantité représente ce que vous savez sur \\(\\theta\\) avant de voir les données. Cette distribution priori ne doit pas dépendre des données, autrement dit ne devrait pas utiliser les données pour la construire. Elle peut être vague ou non-informative si vous ne savez rien sur \\(\\theta\\). Souvent, vous ne partez jamais de zéro, et dans l’idéal vous souhaiteriez que votre priori reflète les connaissances existantes. Je vous parlerai plus en détails des priors au Chapitre 4.Enfin, il y le dénominateur \\(\\Pr(\\text{données})\\), parfois appelée vraisemblance moyenne (average likelihood), moyenne par rapport au prior, car il s’obtient en intégrant la vraisemblance selon la loi priori \\({\\Pr(\\text{données}) = \\int{\\Pr(\\text{données} \\mid \\theta) \\times \\Pr(\\theta) \\, d\\theta}}\\). Cette quantité permet de normaliser la distribution posteriori pour qu’elle intègre à 1. Autrement dit, comme \\(\\int{\\Pr(\\theta \\mid \\text{données}) \\, d\\theta} = 1\\) puisque l’intégrale d’une densité de probabilité vaut 1, que \\(\\displaystyle \\int{\\frac{\\Pr(\\text{données} \\mid \\theta) \\times \\Pr(\\theta)}{\\Pr(\\text{données})} \\, d\\theta} = 1\\). Et puisque \\(\\Pr(\\text{données})\\) ne dépend pas de \\(\\theta\\), que \\(\\Pr(\\text{données}) = \\int{\\Pr(\\text{données} \\mid \\theta) \\times \\Pr(\\theta) \\, d\\theta}\\). C’est une intégrale de dimension égale au nombre de paramètres \\(\\theta\\) à estimer : pour 2 paramètres, une intégrale double, pour 3 paramètres une intégrale triple, etc. , au-delà de 3 dimensions, il devient difficile, voire impossible, de calculer cette intégrale. C’est l’une des raisons pour lesquelles l’approche bayésienne n’pas été utilisée plus tôt, et pourquoi besoin d’algorithmes pour estimer les distributions posteriori, comme je l’explique dans le Chapitre 2. En attendant, va dérouler un exemple relativement simple dans lequel la distribution posteriori une forme explicite.","code":""},{"path":"principes.html","id":"un-exemple-fil-rouge","chapter":"Chapitre 1 L’approche bayésienne","heading":"1.4 Un exemple fil rouge","text":"Prenons un exemple concret pour fixer les idées. Je travaille sur le ragondin (Myocastor coypus) (Figure 1.1), un rongeur semi-aquatique originaire d’Amérique du Sud, introduit en Europe pour l’élevage de fourrure. Il est aujourd’hui considéré comme une espèce invasive, en raison des dégâts qu’il occasionne dans les milieux humides (érosion des berges, destruction de la végétation) et de son rôle possible dans la transmission à l’humain de la leptospirose, une infection bactérienne potentiellement sévère, transmise par l’eau. Grâce à sa forte fécondité et à sa bonne adaptation aux climats tempérés, le ragondin proliféré rapidement.\nFigure 1.1: Cliché de ragondins (Myocastor coypus) pris sur le bassin versant du Lez dans les environs de Montpellier. Crédits : Yann Raulet.\nUne des questions qui m’intéressent est d’estimer la probabilité de survivre à l’hiver, les ragondins étant particulièrement sensibles au froid. Pour cela, équipe plusieurs individus d’une balise GPS au début de l’hiver, disons ici \\(n = 57\\). la fin de l’hiver, observe que \\(y = 19\\) ragondins sont encore vivants. L’objectif est d’estimer la probabilité de survie hivernale, que l’notera \\(\\theta\\). Voici les données :Vous vous dites sûrement qu’avec ces éléments, peut déjà estimer une probabilité de survie. Intuitivement, pense à la proportion d’individus ayant survécu, soit \\(19/57\\). Et vous n’avez pas tort. C’est une estimation raisonnable de \\(\\theta\\), la probabilité de survie hivernale. Essayons maintenant de formaliser cette intuition, afin de mieux comprendre ce qu’elle représente, et ce qu’elle suppose.Comme mentionné plus haut, la vraisemblance est une idée centrale qu’retrouve dans les approches fréquentiste et bayésienne. Commençons donc par construire cette vraisemblance. Pour cela, il nous faut poser quelques hypothèses.Premièrement, nous supposons que les individus sont indépendants, c’est-à-dire que la survie d’un ragondin n’influence pas la survie des autres ragondins. C’est une hypothèse forte, surtout quand sait qu’une femelle peut se reproduire 2 à 3 fois par et donner naissance à jusqu’à 10 petits dépendants d’elle au début de leur vie. Mais en modélisation, il vaut souvent mieux commencer simplement.Deuxièmement, nous supposons que tous les individus ont la même probabilité de survie. Là encore, c’est une simplification : sait, par exemple, que la mortalité des jeunes est plus élevée que celle des adultes.Sous ces deux hypothèses, le nombre \\(y\\) d’animaux encore vivants à la fin de l’hiver suit une loi binomiale, avec \\(\\theta\\) comme probabilité de succès (survie), et \\(n\\) comme nombre d’essais (individus suivis). notera \\(y \\sim \\text{Bin}(n, \\theta)\\). La loi binomiale est en fait la somme de plusieurs épreuves de Bernoulli indépendantes, comme dans l’exemple classique du pile ou face. À chaque lancé, ici le relâché d’un ragondin équipé d’un GPS en début d’hiver, suppose une probabilité \\(\\theta\\) de succès, c’est-à-dire de survivre à l’hiver, et d’échec, c’est-à-dire de mourir de froid. Si toutes ces épreuves sont indépendantes et ont la même probabilité de succès (nos hypothèses), alors le nombre de succès ou de ragondins vivants en sortie d’hiver suit une loi binomiale (voir aussi le Chapitre 6). Je donne des exemples de tirages Bernoulli et binomiaux dans la Figure 1.2.\nFigure 1.2:  Distributions de probabilité discrètes, Bernoulli et binomiale, illustrées avec 100 simulations (des tirages aléatoires générés par ordinateur). représente sur la ligne du haut la fréquence observée d’un tirage Bernoulli pour différentes valeurs de probabilité de survie \\(\\theta\\). Sur la ligne du bas, les histogrammes pour un tirage binomial avec 50 tentatives et différentes valeurs de probabilité de survie \\(\\theta\\).\nAu passage, il est facile de s’embrouiller entre tous les termes utilisés pour décrire une Bernoulli et une binomiale (et la normale) : vous pouvez retenir qu’une probabilité est un nombre, une distribution est une loi, une densité est la fonction qui la représente.","code":"\ny <- 19 # nombre d'individus ayant survécu à l'hiver\nn <- 57 # nombre d'individus suivis au début de l'hiver"},{"path":"principes.html","id":"maxvrais","chapter":"Chapitre 1 L’approche bayésienne","heading":"1.5 Le maximum de vraisemblance","text":"Dans l’approche classique (ou fréquentiste), estime la probabilité de survie \\(\\theta\\) en utilisant la méthode du maximum de vraisemblance. Mais qu’est-ce que cela signifie concrètement ? Il s’agit de trouver la valeur de \\(\\theta\\) qui rend les données observées les plus probables. Autrement dit, puisque les données sont ce qu’elles sont — elles ont été observées — cherche la valeur de \\(\\theta\\) qui maximise la probabilité que cet ensemble de données ait été produit.Comment justifie-t-mathématiquement cette idée plutôt intuitive ? Relisez bien la fin du paragraphe précédent. L’idée de chercher la valeur qui donne la plus grande probabilité revient à maximiser quelque chose. Mais quoi exactement ? La probabilité des données, étant donné un certain modèle paramétré par \\(\\theta\\), autrement dit la vraisemblance ou \\(\\Pr(\\text{données}|\\theta)\\) qu’vue à la Section 1.3. L’estimation classique repose donc sur la maximisation de la vraisemblance, ou plutôt la fonction de vraisemblance, c’est-à-dire la vraisemblance considérée comme une fonction de \\(\\theta\\).Dans notre cas, est face à une expérience binomiale : suit \\(n\\) ragondins à travers l’hiver, chacun ayant une probabilité \\(\\theta\\) de survivre. connaît la probabilité de chaque issue possible (ou fonction de masse). Par exemple, la probabilité qu’aucun ragondin ne survive est \\((1-\\theta)^n\\), car chacun des \\(n\\) individus meurt avec une probabilité \\(1-\\theta\\). Si prend par exemple une probabilité de survie de 0.5, \\((1-0.5)^{57} \\approx 0\\). peut calculer cette probabilité dans R avec la fonction dbinom() :où le premier argument x = 0 est pour aucun ragondin vivant. À l’inverse, la probabilité que tous survivent est \\(\\theta^n\\) qui vaut la même chose. Vous pouvez vérifier avec R et la ligne de commande dbinom(x = 57, size = 57, prob = 0.5). Si un seul ragondin survit, il faut que l’un des \\(n\\) survive avec probabilité \\(\\theta\\), et que les \\(n-1\\) autres meurent, avec probabilité \\((1-\\theta)^{n-1}\\). Comme n’importe lequel des \\(n\\) ragondins peut être celui qui survit, obtient une probabilité totale de \\(n \\theta (1-\\theta)^{n-1}\\). peut calculer cette probabilité avec dbinom(x = 1, size = 57, prob = 0.5). Plus généralement, la probabilité que \\(y\\) individus survivent est donnée par \\(\\displaystyle \\binom{n}{y}\\theta^y(1-\\theta)^{n-y}\\). Si l’considère cette expression comme une fonction de \\(\\theta\\) (et non de \\(y\\)), obtient la fonction de vraisemblance \\(\\displaystyle \\mathcal{L}(\\theta) = \\binom{n}{y} \\theta^y (1 - \\theta)^{n - y}\\). Le terme \\(\\displaystyle \\binom{n}{y}\\) est appelé coefficient binomial. Il correspond au nombre de façons différentes de choisir \\(y\\) survivants parmi les \\(n\\) ragondins, sans tenir compte de leur ordre.peut représenter cette vraisemblance dans R comme dans la Figure 1.3 :\nFigure 1.3: Fonction de vraisemblance pour la probabilité de survie hivernale du ragondin, calculée à partir de \\(y=19\\) survivants sur \\(n=57\\) individus suivis par GPS. Le maximum de vraisemblance est indiqué par une ligne pointillée rouge.\nNotre objectif est de trouver la valeur de \\(\\theta\\) qui maximise cette fonction. Autrement dit, cherche la valeur de survie (sur l’axe des abscisses dans la Figure 1.3) qui maximise la vraisemblance (sur l’axe des ordonnées). Cette valeur correspond à l’estimateur du maximum de vraisemblance, souvent noté \\(\\hat{\\theta}\\). Pour ce faire, il est souvent plus pratique de travailler avec le logarithme de la vraisemblance (la log-vraisemblance) car les sommes sont plus stables numériquement et plus faciles à dériver que les produits :\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta) = \\log \\binom{n}{y} + y \\log \\theta + (n - y) \\log (1 - \\theta).\n\\]\nLe premier terme, \\(\\displaystyle \\log \\binom{n}{y}\\), ne dépend pas de \\(\\theta\\), peut donc l’ignorer pour la suite. dérive alors la log-vraisemblance par rapport à \\(\\theta\\) :\\[\n\\displaystyle \\frac{d\\ell(\\theta)}{d\\theta} = \\frac{y}{\\theta} - \\frac{n - y}{1 - \\theta}.\n\\]cherche la valeur de \\(\\theta\\) qui annule cette dérivée :\\[\n\\frac{y}{\\theta} - \\frac{n - y}{1 - \\theta} = 0.\n\\]Après quelques simplifications, obtient que l’estimateur du maximum de vraisemblance \\(\\hat{\\theta}\\) est :\\[\n\\hat{\\theta} = \\frac{y}{n}.\n\\]Ce résultat rejoint notre intuition de départ : l’estimateur du maximum de vraisemblance est la proportion d’individus qui ont survécu, soit \\(19/57 \\approx 0.333\\). peut visualiser ce résultat sur la Figure 1.3, où le maximum de vraisemblance est indiqué par une ligne pointillée rouge.En pratique, les modèles contiennent plusieurs paramètres, des dizaines voire des centaines, et ne peut pas appliquer la même méthode pour maximiser la vraisemblance et trouver les estimateurs du maximum de vraisemblance. utilise plutôt des algorithmes itératifs d’optimisation qui vont résoudre le problème pour nous, en ajustant pas à pas une valeur initiale jusqu’à trouver celle qui maximise la vraisemblance. Par exemple, dans R, peut obtenir exactement ce même résultat en utilisant une régression logistique sans covariable (voir Chapitre 6) :Le calcul direct \\(\\hat{\\theta}=y/n\\) et le résultat de l’appel à la fonction glm sont cohérents, ils donnent la même valeur.","code":"\ndbinom(x = 0, size = 57, prob = 1 - 0.5)\n#> [1] 6.938894e-18\nmod <- glm(cbind(y, n - y) ~ 1, family = binomial)\ntheta_hat <- plogis(coef(mod))\ntheta_hat\n#> (Intercept) \n#>   0.3333333"},{"path":"principes.html","id":"et-en-bayésien","chapter":"Chapitre 1 L’approche bayésienne","heading":"1.6 Et en bayésien?","text":"Dans l’approche bayésienne, commence par exprimer nos connaissances priori sur la quantité que l’souhaite estimer. Ici, la probabilité de survie hivernale \\(\\theta\\). sait que \\(\\theta\\) est une variable continue comprise entre 0 et 1. Une distribution priori naturelle dans ce cas est la distribution bêta. La distribution bêta est définie par deux paramètres \\(\\) et \\(b\\) qui en contrôlent la forme :\\[\nq(\\theta \\mid , b) = \\frac{1}{\\text{Beta}(, b)}{\\theta^{- 1}} {(1-\\theta)^{b - 1}}\n\\]avec :\\[\n\\text{Beta}(, b) = \\frac{\\Gamma()\\Gamma(b)}{\\Gamma(+b)}, \\quad \\Gamma(n) = (n-1)!\n\\]\nVous pouvez oublier ces équations si vous n’êtes pas à l’aise avec. Essayons plutôt de visualiser cette distribution comme dans la Figure 1.4:\nFigure 1.4: Exemples de lois bêta pour différentes valeurs des paramètres \\(\\) et \\(b\\). Dans chaque panneau, les zones ombrées illustrent la probabilité d’observer une valeur dans un intervalle donné.\nChaque panneau de la figure montre la forme d’une loi bêta pour un couple de paramètres \\((, b)\\) donné. peut y observer plusieurs comportements caractéristiques.Beta(1,1) (en haut à gauche) correspond à une loi uniforme : toutes les valeurs de \\(\\theta\\) entre 0 et 1 sont considérées comme également probables. La densité est constante, ce qui signifie que la probabilité d’observer une valeur entre 0.1 et 0.2 est la même que celle d’en observer une entre 0.8 et 0.9. Cette probabilité est l’aire du rectangle délimité par le trait rouge et les lignes verticales calées à 0.1 et 0.2 ou 0.8 et 0.9 (les zones ombrées en rouge). une situation d’absence de connaissance priori.Beta(2,1) et Beta(1,2) représentent des connaissances asymétriques : la première est biaisée vers des valeurs proches de 1, la seconde vers des valeurs proches de 0. La probabilité d’observer une valeur entre 0.1 et 0.2 est plus petite que celle d’en observer une entre 0.8 et 0.9, et vice-versa.Beta(2,2) est symétrique, mais donne plus de poids aux valeurs centrales qu’une loi uniforme. La probabilité d’observer une valeur entre 0.1 et 0.2 est plus petite que celle d’en observer une entre 0.5 et 0.6.Beta(10,10) représente une connaissance très concentrée autour de 0.5 : c’est un prior très informatif. La probabilité d’observer une valeur entre 0.2 et 0.3 est beaucoup plus petite que celle d’en observer une entre 0.5 et 0.6.Beta(0.8,0.8) illustre une distribution en forme de U ou de baignoire, qui favorise les valeurs extrêmes (proches de 0 ou de 1). Les probabilités d’observer une valeur entre 0 et 0.1 et entre 0.9 et 1 sont plus grandes que celle d’en observer une entre 0.45 et 0.55.Ces exemples permettent de visualiser comment les paramètres \\(\\) et \\(b\\) influencent la forme du prior. Comment passe-t-de ce prior à la distribution posteriori ?suppose que \\(\\theta \\sim \\text{Beta}(, b)\\) et observé \\(y = 19\\) survivants parmi \\(n = 57\\) individus. La vraisemblance est \\(\\displaystyle \\binom{n}{y}\\theta^y(1 - \\theta)^{n - y}\\). Pour l’instant, va ignorer le dénominateur \\(\\Pr(y)\\) dans le théorème de Bayes, verra dans le chapitre suivant pourquoi. donc que l’posteriori est proportionnel au produit de la vraisemblance et de l’priori : \\(\\Pr(\\theta \\mid y) \\propto \\Pr(y \\mid \\theta) \\times \\Pr(\\theta)\\). Dans notre cas, multiplie terme à terme la vraisemblance et le prior, et en réarrangeant les termes en \\(\\theta\\) et \\(1-\\theta\\), :\\[\n\\begin{aligned}\n\\Pr(\\theta \\mid y) &\\propto \\underbrace{\\theta^y (1 - \\theta)^{n - y}}_{\\text{vraisemblance binomiale}} \\times \\underbrace{\\theta^{- 1} (1 - \\theta)^{b - 1}}_{\\text{priori bêta}} \\\\\n&\\propto \\underbrace{\\theta^{+ y - 1} (1 - \\theta)^{b + n - y - 1}}_{\\text{forme d'une loi bêta}}\n\\end{aligned}\n\\]Autrement dit, retrouve donc une loi bêta, avec des paramètres mis à jour \\(+ y\\) et \\(b + n - y\\). dit que la loi binomiale et la loi bêta sont conjuguées : lorsque l’utilise une loi bêta comme distribution priori pour un paramètre de probabilité dans un modèle binomial, la loi posteriori obtenue est également une loi bêta. Si utilise une loi uniforme priori (.e. Beta(1,1)), obtient que la distribution posteriori de la survie hivernale est une \\(\\text{Beta}(1+19, 1+57-19) = \\text{Beta}(20, 39)\\). Au passage, la distribution posteriori est connue, ce qui facilite grandement les calculs et leur interprétation. Par exemple, sait que la moyenne de la \\(\\text{Beta}(, b)\\) est \\(\\displaystyle \\frac{}{+b}\\), soit \\(\\frac{20}{59} \\approx 0.339\\). peut comparer cette valeur à l’estimateur du maximum de vraisemblance \\(19/57 \\approx 0.333\\). peut également visualiser la distribution posteriori comme dans la Figure 1.5, puisqu’connait l’équation de la densité d’une loi Bêta :\nFigure 1.5: Distribution priori uniforme (rouge) et distribution posteriori (noire) de la probabilité de survie hivernale du ragondin. La ligne bleue pointillée correspond à l’estimateur du maximum de vraisemblance.\nPlus généralement, lorsque l’dispose de suffisamment de données, les estimateurs bayésien et fréquentiste ont tendance à être très proches. Intuitivement, les données finissent par « dominer » l’information priori. Grossièrement, le mode de la distribution posteriori (la valeur pour laquelle la densité est maximale) correspond exactement à l’estimateur du maximum de vraisemblance.C’est une illustration du lien entre les deux approches, et du rôle central que joue la vraisemblance en statistique : elle constitue le point commun fondamental entre les approches bayésienne et fréquentiste.","code":""},{"path":"principes.html","id":"en-résumé","chapter":"Chapitre 1 L’approche bayésienne","heading":"1.7 En résumé","text":"Le théorème de Bayes est un outil de mise à jour des connaissances.La statistique bayésienne repose sur la vraisemblance et une loi priori pour les paramètres du modèle.La statistique fréquentiste fournit un estimateur ponctuel quand la statistique bayésienne estime une distribution pour chaque paramètre.Souvent, les approches classique et bayésienne donnent des estimations proches.Dans certains cas, la loi posteriori est explicite (ex : conjugaison bêta/binomiale).Dans la plupart des cas, il nous faudra utiliser des simulations pour obtenir la distribution posteriori, comme va le voir dans le Chapitre 2.","code":""},{"path":"mcmc.html","id":"mcmc","chapter":"Chapitre 2 Les méthodes MCMC","heading":"Chapitre 2 Les méthodes MCMC","text":"","code":""},{"path":"mcmc.html","id":"introduction-2","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.1 Introduction","text":"J’espère que je ne vous ai pas (trop) perdu dans le chapitre précédent avec toutes ces équations. Dans ce nouveau chapitre, nous passons dans les coulisses de la statistique bayésienne en découvrant les méthodes de Monte Carlo par chaînes de Markov (MCMC). Vous verrez comment et pourquoi ces techniques de simulation sont devenues essentielles pour mettre en œuvre l’inférence bayésienne en pratique. Et comme rien ne vaut la pratique, nous mettrons un peu la main à la pâte en codant nous-mêmes, à travers notre exemple fil rouge sur l’estimation d’une probabilité de survie.","code":""},{"path":"mcmc.html","id":"application-du-théorème-de-bayes","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.2 Application du théorème de Bayes","text":"Revenons à notre exemple fil rouge sur les ragondins, je redonne les données :Appliquons le théorème de Bayes de manière plus directe que dans le Chapitre 1, dans lequel mis de côté le dénominateur \\(\\Pr(\\text{données})\\). Voyons s’il est possible de faire avec. Comme l’vu, ce dénominateur est donné par \\(\\displaystyle \\Pr(\\text{y}) = \\int{\\Pr(\\text{données} \\mid \\theta) \\Pr(\\theta) \\, d\\theta}\\). va donc devoir calculer cette intégrale. Commençons par écrire une fonction R qui calcule le produit de la vraisemblance par le prior, c’est-à-dire le numérateur dans le théorème de Bayes \\(\\Pr(\\text{données} \\mid \\theta) \\times \\Pr(\\theta)\\) :Nous pouvons maintenant écrire la fonction qui calcule le dénominateur, et pour ce faire, nous allons utiliser la fonction integrate de R qui permet de calculer l’intégrale d’une fonction d’une variable. La fonction integrate met en oeuvre des techniques de quadrature pour diviser en petits carrés l’aire sous la courbe délimitée par la fonction à intégrer, et les compter.Nous obtenons alors une approximation numérique de la distribution posteriori de la survie hivernale comme dans la Figure 2.1 :\nFigure 2.1: Approximation numérique de la distribution posteriori de la survie hivernale.\nQuelle est la qualité de cette approximation numérique ? Idéalement, voudrait comparer l’approximation à la véritable distribution postérieure. Ça tombe bien, l’obtenue dans le Chapitre 1, il s’agit d’une distribution bêta de paramètres 20 et 39. peut se rendre compte dans la Figure 2.2 que les deux courbes se superposent parfaitement.\nFigure 2.2: Comparaison entre la postérieure exacte (couleur rouge brique) et l’approximation numérique (couleur crème).\nLa distribution postérieure exacte (couleur rouge brique) et l’approximation numérique (couleur crème) de la survie hivernale ne peuvent être distinguées, ce qui suggère que l’approximation numérique est plus que satisfaisante.Dans notre exemple, nous avons un seul paramètre à estimer : la survie hivernale. Cela signifie qu’il s’agit d’une intégrale unidimensionnelle au dénominateur, ce qui est assez facile avec les techniques de quadrature et la fonction R integrate().Mais que se passe-t-il si nous avons plusieurs paramètres ? Par exemple, imaginez que vous vouliez ajuster un modèle de régression avec une probabilité de survie qui dépend d’une variable explicative, par exemple la masse des ragondins. L’effet de cette variable est capturé par le paramètre de régression \\(\\beta_0\\) (l’ordonnée à l’origine), \\(\\beta_1\\) la pente associée, et aussi l’erreur résiduelle avec l’écart-type \\(\\sigma\\) (voir Chapitre 6). Le théorème de Bayes donne alors la distribution postérieure jointe de ces paramètres, c’est-à-dire des trois paramètres ensemble :\\[ \\displaystyle \\Pr(\\beta_0, \\beta_1, \\sigma \\mid \\text{y}) = \\frac{ \\Pr(\\text{y} \\mid \\beta_0, \\beta_1, \\sigma) \\times \\Pr(\\beta_0, \\beta_1, \\sigma)}{\\displaystyle \\iiint \\Pr(\\text{y} \\mid \\beta_0, \\beta_1, \\sigma) \\Pr(\\beta_0, \\beta_1, \\sigma) \\, d\\beta_0 \\, d\\beta_1 \\, d\\sigma} \\]Il y deux défis numériques majeurs :Souhaite-t-vraiment calculer une intégrale triple ? Non, car les méthodes classiques ne vont pas beaucoup plus loin que deux dimensions.s’intéresse souvent aux distributions marginales des paramètres (par ex. celle de \\(\\beta_1\\) correspondant à l’effet de la masse sur la survie), obtenues en intégrant la distribution posteriori jointe sur les autres paramètres (ici une intégrale double par rapport à \\(\\beta_0\\) et \\(\\sigma\\)) - ce qui devient vite incalculable quand leur nombre augmente.Dans la section suivante, nous introduisons des méthodes de simulation puissantes pour surmonter ces limitations.","code":"\ny <- 19 # nombre d'individus ayant survécu à l'hiver\nn <- 57 # nombre d'individus suivis au début de l'hiver\nnum <- function(theta) dbinom(y, n, theta) * dbeta(theta, 1, 1)\nden <- integrate(num, 0, 1)$value\n# Crée une grille de valeurs possibles pour la probabilité de survie (entre 0 et 1)\ngrid <- seq(0, 1, 0.01)\n\n# Calcule les valeurs de la densité a posteriori sur la grille\n# num(grid) est la vraisemblance * prior, et den est la constante de normalisation\nposterior <- data.frame(\n  survival = grid, \n  ratio = num(grid) / den  # densité a posteriori normalisée\n)\n\n# Trace la courbe de la densité a posteriori\nposterior %>%\n  ggplot(aes(x = survival, y = ratio)) + \n  geom_line(size = 1.5) +\n  labs(x = \"Probabilité de survie\", y = \"Densité\") +\n  theme_minimal()"},{"path":"mcmc.html","id":"les-méthodes-de-monte-carlo-par-chaînes-de-markov-mcmc","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.3 Les méthodes de Monte Carlo par chaînes de Markov (MCMC)","text":"En bref, l’idée des méthodes de Monte Carlo par chaînes de Markov (MCMC) est d’utiliser des simulations pour approximer les distributions posteriori avec une certaine précision, en tirant un grand nombre d’échantillons. Cela évite le calcul explicite des intégrales multidimensionnelles auxquelles à faire lorsqu’applique le théorème de Bayes.Ces algorithmes de simulation se composent de deux parties : chaînes de Markov et Monte Carlo. Essayons de comprendre ces deux termes.Que signifie Monte Carlo ? L’intégration Monte Carlo est une technique de simulation utilisée pour calculer des intégrales de fonctions quelconques \\(f\\) d’une variable aléatoire \\(X\\) suivant une distribution \\(\\Pr(X)\\), comme \\(\\displaystyle \\int f(X) \\Pr(X) dX\\). tire des valeurs \\(X_1, \\ldots, X_k\\) dans \\(\\Pr(X)\\), applique la fonction \\(f\\) à ces valeurs, puis calcule la moyenne de ces nouvelles valeurs : \\(\\displaystyle{\\frac{1}{k}}\\sum_{=1}^k{f(X_i)}\\) pour approximer l’intégrale.Comment utilise-t-l’intégration Monte Carlo dans un contexte bayésien ? La distribution posteriori contient toute l’information nécessaire sur le paramètre à estimer. Mais lorsqu’il y plusieurs paramètres, souhaite souvent résumer cette information en calculant des résumés numériques. Le résumé le plus simple est la moyenne de la distribution posteriori, soit \\(E(\\theta) = \\int \\theta \\Pr(\\theta \\mid \\text{données}) \\, d\\theta\\), où \\(X\\) est ici \\(\\theta\\) et \\(f\\) est l’identité. Cette moyenne posteriori peut être estimée par intégration Monte Carlo ; par exemple, pour la survie des ragondins :peut vérifier que la moyenne obtenue est proche de l’espérance théorique d’une distribution bêta :Un autre résumé numérique utile est l’intervalle de crédibilité à l’intérieur duquel se trouve le paramètre avec une certaine probabilité, généralement 0.95, soit un intervalle de crédibilité à 95%. Déterminer les bornes d’un tel intervalle nécessite le calcul de quantiles, ce qui implique aussi des intégrales, donc un recours à l’intégration Monte Carlo. Un intervalle de crédibilité à 95% pour la survie hivernale peut être obtenu avec :En passant, il y une différence entre l’intervalle de crédibilité en statistique bayésienne et l’intervalle de confiance de la statistique fréquentiste. Un intervalle de confiance à 95% signifie que si l’répétait l’expérience un très grand nombre de fois (équiper des ragondins de GPS et constater le nombre de survivants à l’hiver), environ 95% des intervalles construits de cette manière contiendraient la vraie valeur \\(\\theta\\) du paramètre. Mais ne peut pas dire que la probabilité que le paramètre soit dans un intervalle donné est de 95%. Un intervalle de crédibilité à 95%, en revanche, signifie qu’il y 95% de probabilité que le paramètre se trouve dans cet intervalle. L’interprétation de l’intervalle de crédibilité est un peu plus intuitive que celle de l’intervalle de confiance.Maintenant, qu’est-ce qu’une chaîne de Markov ? Une chaîne de Markov est une séquence aléatoire de nombres, dans laquelle chaque nombre dépend uniquement du nombre précédent. Un exemple est la météo dans ma ville, Montpellier, dans le sud de la France, où une journée ensoleillée est très probablement suivie d’une autre journée ensoleillée, disons avec une probabilité de 0.8, et une journée pluvieuse est rarement suivie d’une autre journée pluvieuse, disons avec une probabilité de 0.1. La dynamique de cette chaîne de Markov est capturée par la matrice de transition :\\[\n\\begin{array}{c|cc}\n& \\text{ensoleillé demain} & \\text{pluvieux demain} \\\\\\\\ \\hline\n\\text{ensoleillé aujourd'hui} & 0.8 & 0.2 \\\\\\\\\n\\text{pluvieux aujourd'hui}   & 0.9 & 0.1\n\\end{array}\n\\]Les lignes indiquent la météo aujourd’hui, et les colonnes celle de demain. Les cellules donnent la probabilité d’avoir une journée ensoleillée ou pluvieuse demain, selon le temps qu’il fait aujourd’hui (des probabilités conditionnelles, voir Chapitre 1).Sous certaines conditions, une chaîne de Markov converge vers une distribution stationnaire unique. Dans notre exemple météorologique, lançons la chaîne pour 20 étapes :Chaque ligne de la matrice converge vers la même distribution \\((0.82, 0.18)\\) au fur et à mesure que le nombre d’étapes augmente. La convergence se produit quel que soit l’état de départ : alors une probabilité de 0.82 d’avoir du soleil et de 0.18 d’avoir de la pluie.Revenons aux méthodes MCMC. L’idée centrale est que l’peut construire une chaîne de Markov dont la distribution stationnaire est justement la distribution posteriori de nos paramètres.En combinant Monte Carlo et chaînes de Markov, les méthodes MCMC nous permettent de générer un échantillon de valeurs dont la distribution converge vers la distribution posteriori (chaîne de Markov), et d’utiliser cet échantillon pour calculer des résumés numériques posteriori (Monte Carlo), comme la moyenne ou les intervalles de crédibilité.Il existe plusieurs manières de construire des chaînes de Markov pour l’inférence bayésienne. Vous avez peut-être entendu parler de l’algorithme de Metropolis-Hastings ou de l’échantillonneur de Gibbs. Vous pouvez consulter https://chi-feng.github.io/mcmc-demo/ pour une galerie interactive d’algorithmes MCMC. Ici, j’illustre l’algorithme de Metropolis et sa mise en œuvre pratique. Pour cela je m’inspire de l’excellent livre de Jim Albert (2009). Il n’est pas question d’être capable d’écrire un tel algorithme par soi-même, seulement d’en saisir les grandes lignes, et surtout la notion de simulations.Revenons à notre exemple d’estimation de la survie. Nous allons illustrer l’échantillonnage depuis la distribution posteriori de la survie. Commençons par écrire les fonctions pour la vraisemblance, le prior et la postérieure. se place sur l’échelle log pour manipuler des sommes et des soustractions plutôt que des produits et des ratios qui rendent les calculs numériques instables :L’algorithme de Metropolis fonctionne comme suit :choisit une valeur initiale pour le paramètre à estimer. C’est notre valeur de départ, ou point initial de la chaîne de Markov.choisit une valeur initiale pour le paramètre à estimer. C’est notre valeur de départ, ou point initial de la chaîne de Markov.Pour décider de l’étape suivante, propose de s’éloigner de la valeur courante du paramètre — c’est la valeur candidate. ajoute à la valeur courante une valeur tirée d’une loi normale avec une certaine variance — c’est la loi de proposition. L’algorithme de Metropolis est un cas particulier de celui de Metropolis-Hastings avec des propositions symétriques.Pour décider de l’étape suivante, propose de s’éloigner de la valeur courante du paramètre — c’est la valeur candidate. ajoute à la valeur courante une valeur tirée d’une loi normale avec une certaine variance — c’est la loi de proposition. L’algorithme de Metropolis est un cas particulier de celui de Metropolis-Hastings avec des propositions symétriques.calcule le rapport des vraisemblances entre la position candidate et la position courante : \\(R = \\displaystyle \\frac{\\Pr(\\text{valeur candidate}|\\text{données})}{\\Pr(\\text{valeur courante}|\\text{données})}\\). Pour calculer le numérateur et le dénominateur, il suffit d’appliquer le théorème de Bayes, et c’est là que la magie des méthodes MCMC opère car, comme la quantité \\(\\Pr(\\text{données})\\) apparaît au numérateur et au dénominateur, elle s’annule et plus besoin de la calculer ! remplacé le calcul d’une intégrale par des simulations.calcule le rapport des vraisemblances entre la position candidate et la position courante : \\(R = \\displaystyle \\frac{\\Pr(\\text{valeur candidate}|\\text{données})}{\\Pr(\\text{valeur courante}|\\text{données})}\\). Pour calculer le numérateur et le dénominateur, il suffit d’appliquer le théorème de Bayes, et c’est là que la magie des méthodes MCMC opère car, comme la quantité \\(\\Pr(\\text{données})\\) apparaît au numérateur et au dénominateur, elle s’annule et plus besoin de la calculer ! remplacé le calcul d’une intégrale par des simulations.Si la densité postérieure en la position candidate est plus grande qu’en la position courante, autrement dit si la valeur candidate est plus plausible, l’accepte sans hésiter. Sinon, l’accepte avec probabilité \\(R\\), et la rejette avec probabilité \\(1 - R\\). Par exemple, si la valeur candidate est dix fois moins plausible, l’accepte avec probabilité 0.1. utilise un générateur uniforme entre 0 et 1 (appelons-le \\(X\\)), et si \\(X < R\\), accepte la valeur candidate, sinon reste à la valeur courante. En pratique, vise un taux d’acceptation entre 0.2 et 0.4 qu’peut ajuster en calibrant la variance de la proposition, cela permet d’explorer tout le champ des possibles.Si la densité postérieure en la position candidate est plus grande qu’en la position courante, autrement dit si la valeur candidate est plus plausible, l’accepte sans hésiter. Sinon, l’accepte avec probabilité \\(R\\), et la rejette avec probabilité \\(1 - R\\). Par exemple, si la valeur candidate est dix fois moins plausible, l’accepte avec probabilité 0.1. utilise un générateur uniforme entre 0 et 1 (appelons-le \\(X\\)), et si \\(X < R\\), accepte la valeur candidate, sinon reste à la valeur courante. En pratique, vise un taux d’acceptation entre 0.2 et 0.4 qu’peut ajuster en calibrant la variance de la proposition, cela permet d’explorer tout le champ des possibles.répète les étapes 2 à 4 un certain nombre de fois — ce sont les itérations.répète les étapes 2 à 4 un certain nombre de fois — ce sont les itérations.Assez de théorie, passons à l’implémentation. commence par initialiser :Pourquoi faut-il initialiser ? Avant de lancer la chaîne de Markov, prépare les objets dans lesquels seront stockées les valeurs simulées de notre paramètre (ici, la probabilité de survie), ainsi que l’information sur l’acceptation ou non de chaque proposition. Et set.seed(666), à quoi ça sert ? Cette commande fixe la graine du générateur de nombres aléatoires. Elle permet de garantir que les simulations soient reproductibles : en relançant le code, vous obtiendrez exactement les mêmes valeurs simulées que les miennes.choisit une valeur de départ :Pourquoi une valeur de départ ? Une chaîne de Markov doit bien commencer quelque part : ici, choisit arbitrairement 0.5 comme valeur initiale de la probabilité de survie. La seule contrainte est que cette valeur soit compatible avec le prior, ne va pas prendre une survie de négative ou de 15. place cette valeur dans le premier élément du vecteur theta.post, et indique dans accept[1] <- 1 que cette première valeur est acceptée par construction, puisque c’est notre point de départ.Puis, écrit une fonction pour proposer une valeur candidate à partir de la valeur courante. Pour garantir que la nouvelle valeur proposée reste comprise entre 0 et 1 (puisqu’il s’agit ici d’une probabilité), effectue les calculs sur l’échelle logit :Cette fonction introduit une proposition aléatoire autour de la valeur courante. travaille sur l’échelle logit pour s’assurer que la proposition finale (candidate) reste toujours dans l’intervalle (0,1) (voir aussi le Chapitre 6). Le paramètre away contrôle la dispersion des propositions : plus il est grand, plus la chaîne pourra faire de grands sauts ; plus il est petit, plus les propositions seront proches de la valeur actuelle.Ensuite, applique les étapes 2 à 4 de l’algorithme dans une boucle (c’est l’étape 5, répétition des itérations) :Cette boucle construit itérativement la chaîne de Markov. La probabilité d’accepter une valeur moins plausible est proportionnelle à son rapport de vraisemblance. Le vecteur accept permet ensuite de diagnostiquer la fréquence d’acceptation, utile pour calibrer la chaîne.Jetons un coup d’oeil aux premières et dernières valeurs simulées :\nFigure 2.3: Trace plot des valeurs simulées de la probabilité de survie \\(\\theta\\) au fil des itérations.\nQue nous apprend ce trace plot ? L’axe horizontal représente les itérations (ou temps dans la chaîne de Markov). L’axe vertical montre les valeurs simulées de la probabilité de survie à chaque étape. Dans la figure, observe que la chaîne reste parfois plusieurs itérations consécutives à la même valeur. Cela se produit lorsque la valeur candidate proposée par l’algorithme est rejetée — la chaîne conserve alors la valeur précédente. À d’autres moments, voit des sauts vers de nouvelles valeurs, qui correspondent aux propositions acceptées.peut ensuite encapsuler l’algorithme dans une fonction réutilisable, ce qui permet de lancer facilement plusieurs chaînes :peut maintenant utiliser la fonction metropolis() pour lancer une autre chaîne, cette fois-ci en partant de 0.2 :Notez qu’parle souvent de “lancer plusieurs chaînes” MCMC afin de diagnostiquer la convergence. Il s’agit en réalité de réalisations indépendantes de la même chaîne de Markov, comme si lançait plusieurs fois une pièce avec une distribution un peu plus compliquée qu’une Bernoulli.\nFigure 2.4: Trace plot des valeurs simulées de la probabilité de survie \\(\\theta\\) au fil des itérations. Deux chaînes ont été lancées avec des valeurs initiales différentes, 0.5 en bleu et 0.2 en jaune.\nNotez que nous n’obtenons pas exactement les mêmes résultats car l’algorithme est stochastique. observe l’évolution parallèle de deux chaînes lancées avec des valeurs initiales différentes. Si les deux chaînes se rejoignent rapidement et oscillent autour des mêmes valeurs, cela indique une bonne convergence vers la distribution stationnaire souhaitée. C’est une étape clé des diagnostics de convergence MCMC que l’verra dans la suite de ce chapitre.\nFigure 2.5: Trace plot des valeurs simulées de la probabilité de survie \\(\\theta\\) au fil des 1000 itérations.\nAvec un grand nombre d’itérations, chaque chaîne devrait se stabiliser autour de sa distribution stationnaire. Visuellement, recherche une zone dense, homogène et bien explorée, ressemblant à une pelouse bien tondue.Une fois la distribution stationnaire atteinte, vous pouvez considérer les valeurs simulées de la chaîne de Markov comme un échantillon de la distribution posteriori et obtenir des résumés numériques des paramètres (moyenne posteriori, intervalle de crédibilité).Quand peut-dire qu’atteint cette distribution stationnaire ? Une fois qu’la convergence, combien de simulations faut-il encore faire pour obtenir une bonne approximation de la distribution posteriori de nos paramètres ? Je réponds à ces questions dans la section suivante.","code":"\n# tirage de 1000 valeurs depuis la postérieure bêta(20,39)\nsample_from_posterior <- rbeta(1000, 20, 39) \n# calcul de la moyenne par intégration Monte Carlo\nmean(sample_from_posterior) \n#> [1] 0.3384896\n20/(20+39) # espérance de la loi bêta(20,39)\n#> [1] 0.3389831\nquantile(sample_from_posterior, probs = c(2.5/100, 97.5/100))\n#>      2.5%     97.5% \n#> 0.2252663 0.4705924\ntemps <- matrix(c(0.8, 0.2, 0.9, 0.1), nrow = 2, byrow = T) # matrice de transition\netapes <- 20\nfor (i in 1:etapes){\n  temps <- temps %*% temps # multiplication matricielle\n}\nround(temps, 2) # produit matriciel après 20 étapes\n#>      [,1] [,2]\n#> [1,] 0.82 0.18\n#> [2,] 0.82 0.18\n# 19 animaux retrouvés vivants sur 57 capturés, marqués et relâchés\ny <- 19\nn <- 57\n\n# log-vraisemblance binomiale Bin(n = 57,p)\nloglikelihood <- function(x, p){\n  dbinom(x = x, size = n, prob = p, log = TRUE)\n}\n\n# densité du prior uniforme\nlogprior <- function(p){\n  dunif(x = p, min = 0, max = 1, log = TRUE)\n  # ou bien dbeta(x = p, shape1 = 0, shape2 = 1, log = TRUE)\n}\n\n# densité a posteriori (échelle logarithmique)\nposterior <- function(x, p){\n  loglikelihood(x, p) + logprior(p)\n}\nsteps <- 100 # nombre d'étapes ou itérations de la chaîne\ntheta.post <- rep(NA, steps) # vecteur pour stocker les valeurs simulées\naccept <- rep(NA, steps) # vecteur pour enregistrer les acceptations/rejets\nset.seed(666) # pour la reproductibilité\ninits <- 0.5 # valeur de départ choisie pour theta\ntheta.post[1] <- inits # on enregistre cette valeur comme première position de la chaîne\naccept[1] <- 1 # la valeur initiale est acceptée par défaut\nmove <- function(x, away = 1){ \n  logitx <- log(x / (1 - x)) # transformation logit : transforme x de (0,1) vers (-∞,+∞)\n  logit_candidate <- logitx + rnorm(1, 0, away) # on ajoute un bruit normal centré, de variance contrôlée par away\n  candidate <- plogis(logit_candidate) # transformation réciproque (logit^-1) : retourne une valeur entre 0 et 1\n  return(candidate) # retourne la valeur proposée\n}\nfor (t in 2:steps){ # pour chaque itération, à partir de la 2e\n\n  # Étape 2 : proposer une nouvelle valeur pour theta\n  theta_star <- move(theta.post[t-1])  # valeur candidate tirée à partir de la valeur précédente\n  \n  # Étape 3 : calculer le rapport des densités postérieures (échelle log)\n  pstar <- posterior(y, p = theta_star) # densité a posteriori à la valeur candidate\n  pprev <- posterior(y, p = theta.post[t-1]) # densité a posteriori à la valeur courante\n  logR <- pstar - pprev # différence sur l’échelle log\n  R <- exp(logR) # on revient à l’échelle naturelle (rapport des densités)\n\n  # Étape 4 : décider si on accepte ou rejette la proposition\n  X <- runif(1, 0, 1) # tirage aléatoire entre 0 et 1 : la \"roulette\" d’acceptation\n  if (X < R){ # si la proposition est plus plausible (ou pas trop pire)\n    theta.post[t] <- theta_star # on accepte et on stocke la valeur candidate\n    accept[t] <- 1 # on note que la proposition a été acceptée\n  } else {\n    theta.post[t] <- theta.post[t-1] # sinon on reste sur la valeur précédente\n    accept[t] <- 0 # on note le refus\n  }\n}\nhead(theta.post)\n#> [1] 0.5000000 0.5000000 0.3021903 0.3021903 0.1853669 0.1853669\ntail(theta.post)\n#> [1] 0.4076667 0.4076667 0.4076667 0.4076667 0.2914464 0.2914464\nmetropolis <- function(steps = 100, inits = 0.5, away = 1){\n  \n  theta.post <- rep(NA, steps) # on crée un vecteur pour stocker les échantillons\n  theta.post[1] <- inits # on initialise avec la valeur de départ\n  \n  for (t in 2:steps){ # boucle sur les étapes (à partir de la 2e)\n    \n    theta_star <- move(theta.post[t-1], away) # proposition d'une nouvelle valeur\n\n    # on calcule le log-ratio de la densité a posteriori entre candidat et position courante\n    logR <- posterior(y, theta_star) - \n            posterior(y, theta.post[t-1])\n    R <- exp(logR) # passage à l'échelle normale (non log)\n    \n    X <- runif(1, 0, 1) # tirage d'un nombre aléatoire uniforme\n    theta.post[t] <- ifelse(X < R, # si le tirage < probabilité d'acceptation...\n                            theta_star, # ... on accepte la valeur proposée\n                            theta.post[t-1]) # sinon on conserve la précédente\n  }\n  \n  return(theta.post) # on retourne l’échantillon simulé\n}\ntheta.post2 <- metropolis(steps = 100, inits = 0.2) # départ à 0.2"},{"path":"mcmc.html","id":"convergence-diag","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.4 Évaluer la convergence","text":"Lorsqu’applique une méthode MCMC, il faut déterminer combien de temps il faut à la chaîne de Markov pour converger vers la distribution cible, et combien d’itérations supplémentaires sont nécessaires après la convergence pour obtenir des estimations Monte Carlo fiables des résumés numériques (moyennes posteriori, intervalles de crédibilité).","code":""},{"path":"mcmc.html","id":"burn-in","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.4.1 Burn-in","text":"En pratique, ignore les premières valeurs de la chaîne de Markov et n’utilise que les valeurs simulées après convergence. Les observations initiales que l’écarte sont généralement appelées la période de burn-(ou pré-chauffage).La méthode la plus simple pour déterminer la durée de la période de burn-est d’inspecter les trace plots. Reprenons notre exemple et observons dans la Figure 2.6 un trace plot pour une chaîne démarrant à la valeur 0.99 :\nFigure 2.6: Trace plot pour une chaîne démarrant à 0.99. La zone ombrée illustre une période de burn-possible.\nLa chaîne démarre à 0.99 et se stabilise rapidement, les valeurs oscillant autour de 0.3 à partir de la 100ème itération. peut choisir la zone ombrée comme période de burn-et éliminer les 100 premières valeurs. Par prudence, pourrait utiliser 250 voire 500 itérations comme burn-.Examiner un trace plot d’une seule chaîne est utile, mais lance généralement plusieurs chaînes avec des valeurs initiales différentes pour vérifier que toutes atteignent la même distribution stationnaire. Cette approche est formalisée par la statistique de Brooks-Gelman-Rubin (BGR), notée \\(\\hat{R}\\), qui mesure le ratio entre la variabilité totale (entre-chaînes + intra-chaîne) et la variabilité intra-chaîne. Elle est proche du test \\(F\\) dans une analyse de variance (ici à un facteur dont les modalités sont les chaînes). Une valeur inférieure à 1.1 indique une convergence probable.Revenons à notre exemple : nous exécutons deux chaînes de Markov avec des valeurs initiales de 0.2 et 0.8, en faisant varier le nombre d’itérations de 100 à 1000 toutes les 50 itérations, et nous calculons la statistique BGR en utilisant la moitié des itérations comme période de burn-(Figure 2.7).\nFigure 2.7: Valeur de la statistique de Brooks-Gelman-Rubin (BGR) en fonction du nombre d’itérations. Une valeur proche de 1 suggère la convergence.\nNous obtenons une valeur de la statistique BGR proche de 1 dès 300 itérations, ce qui suggère qu’avec un burn-de 300 itérations, rien n’indique un problème de convergence.Il est important de garder à l’esprit qu’une valeur proche de 1 pour la statistique BGR constitue une condition nécessaire, mais non suffisante, à la convergence. En d’autres termes, ce diagnostic ne permet pas d’affirmer avec certitude que la chaîne convergé, mais simplement qu’ne détecte pas de signe évident qu’elle ne l’pas fait. Mon conseil : prenez toujours le temps de jeter un coup d’oeil aux trace plots.","code":""},{"path":"mcmc.html","id":"longueur-de-chaîne","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.4.2 Longueur de chaîne","text":"Quelle longueur de chaîne est nécessaire pour obtenir des estimations fiables des paramètres ? Il faut garder à l’esprit que les étapes successives d’une chaîne de Markov ne sont pas indépendantes. C’est ce qu’appelle l’autocorrélation. Idéalement, cherche à minimiser cette autocorrélation.Ici encore, les trace plots permettent de diagnostiquer des problèmes d’autocorrélation. Revenons à l’exemple de survie. La Figure 2.8 ci-dessous montre les trace plots (3000 itérations) pour différentes valeurs de l’écart-type (paramètre away) de la loi normale de proposition utilisée pour générer les valeurs candidates :\nFigure 2.8: Trace plots pour différentes valeurs de l’écart-type de la proposition (away). Un bon mixing est observé avec away = 1. La zone grise ombrée correspond à un burn-de 300 itérations.\nLes petits et grands déplacements visibles dans les panneaux de gauche et de droite entraînent une forte corrélation entre les observations successives de la chaîne de Markov, tandis qu’un écart-type égal à 1 (au centre) permet une exploration efficace de l’espace des paramètres. Ce mouvement dans l’espace des paramètres est appelé “mixing”. Le mixing est considéré comme mauvais lorsque la chaîne fait de trop petits ou de trop grands sauts, et bon dans le cas contraire.\nFigure 2.9: Fonctions d’autocorrélation (ACF) pour différentes valeurs de l’écart-type de la proposition. Une faible autocorrélation est un signe de bon mixing. Un burn-de 300 itérations est appliqué.\nDans les panneaux de gauche et de droite, l’autocorrélation est forte, diminue lentement avec le lag, et le mixing est mauvais. Dans le panneau central, l’autocorrélation est faible, diminue rapidement avec le lag, et le mixing est bon.L’autocorrélation n’est pas forcément un gros problème. Des observations fortement corrélées nécessitent simplement un plus grand nombre d’échantillons, et donc des simulations plus longues. Mais combien d’itérations faut-il exactement ? La taille effective de l’échantillon (n.eff) mesure la longueur utile de la chaîne en tenant compte de l’autocorrélation. Il est recommandé de vérifier la n.eff pour chaque paramètre d’intérêt, ainsi que pour toute combinaison pertinente de paramètres. En général, considère qu’il faut au moins \\(\\text{n.eff} \\geq 100\\) observations indépendantes pour obtenir des estimations Monte Carlo fiables des paramètres du modèle. Dans l’exemple de la survie animale, n.eff peut être calculée avec la fonction coda::effectiveSize():Comme pouvait s’y attendre, la valeur de n.eff est inférieure au nombre total d’itérations MCMC (2000) en raison de l’autocorrélation. Ce n’est que lorsque l’écart-type de la distribution de proposition est égal à 1 que le mixing est bon (\\(\\geq 100\\)), ce qui permet d’obtenir une taille d’échantillon effective satisfaisante.","code":"\n# Générer les chaînes pour trois valeurs d'écart-type\nd <- tibble(away = c(0.1, 1, 10)) %>% \n     mutate(accepted_traj = map(away, \n                       metropolis, \n                                steps = n_steps, \n                                inits = 0.1)) %>% \n     unnest(accepted_traj) %>%\n     mutate(proposal_sd = str_c(\"Écart-type = \", away),\n            iter = rep(1:n_steps, times = 3))\n\n# Calculer la taille effective d'échantillon\nneff1 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"Écart-type = 0.1\"][-c(1:300)])\nneff2 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"Écart-type = 1\"][-c(1:300)])\nneff3 <- coda::effectiveSize(d$accepted_traj[d$proposal_sd==\"Écart-type = 10\"][-c(1:300)])\ntibble(\"Écart-type\" = c(0.1, 1, 10),\n       \"n.eff\" = round(c(neff1, neff2, neff3)))\n#> # A tibble: 3 × 2\n#>   `Écart-type` n.eff\n#>          <dbl> <dbl>\n#> 1          0.1    81\n#> 2          1     524\n#> 3         10      77"},{"path":"mcmc.html","id":"et-si-vous-avez-des-problèmes-de-convergence","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.4.3 Et si vous avez des problèmes de convergence ?","text":"Lorsque vous diagnostiquez la convergence d’une chaîne MCMC, vous rencontrerez (très) souvent des difficultés. Cette section propose quelques conseils pratiques qui, je l’espère, vous seront utiles.Lorsque le mixing est mauvais et que la taille effective de l’échantillon est faible, il peut suffire d’augmenter la période de burn-et/ou d’augmenter le nombre de simulations. L’utilisation de priors plus informatifs peut également faciliter la convergence des chaînes de Markov, en aidant l’algorithme MCMC à explorer plus efficacement l’espace des paramètres. Dans le même esprit, choisir de meilleures valeurs initiales pour démarrer la chaîne peut aussi améliorer les choses. Une stratégie utile consiste à utiliser les estimations d’un modèle plus simple pour lequel vos chaînes MCMC convergent déjà.Si les problèmes de convergence persistent, il y souvent un problème avec le modèle lui-même. Un bug dans le code ? Une faute de frappe ? Une erreur dans les équations ? Comme souvent en programmation, le meilleur moyen d’identifier le problème est de réduire la complexité du modèle et de repartir d’un modèle plus simple, jusqu’à ce que vous trouviez ce qui ne va pas.Un autre conseil est de considérer votre modèle avant tout comme un générateur de données. Simulez des données à partir de ce modèle, en utilisant des valeurs réalistes pour les paramètres, puis tentez de retrouver ces paramètres en ajustant le modèle aux données simulées. Cette approche vous aidera à mieux comprendre comment le modèle fonctionne, ce qu’il ne fait pas, et le type de données nécessaire pour obtenir des estimations de paramètres fiables. reviendra sur cette technique dans les chapitres suivants.","code":""},{"path":"mcmc.html","id":"en-résumé-1","chapter":"Chapitre 2 Les méthodes MCMC","heading":"2.5 En résumé","text":"L’idée des méthodes de Monte Carlo par chaînes de Markov (MCMC) est de simuler des valeurs à partir d’une chaîne de Markov dont la distribution stationnaire est précisément la distribution posteriori des paramètres qu’cherche à estimer.L’idée des méthodes de Monte Carlo par chaînes de Markov (MCMC) est de simuler des valeurs à partir d’une chaîne de Markov dont la distribution stationnaire est précisément la distribution posteriori des paramètres qu’cherche à estimer.En pratique, lance plusieurs chaînes de Markov en partant de valeurs initiales dispersées.En pratique, lance plusieurs chaînes de Markov en partant de valeurs initiales dispersées.écarte les premières itérations (phase de pré-chauffage ou burn-) et considère que la convergence est atteinte lorsque toutes les chaînes convergent vers le même régime.écarte les premières itérations (phase de pré-chauffage ou burn-) et considère que la convergence est atteinte lorsque toutes les chaînes convergent vers le même régime.À partir de là, fait tourner les chaînes suffisamment longtemps, puis calcule des estimations Monte Carlo de résumés numériques (par exemple, les moyennes posteriori ou les intervalles de crédibilité) des paramètres.À partir de là, fait tourner les chaînes suffisamment longtemps, puis calcule des estimations Monte Carlo de résumés numériques (par exemple, les moyennes posteriori ou les intervalles de crédibilité) des paramètres.Évidemment, n’pas envie de construire et implémenter à la main les méthodes MCMC à chaque nouvelle analyse, et verra dans le Chapitre 3 comment se faciliter la tâche.Évidemment, n’pas envie de construire et implémenter à la main les méthodes MCMC à chaque nouvelle analyse, et verra dans le Chapitre 3 comment se faciliter la tâche.","code":""},{"path":"logiciels.html","id":"logiciels","chapter":"Chapitre 3 Mise en oeuvre pratique","heading":"Chapitre 3 Mise en oeuvre pratique","text":"","code":""},{"path":"logiciels.html","id":"introduction-3","chapter":"Chapitre 3 Mise en oeuvre pratique","heading":"3.1 Introduction","text":"Dans ce chapitre, nous découvrirons brms un outil très pratique pour faire de la statistique bayésienne sans trop d’efforts. Dans la version enrichie en ligne à https://oliviergimenez.github.io/statistique-bayes/logiciels.html, vous trouverez aussi une introduction à NIMBLE. Il s’agit de deux packages R qui implémentent pour vous les algorithmes MCMC. Concrètement, il vous suffit de spécifier une vraisemblance et des priors pour que le théorème de Bayes s’applique automatiquement. Grâce à une syntaxe proche de celle de R, les deux packages rendent cette étape relativement simple, même pour des modèles complexes.","code":""},{"path":"logiciels.html","id":"brms","chapter":"Chapitre 3 Mise en oeuvre pratique","heading":"3.2 brms","text":"brms signifie Bayesian Regression Models using Stan. Ce package permet de formuler et d’estimer des modèles de régression (voir la section suivante et les Chapitres 5 et 6) de manière intuitive grâce à une syntaxe proche de celle du package lme4 (la référence R pour les modèles mixtes), tout en s’appuyant sur Stan. Le package est en constant développement, rendez-vous à https://paul-buerkner.github.io/brms/. Vous pouvez obtenir de l’aide via https://discourse.mc-stan.org/.Pour utiliser brms, commence par préparer les données :Sans oublier de charger brms :La vraisemblance est binomiale dans notre exemple fil rouge. Dans brms, peut exprimer cela simplement :La syntaxe est relativement simple mais nécessite quelques explications. L’argument y | trials(n) ~ 1 permet de spécifier un modèle dans lequel \\(y\\) succès parmi \\(n\\) essais, et estime une ordonnée à l’origine ou intercept seulement, le 1 après ~. Pourquoi un intercept ici ? Pourquoi pas directement la survie \\(\\theta\\). Parce qu’utilise family = binomial(\"logit\") à la ligne d’après pour spécifier à brms que la variable réponse suit une loi binomiale. Autrement dit un modèle linéaire généralisé (voir le Chapitre 6) avec \\(\\text{logit}(\\theta) = \\beta\\) et estime \\(\\beta\\) l’intercept. Les arguments iter = 2000, warmup = 300 et chains = 3 stipulent à brms d’utiliser 300 itérations pour l’adaptation (burn-), et les 1700 suivantes pour l’inférence, avec 3 chaînes.\n\nJetons un coup d’oeil aux résultats :Cette commande affiche un tableau récapitulatif des estimations postérieures pour chaque paramètre du modèle. y trouve :Estimate est la moyenne posteriori.Est.Error est l’écart-type de cette estimation.l-95% CI et u-95% CI sont les bornes de l’intervalle de crédibilité à 95%.Le diagnostic de convergence Rhat.Et Bulk_ESS la taille effective d’échantillon (Tail_ESS est une autre mesure de la taille effective d’échantillon qu’n’utilisera pas ici).La moyenne posteriori vaut -0.7028089 bien loin de la proportion de ragondins qui ont survécu à l’hiver (\\(19/57 \\approx 0.33\\)). Comme toujours dans R et l’implémentation des modèles linéaires généralisés (voir Chapitre 6), les estimations des paramètres sont données sur l’échelle de la fonction de lien. Ici l’intercept estimé est exprimé sur l’échelle logit. Pour le convertir en probabilité de survie (entre 0 et 1), extrait d’abord les valeurs générées dans la distribution posteriori de l’intercept \\(\\beta\\) avec la fonction brms::as_draws_matrix() :Puis applique la fonction logistique réciproque plogis() sur chacune de ces valeurs pour obtenir tout un tas de valeurs simulées dans la distribution posteriori de la survie \\(\\theta\\) :obtient ainsi une estimation directe de la moyenne posteriori de la probabilité de survie, accompagnée de son intervalle de crédibilité à 95% :Ou plus directement avec la fonction posterior::summarise_draws() :Pour visualiser la distribution posteriori de la probabilité de survie, il suffit d’utiliser (Figure 3.1) :\nFigure 3.1: Histogramme de la distribution posteriori de la probabilité de survie (\\(\\theta\\)).\nDans brms, peut évaluer la convergence des chaînes MCMC (Figure 3.2) :\nFigure 3.2: Densité posteriori et trace plot de la probabilité de survie sur l’échelle logit (\\(\\beta\\)).\nCe graphique affiche les trace plots (à droite) ainsi que les densités posteriori (à gauche).\nAu passage, pour déterminer de la longueur de la période de pré-chauffage ou burn-, il suffit de faire tourner brms avec warmup = 0 pour quelques centaines ou milliers d’itérations et d’examiner la trace du paramètre pour décider du nombre d’itérations à utiliser pour atteindre la convergence.Un avantage majeur des méthodes MCMC est qu’elles permettent d’obtenir la distribution posteriori de n’importe quelle fonction des paramètres en appliquant cette fonction aux valeurs tirées dans les distributions posteriori de ces paramètres. noter qu’ici estime l’intercept \\(\\beta\\) et donc déjà utilisé cette idée pour obtenir la distribution posteriori de la probabilité de survie en appliquant la fonction logit réciproque. Comme autre exemple, disons que j’aimerais calculer l’espérance de vie des ragondins, celle-ci étant donnée par \\(\\lambda = -1/\\log(\\theta)\\) :L’espérance de vie est d’un approximativement. peut également visualiser la distribution posteriori de l’espérance de vie (Figure 3.3) :\nFigure 3.3: Histogramme de la distribution posteriori de l’espérance de vie.\nIl y tout un tas de paramètres qui sont fixés par défaut dans brms, il est important d’en être conscient. Ça concerne les priors en particulier. Dans brms, les priors par défaut sont souvent non informatifs ou faiblement informatifs, mais il est toujours bon de les examiner explicitement. La commande suivante permet d’afficher le résumé des priors utilisés dans un modèle déjà ajusté :Le package brms utilise comme priori faiblement informatif une loi de Student à 3 degrés de liberté, centrée en 0, avec un écart-type de 2.5. Les 3 degrés de liberté donnent une distribution avec des queues plus épaisses qu’une normale, permettant une certaine robustesse aux valeurs extrêmes. Le centre en 0 traduit une absence d’priori fort sur la valeur de l’intercept. La largeur 2.5 autorise une variation raisonnablement large de l’intercept sans être complètement non-informatif.Dans certains cas, il est pertinent de définir soi-même un prior, par exemple pour refléter des connaissances issues de la littérature ou pour contraindre d’avantage l’estimation (prior informatif). Ici, propose un prior normal centré en 0 avec un écart-type de 1.5 sur l’intercept, en reparlera au Chapitre 4 :peut ensuite l’utiliser dans la spécification du modèle :Vous pouvez vérifier que les résultats sont proches de ceux obtenus avec le prior par défaut :","code":"\ndat <- data.frame(y = 19, n = 57)\nlibrary(brms)\nbayes.brms <- brm(\n  y | trials(n) ~ 1, # le nombre de succès est fonction d'un intercept\n  family = binomial(\"logit\"), # famille binomiale avec fonction de lien logit\n  data = dat, # données utilisées\n  chains = 3, # nombre de chaînes MCMC\n  iter = 2000, # nombre total d'itérations par chaîne\n  warmup = 300, # nombre d'itérations burn-in\n  thin = 1 # pas de sous-échantillonnage (chaque itération est conservée)\n)\nsummary(bayes.brms)\n#>  Family: binomial \n#>   Links: mu = logit \n#> Formula: y | trials(n) ~ 1 \n#>    Data: dat (Number of observations: 1) \n#>   Draws: 3 chains, each with iter = 2000; warmup = 300; thin = 1;\n#>          total post-warmup draws = 5100\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    -0.70      0.28    -1.26    -0.17 1.00     1766     2278\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\ndraws_fit <- as_draws_matrix(bayes.brms)\nbeta <- draws_fit[,'Intercept'] # sélectionne la colonne intercept\ntheta <- plogis(beta)  # conversion logit -> [0,1]\nmean(theta)\n#> [1] 0.3341162\nquantile(theta, probas = c(2.5,97.5)/100)\n#>        0%       25%       50%       75%      100% \n#> 0.1321266 0.2916357 0.3333167 0.3748659 0.5535767\nsummarise_draws(theta)\n#> # A tibble: 1 × 10\n#>   variable   mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 Intercept 0.334  0.333 0.0615 0.0617 0.236 0.438  1.00    1766.    2278.\ndraws_fit %>%\n  ggplot(aes(x = theta)) +\n  geom_histogram(color = \"white\", fill = \"steelblue\", bins = 30) +\n  labs(x = \"Probabilité de survie\", y = \"Fréquence\")\nplot(bayes.brms)\nbeta <- draws_fit[,'Intercept'] # sélectionne la colonne intercept\ntheta <- plogis(beta)  # conversion logit -> [0,1]\nlambda <- -1 / log(theta) # transforme survie en espérance de vie\nsummarize_draws(lambda) # résumé des tirages : moyenne, médiane, intervalles\n#> # A tibble: 1 × 10\n#>   variable   mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 Intercept 0.924  0.910 0.160 0.153 0.693  1.21  1.00    1766.    2278.\nlambda %>%\n  as_tibble() %>%\n  ggplot() +\n  geom_histogram(aes(x = Intercept), color = \"white\") +\n  labs(x = \"Espérance de vie\")\nprior_summary(bayes.brms)\n#> Intercept ~ student_t(3, 0, 2.5)\nnlprior <- prior(normal(0, 1.5), class = \"Intercept\")\nbayes.brms <- brm(y | trials(n) ~ 1,\n                  family = binomial(\"logit\"),\n                  data = dat,\n                  prior = nlprior, # nos propres priors\n                  chains = 3,\n                  iter = 2000,\n                  warmup = 300,\n                  thin = 1)\nsummary(bayes.brms)\n#>  Family: binomial \n#>   Links: mu = logit \n#> Formula: y | trials(n) ~ 1 \n#>    Data: dat (Number of observations: 1) \n#>   Draws: 3 chains, each with iter = 2000; warmup = 300; thin = 1;\n#>          total post-warmup draws = 5100\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    -0.68      0.28    -1.24    -0.13 1.00     1914     2515\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"logiciels.html","id":"en-résumé-2","chapter":"Chapitre 3 Mise en oeuvre pratique","heading":"3.3 En résumé","text":"brms permet de tirer parti des méthodes MCMC sans avoir à écrire le modèle soi-même (la vraisemblance en particulier).brms permet de tirer parti des méthodes MCMC sans avoir à écrire le modèle soi-même (la vraisemblance en particulier).Sa syntaxe est simple et proche de celle de lme4, ce qui le rend particulièrement adapté pour les modèles linéaires généralisés (mixtes ou pas ; voir Chapitre 6).Sa syntaxe est simple et proche de celle de lme4, ce qui le rend particulièrement adapté pour les modèles linéaires généralisés (mixtes ou pas ; voir Chapitre 6).En contrepartie, brms repose sur des composants préprogrammés (familles de modèles, etc.), et il est important d’être attentif aux choix faits par défaut, notamment en ce qui concerne les distributions priori.En contrepartie, brms repose sur des composants préprogrammés (familles de modèles, etc.), et il est important d’être attentif aux choix faits par défaut, notamment en ce qui concerne les distributions priori.Ce chapitre propose ainsi une première approche concrète de l’implémentation des modèles bayésiens, avant d’aborder des modèles plus riches, comme les modèles mixtes.Ce chapitre propose ainsi une première approche concrète de l’implémentation des modèles bayésiens, avant d’aborder des modèles plus riches, comme les modèles mixtes.","code":""},{"path":"prior.html","id":"prior","chapter":"Chapitre 4 Les distributions a priori","heading":"Chapitre 4 Les distributions a priori","text":"","code":""},{"path":"prior.html","id":"introduction-4","chapter":"Chapitre 4 Les distributions a priori","heading":"4.1 Introduction","text":"Dans ce chapitre, nous allons explorer un aspect fondamental de la statistique bayésienne : le rôle des distributions priori ou priors. Nous verrons comment ces priors interagissent avec les données via le théorème de Bayes pour produire la distribution posteriori, et comment cette influence varie selon la quantité d’information apportée par les données. Nous apprendrons également à intégrer des informations extérieures pertinentes issues d’expertises ou d’études antérieures, et à évaluer de manière critique nos choix priori à l’aide de simulations.","code":""},{"path":"prior.html","id":"roleprior","chapter":"Chapitre 4 Les distributions a priori","heading":"4.2 Le rôle du prior","text":"En statistique bayésienne, le prior joue un rôle essentiel : il traduit nos connaissances, nos incertitudes ou, au contraire, notre absence d’information sur les paramètres d’un modèle. Bien choisir ses priors est donc une étape clé de toute analyse bayésienne. Pourquoi utiliser un prior ?Pour intégrer les connaissances existantes : dispose souvent d’informations issues d’études antérieures, de méta-analyses ou d’avis d’experts. Le prior permet de formaliser et d’intégrer cette connaissance préalable, plutôt que de l’ignorer et de faire comme si ne partait de rien. Nous verrons un exemple dans la Section 4.4.Pour intégrer les connaissances existantes : dispose souvent d’informations issues d’études antérieures, de méta-analyses ou d’avis d’experts. Le prior permet de formaliser et d’intégrer cette connaissance préalable, plutôt que de l’ignorer et de faire comme si ne partait de rien. Nous verrons un exemple dans la Section 4.4.Pour faire face à un manque de données : lorsque les données sont rares ou peu informatives, les méthodes fréquentistes peuvent échouer à estimer correctement certains paramètres (estimation aux bornes pour une probabilité, ou variance nulle). Dans ces situations, un prior bien choisi peut aider à stabiliser l’inférence, en apportant une information complémentaire.Pour faire face à un manque de données : lorsque les données sont rares ou peu informatives, les méthodes fréquentistes peuvent échouer à estimer correctement certains paramètres (estimation aux bornes pour une probabilité, ou variance nulle). Dans ces situations, un prior bien choisi peut aider à stabiliser l’inférence, en apportant une information complémentaire.Pour encadrer les modèles complexes : dans les modèles mixtes, ou en présence de paramètres difficilement estimables, les priors permettent de borner l’espace des solutions à des valeurs plausibles et d’éviter des estimations aberrantes. Par exemple, dans un modèle mixte (voir Chapitre 6) où l’estime la variance entre groupes ou modalités d’un effet, l’absence de prior peut entraîner des valeurs irréalistes ou des instabilités numériques. Un prior faiblement informatif peut aider dans cette situation.Pour encadrer les modèles complexes : dans les modèles mixtes, ou en présence de paramètres difficilement estimables, les priors permettent de borner l’espace des solutions à des valeurs plausibles et d’éviter des estimations aberrantes. Par exemple, dans un modèle mixte (voir Chapitre 6) où l’estime la variance entre groupes ou modalités d’un effet, l’absence de prior peut entraîner des valeurs irréalistes ou des instabilités numériques. Un prior faiblement informatif peut aider dans cette situation.Pour prévenir le sur-ajustement : dans les modèles comportant de nombreuses variables explicatives, les priors jouent un rôle de régularisation en pénalisant les effets peu importants. Par exemple, dans une régression incluant de nombreuses covariables, un prior du type \\(N(0,1.5^2)\\) empêche le modèle d’attribuer des effets trop forts à des variables peu informatives, réduisant ainsi le risque de sur-ajustement.Pour prévenir le sur-ajustement : dans les modèles comportant de nombreuses variables explicatives, les priors jouent un rôle de régularisation en pénalisant les effets peu importants. Par exemple, dans une régression incluant de nombreuses covariables, un prior du type \\(N(0,1.5^2)\\) empêche le modèle d’attribuer des effets trop forts à des variables peu informatives, réduisant ainsi le risque de sur-ajustement.Le choix d’un prior dépend directement du contexte et de la question scientifique.Un prior non-informatif vise à exprimer un manque de connaissance : il est souvent utilisé lorsqu’ne veut pas introduire d’hypothèses fortes. En pratique, cela se traduit par des distributions larges ou uniformes. Mais attention : même un prior apparemment vague peut être informatif une fois transformé sur l’échelle du modèle, comme le verra dans la Section 4.5.Un prior non-informatif vise à exprimer un manque de connaissance : il est souvent utilisé lorsqu’ne veut pas introduire d’hypothèses fortes. En pratique, cela se traduit par des distributions larges ou uniformes. Mais attention : même un prior apparemment vague peut être informatif une fois transformé sur l’échelle du modèle, comme le verra dans la Section 4.5.Un prior informatif reflète une connaissance crédible et externe au jeu de données analysé : il peut provenir d’une synthèse bibliographique, d’une expérience passée ou de l’avis d’un spécialiste. Il pour avantage de réduire l’incertitude sur les paramètres, surtout avec peu de données. verra un exemple dans la Section 4.4.Un prior informatif reflète une connaissance crédible et externe au jeu de données analysé : il peut provenir d’une synthèse bibliographique, d’une expérience passée ou de l’avis d’un spécialiste. Il pour avantage de réduire l’incertitude sur les paramètres, surtout avec peu de données. verra un exemple dans la Section 4.4.Un prior faiblement informatif (ou weakly informative) est un peu un compromis entre les priors non-informatifs et informatifs. L’idée est d’exclure des valeurs manifestement aberrantes ou incompatibles avec ce que l’sait du phénomène étudié, tout en laissant suffisamment de liberté au modèle pour apprendre des données. Ce type de prior est utilisé notamment dans brms. verra un exemple dans le Chapitre 6 qui suit.Un prior faiblement informatif (ou weakly informative) est un peu un compromis entre les priors non-informatifs et informatifs. L’idée est d’exclure des valeurs manifestement aberrantes ou incompatibles avec ce que l’sait du phénomène étudié, tout en laissant suffisamment de liberté au modèle pour apprendre des données. Ce type de prior est utilisé notamment dans brms. verra un exemple dans le Chapitre 6 qui suit.En pratique, une stratégie prudente consiste à commencer avec un prior faiblement informatif, comme une loi normale centrée avec une variance modérée, puis à tester des alternatives plus informatives (ou plus vagues) pour examiner l’impact sur les résultats posteriori. C’est l’idée de l’analyse de sensibilité qu’développe dans la Section 4.3.","code":""},{"path":"prior.html","id":"sensibilite","chapter":"Chapitre 4 Les distributions a priori","heading":"4.3 Sensibilité au prior","text":"Revenons à notre exemple fil rouge sur la survie des ragondins. Examinons comment différents choix de priors influencent la distribution posteriori de cette probabilité de survie. Dans la Figure 4.1, trois priors de plus en plus informatifs (en colonnes), et deux tailles d’échantillon (en lignes).\nFigure 4.1: Effet combiné du prior et de la taille d’échantillon sur la distribution posteriori avec une vraisemblance binomiale. En colonnes : trois lois bêta priori Beta(1,1), Beta(5,5) et Beta(20,1). En lignes : petit (n = 6, y = 2) et grand (n = 57, y = 19) échantillon (facteur 10). Le trait rouge représente le prior, le trait noir la distribution posteriori.\nAvec peu de données (ligne du haut), l’effet du prior est visible : la distribution posteriori de la survie reste proche du prior, en particulier avec la \\(\\text{Beta}(20,1)\\) qui tire l’estimation vers des valeurs élevées. Avec plus de données (ligne du bas), la distribution posteriori est dominée par la vraisemblance : elle se concentre autour de la proportion observée, à part pour le prior \\(\\text{Beta}(20,1)\\) avec lequel la distribution posteriori est centrée sur 0.5. observe ainsi un principe fondamental de l’inférence bayésienne : plus les données sont nombreuses et informatives, moins le prior influence les résultats.peut formaliser les observations faites à la Figure 4.1. Rappelez-vous que lorsque la vraisemblance est \\(\\text{Bin}(n,\\theta)\\) avec \\(y\\) succès, et que le prior est une loi \\(\\text{Beta}(,b)\\), la loi posteriori est également bêta (conjugaison), et plus exactement \\(\\text{Beta}(+y,\\;b+n-y)\\). la moyenne d’une \\(\\text{Beta}(,b)\\) est \\(\\displaystyle \\frac{}{+b}\\), et donc la moyenne de la distribution posteriori \\(\\text{Beta}(+y,\\;b+n-y)\\) est \\(\\displaystyle \\frac{+y}{+b+n}\\) qui peut se réécrire comme une moyenne pondérée entre la moyenne de la distribution priori \\(\\mu_{prior} = \\displaystyle \\frac{}{+b}\\) et la proportion observée \\(y/n\\) qui n’est autre que l’estimateur du maximum de vraisemblance \\(\\hat{\\theta}\\), avec le poids \\(w = \\displaystyle \\frac{n}{+b+n}\\). Attention, c’est un poids au sens statistique du terme, un facteur de pondération, pas au sens “kilos de ragondin”. Autrement dit la moyenne de la distribution posteriori vaut \\((1-w)\\mu_{prior} + w \\hat{\\theta}\\). Ainsi, quand l’échantillon de taille \\(n\\) est grand, \\(w\\) tend vers 1, et la moyenne posteriori se rapproche de l’estimateur du maximum de vraisemblance. À l’inverse, pour un petit échantillon ou un prior très informatif (la somme \\(+b\\) est grande, voir Figure 1.4), \\(w\\) est petit, et le prior tire l’estimation. En résumé, quand les données sont limitées, s’appuie davantage sur le prior ; quand elles sont riches, laisse parler la vraisemblance.En conclusion, c’est toujours une bonne idée de faire ce genre d’analyse de sensibilité. En comparant les résultats obtenus avec différents priors (non-informatif, peu informatif, informatif), peut s’assurer que les conclusions ne dépendent pas excessivement des choix priori. Si c’est le cas, pas de panique, ça veut simplement dire qu’peu d’informations sur le paramètre en question, et qu’il faut redoubler de prudence et bien réfléchir au prior utilisé. y reviendra dans la suite.","code":""},{"path":"prior.html","id":"informativeprior","chapter":"Chapitre 4 Les distributions a priori","heading":"4.4 Comment intégrer l’information a priori ?","text":"","code":""},{"path":"prior.html","id":"méta-analyse","chapter":"Chapitre 4 Les distributions a priori","heading":"4.4.1 Méta-analyse","text":"Repartons de notre exemple fil rouge sur l’estimation d’une probabilité de survie, mais en le complexifiant légèrement pour tenir compte d’un problème fréquent lorsqu’étudie des populations animales : la détection imparfaite des individus. En effet, selon leur comportement ou les conditions de terrain, un animal peut très bien être vivant et présent, mais ne pas être détecté au moment de l’échantillonnage. Pour corriger ce biais, utilise souvent des protocoles de capture–recapture, qui reposent sur l’identification individuelle des animaux, grâce à une bague, un motif de pelage, un profil génétique, etc.Un individu peut ainsi être détecté (1) ou pas (0), et code par exemple 101 qui signifie : vu la première année, manqué la seconde, puis revu la troisième. Dans le modèle le plus simple, suppose une probabilité de survie \\(\\theta\\) constante et une probabilité de détection \\(p\\) constante. La vraisemblance pour l’historique 101 est donc : \\(\\Pr(101)=\\theta\\,(1-p)\\,\\theta\\,p\\). Pour obtenir la vraisemblance complète, fait ce calcul pour chaque individu et suppose que tous partagent les mêmes \\(\\theta\\) et \\(p\\), et qu’ils sont indépendants.Pour changer des ragondins, intéressons-nous au Cincle plongeur (Cinclus cinclus) un oiseau étudié pendant plus de 40 ans par Gilbert Marzolin, un professeur de mathématiques passionné d’ornithologie avec qui j’ai eu la chance de travailler. Nous disposons ici de données de capture-recapture sur 7 ans (1981–1987) pour plus de 200 oiseaux.va démarrer par un prior non-informatif sur la probabilité de survie, au hasard une \\(\\text{Beta}(1,1)\\). Ce sera notre modèle . Comme prior alternatif, peut s’appuyer sur des connaissances accumulées pour des espèces similaires. Chez les passereaux, observe par exemple une relation entre la masse corporelle et la probabilité de survie : en moyenne, les oiseaux plus lourds vivent plus longtemps. Cette relation dite allométrique été quantifiée par McCarthy (2007) grâce à une régression linéaire (voir Chapitre 5), à partir des données de survie et de masse pour 27 espèces de passereaux européens. En utilisant cette régression sur les passereaux au cas particulier du cincle, et sachant que le cincle pèse en moyenne 59.8 grammes, peut prédire sa probabilité de survie annuelle. Le modèle fournit ainsi une estimation de 0.57 avec une erreur standard de 0.075. Ces valeurs nous permettent de définir un prior informatif, sous la forme d’une loi normale centrée en 0.57 et de variance \\(0.075^2\\). Ce sera notre modèle B.obtient ainsi les résultats suivants pour le cincle :Avec un jeu de données riche (7 années), l’information contenue dans la vraisemblance domine ; le prior informatif n’apporte presque aucune information, et les deux modèles produisent des résultats très proches.Imaginons maintenant qu’des données limitées. Que se passe‑t‑il si l’ne dispose que des trois premières années par exemple ? refait l’analyse, et les résultats sont maintenant :Cette fois, le prior informatif fait une vraie différence. réduit la largeur de l’intervalle de près de 50%, tout en ramenant l’estimation moyenne vers une valeur plus réaliste pour un passereau. note aussi que l’estimation postérieure du modèle B avec 3 années de données est proche de celle obtenue avec 7 années (Figure 4.2).\nFigure 4.2: Comparaison des estimations posteriori de la survie du cincle plongeur selon le type de prior et la durée de l’étude. Chaque point représente la moyenne posteriori, avec son intervalle de crédibilité à 95%. La ligne grise indique la valeur de survie issue de la méta-analyse pour les passereaux (0.57).\nCet exemple montre que les données issues de la littérature (ici une relation allométrique masse–survie obtenue via une méta-analyse) peuvent être utilisées pour construire un prior informatif pertinent, capable d’améliorer sensiblement la précision des estimations, en particulier lorsque les données sont limitées. Cette approche offre une alternative peu coûteuse à l’allongement des protocoles de terrain.","code":""},{"path":"prior.html","id":"méthode-du-moment-matching","chapter":"Chapitre 4 Les distributions a priori","heading":"4.4.2 Méthode du moment-matching","text":"Dans l’exemple du cincle, utilisé une distribution normale comme prior informatif pour un paramètre qui se trouve être une probabilité. la normale peut prendre des valeurs négatives ou plus grande que 1, ce qui n’est pas souhaitable pour une probabilité. Dans l’exemple, le prior informatif \\(N(0.57, 0.075^2)\\) est en moyenne entre 0 et 1 avec une petite variance, donc peu de chance que cela tourne mal. Vous pouvez vous en rendre compte en simulant des données avec R et la commande summary(rnorm(n = 100, mean = 0.57, sd = 0.075)). Malgré tout, ça n’est pas très satisfaisant.La bonne nouvelle c’est qu’peut construire un prior informatif plus adéquat pour une probabilité par la méthode dit du “moment-matching”. La méthode du moment-matching sert à choisir les paramètres d’une loi priori en les calant sur les moments (souvent la moyenne et la variance) qui traduisent l’information priori qu’possède (avant de voir les données).Lorsque l’information priori est disponible sous forme d’une moyenne \\(\\mu\\) et d’un écart‑type \\(\\sigma\\), peut transformer ces moments en paramètres \\(,b\\) d’une distribution bêta. Pour rappel, la moyenne et la variance d’une bêta de paramètres \\(\\) et \\(b\\) sont \\(\\mu=\\dfrac{}{+b}\\) et \\(\\sigma^2=\\dfrac{ab}{(+b)^2(+b+1)}\\). En inversant ces relations obtient : \\(=\\displaystyle \\Bigl(\\frac{1-\\mu}{\\sigma^2}-\\frac{1}{\\mu}\\Bigr)\\mu^2\\) et \\(b=\\displaystyle \\Bigl(\\frac{1}{\\mu}-1\\Bigr)\\). Dans notre exemple, \\(\\mu=0.57\\) et \\(\\sigma=0.075\\) dont peut déduire \\(= 24.3\\) et \\(b = 18.3\\) avec quelques lignes de code :peut vérifier que cette distribution bêta bien pour moyenne et écart-type les valeurs données par la méta-analyse :peut donc adopter un prior \\(\\text{Beta}(=24.3,\\,b=18.3)\\) pour tenir compte de l’information moyenne et sa variabilité obtenue par la relation allométrique survie-masse.La méthode du moment matching ne s’applique pas qu’aux probabilités. peut aussi s’en servir pour construire un prior pour un paramètre réel, par exemple l’effet de la masse des ragondins sur leur survie (voir Chapitre 5). Imaginons qu’un·e expert·e dise : « Je suis 80% sûr que le paramètre \\(\\theta\\) se trouve entre –0.15 et 0.25. ». Cette phrase définit un intervalle de crédibilité à 80 % : \\(\\Pr(\\theta \\[-0.15,0.25]) = 0.80\\). cherche un prior de type loi normale \\(\\theta \\sim N(\\mu,\\sigma^2)\\) qui reflète exactement cette information.peut commencer par la moyenne \\(\\mu\\). L’intervalle est symétrique, donc peut déduire directement que la moyenne \\(\\mu\\) du prior est le milieu de l’intervalle : \\(\\displaystyle{\\mu = \\frac{-0.15+0.25}{2}}=0.05\\).Passons à l’écart-type \\(\\sigma\\). L’expert·e affime que 80% des valeurs de \\(\\theta\\) sont comprises entre –0.15 et 0.25. pour une loi normale, cette proportion s’écrit \\(\\Pr(\\mu - z\\,\\sigma \\leq \\theta \\leq \\mu + z \\, \\sigma) = 0.80\\). Cela signifie que 80% de la masse de la distribution est contenue dans un intervalle centré sur \\(\\mu\\) et de largeur \\(2z\\sigma\\). Pour un niveau de 80%, la valeur de \\(z\\) vaut environ 1.2816 (l’obtient via qnorm(0.90) où 0.90 est le quantile supérieur \\(1−\\alpha/2 = 1-20/2\\) avec \\((1−\\alpha)\\% = 80\\%\\) et donc \\(\\alpha = 0.20\\)). Finalement, obtient \\(\\sigma = \\displaystyle \\frac{0.25-(-0.15)}{2 \\times 1.2816} \\approx 0.156\\). Voici le calcul dans R :conclut que le prior informatif voulu est une \\(N(\\mu=0.05,\\sigma=0.156)\\). peut vérifier que tout s’est bien passé :Visuellement, la Figure 4.3 représente la densité d’une loi normale avec une moyenne \\(\\mu=0.05\\) et un écart-type \\(\\sigma=0.156\\). L’intervalle en bleu clair correspond à l’intervalle crédible central à 80%, c’est-à-dire l’intervalle [−0.15; 0.25] qui contient 80% de la masse de probabilité. Les lignes pointillées grises indiquent les bornes de cet intervalle, tandis que la ligne en pointillés noirs marque la position de la moyenne. observe que, grâce à la symétrie de la loi normale, l’intervalle est centré autour de la moyenne, et que 10% de la masse est située de chaque côté en dehors de cet intervalle.\nFigure 4.3: Distribution normale avec une moyenne de 0.05 et un écart-type de 0.156. L’intervalle ombré correspond à l’intervalle de crédibilité à 80 %, entre –0.15 et 0.25.\n","code":"\n# paramètres de moyenne et d'écart-type souhaités pour la distribution bêta\nmu <- 0.57 # moyenne de la probabilité\nsigma <- 0.075 # écart-type sur cette probabilité\n# formules inverses pour obtenir les paramètres a et b d'une distribution bêta\na <- ((1 - mu) / (sigma^2) - 1 / mu) * mu^2\nb <- a * (1 / mu - 1)\n# affichage des valeurs de a et b arrondies\nc(a = round(a, 1), b = round(b, 1))\n#>    a    b \n#> 24.3 18.3\n# on génère 10000 valeurs tirées d'une loi Bêta avec les paramètres a = 24.3 et b = 18.3\nech_prior <- rbeta(n = 10000, shape1 = 24.3, shape2 = 18.3)\n# on calcule la moyenne empirique des tirages (doit approcher 0.57)\nmean(ech_prior)\n#> [1] 0.570328\n# on calcule l'écart-type empirique des tirages (doit approcher 0.075)\nsd(ech_prior)\n#> [1] 0.07613299\n# borne inférieure et supérieure données par l’expert·e\na <- -0.15\nb <-  0.25\n\n# niveau de confiance exprimé\nlevel <- 0.80\nalpha <- 1 - level\n\n# valeur z correspondant à un intervalle de crédibilité à 80 %\nz <- qnorm(1 - alpha / 2)  # ≈ 1.2816\n\n# moyenne = centre de l’intervalle\nmu <- (a + b) / 2\n\n# écart-type déduit de la largeur de l’intervalle\nsigma <- (b - a) / (2 * z)\n\nmu\n#> [1] 0.05\nsigma\n#> [1] 0.1560608\nmu    <- 0.05\nsigma <- 0.1560608\npnorm(c(-0.15, 0.25), mean = mu, sd = sigma)\n#> [1] 0.09999996 0.90000004\n#> 0.10 0.90    # Ok : 10 % à gauche, 90 % à droite → 80 % au centre"},{"path":"prior.html","id":"surprise","chapter":"Chapitre 4 Les distributions a priori","heading":"4.5 Attention aux priors dits non-informatifs","text":"En statistique bayésienne, utilise souvent des priors non-informatifs. Mais attention, les apparences peuvent être trompeuses, surtout lorsqu’travaille sur des paramètres définis sur des échelles transformées, comme le logit ou le log dans les modèles linéaires généralisés (Chapitre 6). Prenons un exemple courant où l’modélise une probabilité \\(\\theta\\) sur l’échelle logit via un paramètre \\(\\beta\\) tel que \\(\\text{logit}(\\theta) = \\beta\\).En pratique, peut utiliser les simulations pour vérifier que des priors ne réservent pas de mauvaises surprises après transformation, c’est ce qu’appelle des prior predictive checks. Ça se passe avant même d’ajuster un modèle, et pour ce faire va :simuler des valeurs depuis le prior de \\(\\beta\\) sur l’échelle logit ;appliquer la transformation réciproque du logit pour obtenir \\(\\theta\\) ;inspecter la distribution priori induite sur \\(\\theta\\) et juger si elle semble réaliste.Un premier choix est de prendre comme prior une loi normale avec une grande variance, par exemple \\(\\beta \\sim N(0, 10^2)\\). Les étapes 1 et 2 s’obtiennent via :Le problème est qu’après transformation avec la fonction réciproque du logit, la majorité des valeurs simulées, et donc la probabilité \\(\\theta\\), sont proches de 0 ou de 1 comme le voit dans la Figure 4.4 (panneau de gauche), ce qui favorise de manière implicite des valeurs extrêmes. passe d’un prior non-informatif sur l’échelle logit à un prior très informatif (sans le vouloir) sur l’échelle naturelle de la probabilité.Un autre choix consiste à prendre \\(\\beta \\sim N(0, 1.5^2)\\). Les deux premières étapes de la simulation se résument à :Ici la distribution induite sur \\(\\theta\\) est uniforme, couvrant surtout la plage de valeurs entre 0.05 et 0.95 comme peut le voir dans la Figure 4.4 (panneau de droite), ce qui reflète mieux un manque d’information sur \\(\\theta\\). Ce deuxième choix est le bon, parle de priors faiblement informatifs (ou weakly informative).\nFigure 4.4: Comparaison de deux priors obtenus sur la probabilité \\(\\theta = \\text{logit}^{-1}(\\beta)\\) après transformation par la fonction logit réciproque de \\(\\beta \\sim N(0, 10^2)\\) et \\(\\beta \\sim N(0, 1.5^2)\\).\nIl existe aussi des priors invariants, c’est-à-dire dont la forme tient compte de l’échelle du paramètre. Le prior de Jeffreys en est un exemple : il maximise l’information apportée par les données, tout en restant invariant par reparamétrisation. Par exemple, pour une probabilité \\(\\theta\\), le prior de Jeffreys est \\(\\text{Beta}(0.5, 0.5)\\). Ce prior est moins plat qu’une uniforme \\(\\text{Beta}(1, 1)\\). Il est souvent utilisé lorsqu’souhaite une approche objective, sans introduire d’information subjective. En pratique toutefois, le prior de Jeffreys est difficile à calculer, et privilégiera l’approche par simulations pour s’assurer que les paramètres transformés ont des priors raisonnables.","code":"\nlogit_prior <- rnorm(n = 1000, mean = 0, sd = 10) # simulation\nprior <- plogis(logit_prior) # transformation\nlogit_prior2 <- rnorm(n = 1000, mean = 0, sd = 1.5)\nprior2 <- plogis(logit_prior2)"},{"path":"prior.html","id":"en-résumé-3","chapter":"Chapitre 4 Les distributions a priori","heading":"4.6 En résumé","text":"Plus les données sont riches, moins le prior influence l’estimation posteriori.Plus les données sont riches, moins le prior influence l’estimation posteriori.N’hésitez pas à prendre le temps de visualiser vos priors sur l’échelle naturelle des paramètres à l’aide de simulations.N’hésitez pas à prendre le temps de visualiser vos priors sur l’échelle naturelle des paramètres à l’aide de simulations.Les méthodes de moment-matching offrent un moyen pratique de transformer, d’encoder des connaissances dans les paramètres de distributions qui peuvent servir de priors (bêta ou normale par exemple).Les méthodes de moment-matching offrent un moyen pratique de transformer, d’encoder des connaissances dans les paramètres de distributions qui peuvent servir de priors (bêta ou normale par exemple).Quand utiliser quel type de prior ?Quand utiliser quel type de prior ?","code":""},{"path":"lms.html","id":"lms","chapter":"Chapitre 5 La régression","heading":"Chapitre 5 La régression","text":"","code":""},{"path":"lms.html","id":"introduction-5","chapter":"Chapitre 5 La régression","heading":"5.1 Introduction","text":"Ce chapitre présente l’application de la statistique bayésienne à la régression linéaire. prendra un exemple qui nous permettra d’aller un peu plus loin que notre exemple fil rouge sur la survie. Ce sera l’occasion d’aborder comment et pourquoi utiliser un modèle pour simuler des données. Nous en profiterons pour illustrer la comparaison et la validation des modèles. Nous utiliserons brms (l’équivalent en NIMBLE est disponible dans la version enrichie du livre en ligne à https://oliviergimenez.github.io/statistique-bayes/lms.html) et comparerons avec l’approche fréquentiste.","code":""},{"path":"lms.html","id":"la-régression-linéaire","chapter":"Chapitre 5 La régression","heading":"5.2 La régression linéaire","text":"","code":""},{"path":"lms.html","id":"le-modèle","chapter":"Chapitre 5 La régression","heading":"5.2.1 Le modèle","text":"Pour changer un peu, je vous propose d’utiliser brms sur un exemple différent de celui de l’estimation de la survie. Attardons-nous sur la régression linéaire.Commençons par poser les bases de notre modèle linéaire. \\(n\\) mesures d’une variable réponse \\(y_i\\) avec \\(\\) qui varie de 1 à \\(n\\). Pensez par exemple à la masse (en kilogrammes) de nos ragondins dans l’exemple fil rouge. associe chaque mesure à une variable explicative \\(x_i\\), par exemple la température extérieure moyenne en hiver (en degrés Celsius) pour nos ragondins. cherche à étudier l’effet de la température sur la masse. Le plus simple est de supposer une relation linéaire entre les deux, utilise donc un modèle de régression linéaire. Le modèle comporte une ordonnée à l’origine (ou intercept) \\(\\beta_0\\), et une pente \\(\\beta_1\\) qui décrit l’effet de \\(x_i\\) sur \\(y_i\\), ou de la température sur la masse des ragondins. aussi besoin d’un paramètre pour décrire la variabilité résiduelle représentée par un paramètre de variance \\(\\sigma^2\\), qui capte la part de variation dans les \\(y_i\\) non expliquée par les \\(x_i\\). Vous avez probablement déjà rencontré ce modèle sous la forme : \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\) où les erreurs \\(\\varepsilon_i\\) sont supposées indépendantes et distribuées selon une loi normale de moyenne 0 et de variance \\(\\sigma^2\\).L’intercept \\(\\beta_0\\) nous donne la masse quand la température est de 0 degré (\\(x_i = 0\\)). Le paramètre \\(\\beta_1\\) nous renseigne sur le changement dans la variable réponse pour une augmentation d’une unité (ici 1 degré Celsius) de la variable explicative (d’où le terme “pente” pour désigner ce paramètre). En général, conseille (fortement) de centrer (soustraire la moyenne) et réduire (diviser par l’écart-type) les valeurs de la variable explicative pour des questions numériques et d’interprétation. Numérique d’abord car cela permet aux algorithmes, qu’ils soient fréquentistes ou bayésiens, de ne pas se perdre dans des recoins de l’espace du paramètre. Et d’interprétation ensuite, car interprète alors l’intercept \\(\\beta_0\\) comme la valeur de la variable réponse pour une valeur moyenne de la variable explicative.Dans cette section, plutôt que d’analyser de “vraies” données, nous allons, à partir des paramètres \\(\\beta_0\\), \\(\\beta_1\\) et \\(\\sigma\\), simuler des données artificielles, comme si elles provenaient d’un vrai processus sous-jacent.","code":""},{"path":"lms.html","id":"simuler-des-données","chapter":"Chapitre 5 La régression","heading":"5.2.2 Simuler des données","text":"Qu’est-ce que j’entends par simuler des données ? L’analyse et la simulation des données sont deux faces d’un même modèle. Dans l’analyse, utilise les données pour estimer les paramètres d’un modèle. Dans la simulation, fixe les paramètres et utilise le modèle pour générer des données. Une raison d’utiliser les simulations est que cette gymnastique va nous obliger à bien comprendre le modèle ; si je n’arrive pas à simuler des données à partir d’un modèle, c’est que je n’ai pas complètement compris comment il marchait. Il y des tas d’autres bonnes raisons pour utiliser les simulations. Comme la vérité (les paramètres et le modèle) est connue, peut vérifier que le modèle est bien codé. peut évaluer le biais et la précision des estimations de nos paramètres, évaluer les effets de ne pas respecter les hypothèses du modèle, planifier un protocole de récolte de données ou encore évaluer la puissance d’un test statistique. Bref, c’est une technique très utile à avoir dans votre boîte à outils !Revenons à notre exemple. Pour simuler des données selon le modèle de régression linéaire, commence par fixer nos paramètres : \\(\\beta_0 = 0.1\\), \\(\\beta_1 = 1\\) et \\(\\sigma^2 = 0.5\\) :Puis simule \\(n = 100\\) valeurs \\(x_i\\) de notre variable explicative selon une loi normale de moyenne 0 et d’écart-type 1, autrement dit \\(N(0,1)\\) :Enfin, simule les valeurs de la variable réponse, en ajoutant une erreur normale epsilon à la relation linéaire beta0 + beta1 * x :\nFigure 5.1: Données simulées (n = 100) selon le modèle \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\), avec \\(\\beta_0 = 0.1\\), \\(\\beta_1 = 1\\) et \\(\\sigma = 1\\). La droite rouge correspond à la droite de régression.\n","code":"\nbeta0 <- 0.1 # valeur vraie de l'intercept\nbeta1 <- 1 # valeur vraie du coefficient de x\nsigma <- 0.5 # écart-type des erreurs\nset.seed(666) # pour rendre la simulation reproductible\nn <- 100 # nombre d'observations\nx <- rnorm(n = n, mean = 0, sd = 1) # covariable x simulée selon une loi normale standard\nepsilon <- rnorm(n, mean = 0, sd = sigma) # génère les erreurs normales\ny <- beta0 + beta1 * x + epsilon # ajoute les erreurs à la relation linéaire\ndata <- data.frame(y = y, x = x)"},{"path":"lms.html","id":"lajustement-avec-brms","chapter":"Chapitre 5 La régression","heading":"5.2.3 L’ajustement avec brms","text":"Dans cette section, utilise brms pour ajuster le modèle de régression linéaire aux données qu’vient de générer. Si tout se passe bien, les paramètres estimés devraient être proches des valeurs utilisées pour générer les données. Je vais relativement vite ici puisqu’couvert les différentes étapes au Chapitre 3. La syntaxe est très proche de celle qu’utiliserait pour ajuster le modèle par maximum de vraisemblance avec la fonction lm() dans R :Jetons un coup d’oeil aux résumés numériques et aux diagnostics de convergence :Par défaut, brms utilisé 4 chaînes qui ont tourné pendant 2000 itérations chacune avec 1000 itérations utilisées comme burn-, soit au total 4000 itérations pour l’inférence posteriori. Dans les sorties, Intercept, x et sigma correspondent respectivement aux paramètres \\(\\beta_0\\), \\(\\beta_1\\) et \\(\\sigma\\) du modèle. Le \\(\\hat{R}\\) pour les 3 paramètres vaut 1, et les tailles d’échantillon efficaces sont satisfaisantes. Les intervalles de crédibilité contiennent la vraie valeur du paramètre utilisée pour simuler les données.vérifie que le mixing est bon (Figure 5.2) :\nFigure 5.2: Histogrammes des distributions posteriori (colonne de gauche) et traces (colonne de droite) des paramètres de la régression linéaire.\n","code":"\nlm.brms <- brm(y ~ x, # formule : y en fonction de x\n               data = data, # jeu de données\n               family = gaussian) # distribution normale\nsummary(lm.brms)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: y ~ x \n#>    Data: data (Number of observations: 100) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.06      0.06    -0.05     0.17 1.00     4138     3110\n#> x             1.10      0.06     0.99     1.21 1.00     3735     3192\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.57      0.04     0.49     0.66 1.00     3951     2849\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(lm.brms)"},{"path":"lms.html","id":"weakly-informative-priors","chapter":"Chapitre 5 La régression","heading":"5.2.4 Des priors faiblement informatifs","text":"Plutôt que d’utiliser les priors par défaut de brms, choisissons d’autres priors. Nous allons utiliser des priors faiblement informatifs, et plus spécifiquement une normale avec moyenne 0 et écart-type 1.5 ou \\(N(0,1.5)\\) pour les paramètres de régression \\(\\beta_0\\) et \\(\\beta_1\\). déjà parlé des priors faiblement informatifs au Chapitre 4. L’idée est proche de celle des priors vagues ou non-informatifs, dans le sens où l’s’efforce de refléter via les priors faiblement informatifs le fait qu’n’pas vraiment d’information sur les paramètres du modèle. La différence est que les priors non-informatifs peuvent induire des valeurs aberrantes comme l’vu au Chapitre 4. C’est encore le cas ici. Prenez par exemple des \\(N(0,100)\\) pour les paramètres de la relation linéaire qui lie la masse des ragondins à la température, et simulez tout un tas de valeurs dans ces priors, puis formez la relation linéaire :\nFigure 5.3: Simulation de droites de régression issues des distributions priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 100).\n\nFigure 5.4: Simulation de droites de régression issues des distributions priori. Chaque ligne correspond à un tirage des paramètres : intercept et pente ~ N(0, 1.5).\nobtient des valeurs plus raisonnables pour la masse des ragondins qui dépassent rarement 10 kilogrammes. Il y aussi un avantage numérique à utiliser des priors faiblement informatifs, ils aident les méthodes MCMC à ne pas se perdre dans l’espace de toutes les valeurs possibles pour les paramètres à estimer, et leur permettent de se focaliser sur les valeurs réalistes de ces paramètres. En faisant ça, vous avez peut-être l’impression qu’utilise les données pour construire les priors, alors qu’dit que le prior devait refléter l’information disponible avant de voir les données. C’est l’occasion de préciser un peu ce point. L’important est surtout que le prior représente l’information indépendante des données qui sont utilisées dans la vraisemblance.s’est jusqu’ici concentrés sur les paramètres de régression, l’intercept \\(\\beta_0\\) et la pente \\(\\beta_1\\). Mais qu’en est-il de l’écart-type, \\(\\sigma\\) ? Ce paramètre est tout aussi important : il reflète à quel point les observations s’écartent de la tendance moyenne décrite par la droite de régression.Une option souvent envisagée est de lui attribuer une loi uniforme, par exemple \\(\\sigma \\sim U(0, B)\\), avec une borne inférieure naturelle (0, puisque \\(\\sigma\\) est toujours positive), mais une borne supérieure \\(B\\) difficile à choisir. Quelle valeur maximale donner à un écart-type ? Dans certains cas, une valeur apparemment raisonnable peut se révéler trop large. Par exemple, si l’modélise des tailles humaines et que l’fixe \\(\\sigma \\sim U(0, 50)\\) (en cm), cela revient à supposer que 95% des tailles sont réparties sur une plage de 100 cm autour de la moyenne – ce qui est très improbable.Une alternative plus souple et plus réaliste consiste à utiliser une loi exponentielle \\(\\sigma \\sim \\exp(\\lambda)\\) où \\(\\lambda > 0\\) est un paramètre de taux. Cette loi est définie uniquement pour des valeurs positives, ce qui est cohérent avec la nature de \\(\\sigma\\), et elle favorise les petites valeurs d’écart-type tout en laissant la possibilité à \\(\\sigma\\) d’être plus grande si les données le justifient.Par défaut, prend souvent \\(\\lambda = 1\\). Avec \\(\\lambda = 1\\), la moyenne et l’écart-type de cette loi sont tous deux égaux à \\(1\\), ce qui induit une loi priori modeste mais non restrictive (Figure 5.5).\nFigure 5.5: Comparaison entre deux lois priori pour l’écart-type \\(\\sigma\\) : une loi uniforme \\(\\text{U}(0,5)\\), qui donne la même densité entre 0 et 5, et une loi exponentielle \\(\\text{Exp}(1)\\), qui favorise les petites valeurs tout en conservant une queue plus lourde.\npeut formaliser ce modèle comme suit :\n\\[\\begin{align}\ny_i &\\sim \\text{Normale}(\\mu_i, \\sigma^2) &\\text{[vraisemblance]}\\\\\n\\mu_i &= \\beta_0 + \\beta_1 \\; x_i &\\text{[relation linéaire]}\\\\\n\\beta_0, \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur les paramètres]} \\\\\n\\sigma &\\sim \\text{Exp}(1) &\\text{[prior sur les paramètres]} \\\\\n\\end{align}\\]Spécifions ces priors :Puis refaisons l’ajustement avec brms :vérifie que les résumés numériques obtenus sont proches de ceux obtenus avec les priors par défaut, et surtout des valeurs utilisées pour simuler les données :Ici, les deux modèles donnent quasiment la même chose, ce qui n’rien de surprenant car les données sont suffisamment informatives pour qu’elles “prennent le dessus sur” le prior. L’intérêt des priors faiblement informatifs ne se voit pas tant dans ce petit exemple que dans d’autres situations : ils évitent les valeurs aberrantes, stabilisent les calculs MCMC et restent utiles quand moins de données ou des modèles plus complexes.","code":"\n\n# nombre de droites à simuler\nn_lines <- 100\n\n# tirages des intercepts et pentes selon les priors\nintercepts <- rnorm(n_lines, mean = 0, sd = 100)\nslopes <- rnorm(n_lines, mean = 0, sd = 100)\n\n# création d'un data frame\nlines_df <- data.frame()\nfor (i in 1:n_lines) {\n  y_vals <- intercepts[i] + slopes[i] * x\n  temp_df <- data.frame(x = x, y = y_vals, line = as.factor(i))\n  lines_df <- rbind(lines_df, temp_df)\n}\n\n# tracé avec ggplot2\nggplot(lines_df, aes(x = x, y = y, group = line)) +\n  geom_line(alpha = 0.3) +\n  theme_minimal() +\n  labs(x = \"x\", y = \"y\")\nmyprior <- c(\n  prior(normal(0, 1.5), class = b), # prior sur le coefficient de x\n  prior(normal(0, 1.5), class = Intercept), # prior sur l'intercept\n  prior(exponential(1), class = sigma) # prior sur l'écart-type de l'erreur\n)\nlm.brms <- brm(y ~ x, \n               data = data, \n               family = gaussian, \n               prior = myprior)\nsummary(lm.brms)\n#>  Family: gaussian \n#>   Links: mu = identity; sigma = identity \n#> Formula: y ~ x \n#>    Data: data (Number of observations: 100) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     0.06      0.06    -0.06     0.18 1.00     3648     2815\n#> x             1.10      0.06     0.99     1.20 1.00     3778     2918\n#> \n#> Further Distributional Parameters:\n#>       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma     0.57      0.04     0.49     0.66 1.00     3555     2593\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"lms.html","id":"lajustement-par-maximum-de-vraisemblance","chapter":"Chapitre 5 La régression","heading":"5.2.5 L’ajustement par maximum de vraisemblance","text":"Et pour finir, peut comparer avec l’ajustement par maximum de vraisemblance qu’obtient simplement avec la commande lm(y ~ x, data = data), tout est dans la Figure 5.6 :\nFigure 5.6: Comparaison des estimations des paramètres du modèle (intercept ou ordonnée à l’origine et pente) selon les différentes méthodes (brms et lm). Les points donnent les moyennes posteriori pour brms, et l’estimation du maximum de vraisemblance pour lm. donne également les intervalles de crédibilité (pour brms) et de confiance (pour lm) à 95%. La ligne en tirets noirs indique la vraie valeur utilisée pour simuler les données.\nLes moyennes posteriori obtenues avec brms sont proches des estimations par maximum de vraisemblance pour les deux paramètres de régression. Les intervalles de crédibilité obtenus avec brms et l’intervalle de confiance obtenu par maximum de vraisemblance englobent tous les vraies valeurs des paramètres qui ont servi à simuler les données.","code":""},{"path":"lms.html","id":"lévaluation-des-modèles","chapter":"Chapitre 5 La régression","heading":"5.3 L’évaluation des modèles","text":"La qualité de l’ajustement d’un modèle aux données est essentielle pour évaluer la confiance que l’peut accorder aux estimations des paramètres. Les tests de qualité d’ajustement (ou goodness--fit en anglais) sont bien établis en statistique fréquentiste, et beaucoup d’entre eux peuvent aussi être utilisés dans des modèles bayésiens simples. C’est le cas par exemple de l’analyse des résidus.Dans le cas d’une régression linéaire, il y plusieurs hypothèses sur lesquelles repose le modèle. Ce sont les hypothèses d’indépendance, de normalité, de linéarité et d’homoscédasticité (\\(\\sigma\\) ne varie pas avec la variable explicative). peut en général évaluer les deux premières avec le contexte. Concernant les deux autres, peut visualiser l’ajustement en superposant la droite de régression estimée au nuage de points observés. Avec le package brms, cela donne la Figure 5.7 :\nFigure 5.7: Ajustement du modèle linéaire par brms. La droite bleue est la régression estimée, obtenue en fixant l’ordonnée à l’origine et la pente à leur moyenne posteriori, entourée de son intervalle de crédibilité à 95 %.\nLes méthodes bayésiennes sont souvent utilisées pour des modèles plus complexes que la régression linéaire (comme les modèles mixtes, voir Chapitre 6), pour lesquels il n’existe pas de tests de qualité d’ajustement standards “clé en main”. Dans ces situations, utilise couramment ce qu’appelle des posterior predictive checks. L’idée est de simuler de nouveaux jeux de données à partir de la distribution posteriori des paramètres du modèle, puis de les comparer aux données observées. Plus les données simulées ressemblent aux données réelles, plus cela suggère que le modèle s’ajuste bien. Cette comparaison peut se faire de manière visuelle ou à l’aide d’une Bayesian p-value qui quantifie l’écart entre données simulées et observées.Dans brms, il suffit de faire :\nFigure 5.8: Posterior predictive checks réalisés avec brms. La courbe noire correspond aux données observées, les courbes bleues aux données simulées selon le modèle.\nLa fonction pp_check() génère des graphiques de posterior predictive checks (Figure 5.8). Elle compare les données observées à des données simulées à partir du modèle ajusté. Si le modèle est bien ajusté aux données, alors devrait pouvoir l’utiliser pour générer des données qui ressemblent aux données observées. Par conséquent, si les courbes simulées recouvrent bien les observations, cela indique que le modèle capte correctement la structure des données. Dans le cas contraire, cela peut suggérer un problème de spécification du modèle, par exemple un lien ou une famille de distribution inadaptée (voir Chapitre 6).peut également calculer une Bayesian p-value qui représente la proportion de jeux de données simulés sous le modèle pour lesquels la statistique choisie (ici la moyenne) est aussi grande ou plus grande que celle observée. Une valeur proche de 0 ou de 1 peut indiquer un mauvais ajustement du modèle pour cette statistique particulière, tandis qu’une valeur proche de 0.5 suggère un bon ajustement. Avec brms, cette Bayesian p-value s’obtient comme suit :","code":"\n# extrait les valeurs tirées dans les distributions a posteriori des paramètres\npost <- as_draws_df(lm.brms)\n\n# crée une grille de x pour tracer l'intervalle de crédibilité\ngrille_x <- tibble(x = seq(min(data$x), max(data$x), length.out = 100))\n\n# pour chaque x, simule des valeurs de y à partir des échantillons\npred <- post %>%\n  select(b_Intercept, b_x) %>%\n  expand_grid(grille_x) %>%\n  mutate(y = b_Intercept + b_x * x) %>%\n  group_by(x) %>%\n  summarise(\n    mean = mean(y),\n    lower = quantile(y, 0.025),\n    upper = quantile(y, 0.975),\n    .groups = \"drop\"\n  )\n\n# extrait les moyennes a posteriori des paramètres\nintercept <- summary(lm.brms)$fixed[1,1]\nslope <- summary(lm.brms)$fixed[2,1]\n\n# tracé\nggplot(data, aes(x = x, y = y)) +\n  geom_point(alpha = 0.6) +\n  geom_ribbon(data = pred, aes(x = x, ymin = lower, ymax = upper), fill = \"blue\", alpha = 0.2, inherit.aes = FALSE) +\n  geom_line(data = pred, aes(x = x, y = mean), color = \"blue\", size = 1.2) +\n  labs(x = \"x\", y = \"y\") +\n  coord_cartesian(xlim = range(grille_x$x)) +\n  theme_minimal()\npp_check(lm.brms)\n# Extraire les simulations de y_rep\ny_rep <- posterior_predict(lm.brms)\n\n# Calculer la statistique de test sur les données simulées (moyenne ici)\nT_sim <- rowMeans(y_rep)\n\n# Calculer la statistique observée\nT_obs <- mean(lm.brms$data$y)\n\n# Calculer la Bayesian p-value\nbayes_pval <- mean(T_sim >= T_obs)\n\n# Afficher le résultat\nbayes_pval\n#> [1] 0.5"},{"path":"lms.html","id":"la-comparaison-de-modèles","chapter":"Chapitre 5 La régression","heading":"5.4 La comparaison de modèles","text":"Comme l’vu dans le Chapitre 1, la statistique bayésienne permet de comparer plusieurs hypothèses entre elles, et de savoir à quel point une hypothèse est plausible à partir des données que nous avons collectées.Il est essentiel, avant de comparer des modèles, de se demander quel est l’objectif de l’analyse : s’agit-il de mieux comprendre un phénomène (approche explicative), ou plutôt de faire des prédictions (approche prédictive) ?Une stratégie consiste à construire un modèle unique incluant les variables jugées pertinentes, puis à l’ajuster, l’examiner, le tester, et l’améliorer progressivement. Cette approche vise moins à identifier le meilleur modèle qu’à explorer différentes variantes pour mieux comprendre le système étudié.Pour évaluer la capacité prédictive d’un modèle, peut s’appuyer sur des données déjà utilisées pour l’ajustement (prédiction interne) ou, de manière plus fiable, sur de nouvelles données (prédiction externe). Cette dernière approche nécessite toutefois de diviser les données en un jeu d’apprentissage et un jeu de test. À défaut, il est possible d’estimer les performances prédictives sur les données d’apprentissage elles-mêmes à l’aide d’outils comme le WAIC ou le LOO-CV.Le WAIC (Watanabe-Akaike Information Criterion) et le LOO-CV (Leave-One-cross-validation) permettent de comparer des modèles en estimant leur capacité à prédire de nouvelles données. Ils combinent l’ajustement aux données observées avec une pénalisation de la complexité du modèle. Une valeur de WAIC ou de LOO-CV plus faible indique un meilleur modèle. Le WAIC est basé sur une approximation théorique, tandis que le LOO-CV repose sur une validation croisée. Le LOO-CV est généralement plus précis, surtout pour les modèles complexes ou les jeux de données de taille limitée, mais il est aussi plus coûteux en calcul. En pratique, lorsque les modèles sont bien spécifiés et que l’échantillon est grand, WAIC et LOO-CV donnent souvent des résultats très proches pour un même modèle.Je reviens à l’exemple de la régression linéaire. aimerait tester l’hypothèse que la variable \\(x\\) explique bien une part importante de la variation dans \\(y\\). Cela revient à comparer les modèles avec et sans cette variable.Dans brms, ajuste ces deux modèles avec des priors faiblement informatifs :La fonction waic() permet d’extraire le WAIC, où le modèle avec la plus petite valeur est préféré. Si le modèle avec \\(x\\) est bien le bon (c’est ce qu’attend puisque c’est comme ça que les données ont été simulées), devrait voir qu’il est nettement meilleur que celui sans covariable :Ouf, c’est bien le cas. La fonction loo() permet de calculer le LOO-CV (une approximation en fait) :Dans cette sortie R, elpd_diff donne l’écart de LOO-CV entre chaque modèle et celui qui la plus grande valeur. Ainsi, le meilleur modèle est sur la première ligne avec un elpd_diff égal à zéro ; ici, c’est le modèle avec la covariable. arrive donc à la même conclusion qu’avec le WAIC.","code":"# Modèle avec covariable\nfit1 <- brm(y ~ x, data = data, family = gaussian(),\n            prior = c(\n              prior(normal(0, 1.5), class = Intercept),\n              prior(normal(0, 1.5), class = b),\n              prior(exponential(1), class = sigma)\n            ))\n\n# Modèle sans covariable\nfit0 <- brm(y ~ 1, data = data, family = gaussian(),\n            prior = c(\n              prior(normal(0, 1.5), class = Intercept),\n              prior(exponential(1), class = sigma))\n# Calcul du WAIC pour chaque modèle\nwaic1 <- waic(fit1)\nwaic0 <- waic(fit0)\n\n# Comparaison\nwaic1$estimates['waic',]\n#>  Estimate        SE \n#> 172.43145  13.14333\nwaic0$estimates['waic',]\n#>  Estimate        SE \n#> 334.03145  17.13167\n# Leave-one-out cross-validation\nloo1 <- loo(fit1)\nloo0 <- loo(fit0)\n\n# Comparaison\nloo_compare(loo0, loo1)\n#>      elpd_diff se_diff\n#> fit1   0.0       0.0  \n#> fit0 -80.8       9.1"},{"path":"lms.html","id":"en-résumé-4","chapter":"Chapitre 5 La régression","heading":"5.5 En résumé","text":"La régression linéaire permet de modéliser la relation entre une variable réponse continue et une ou plusieurs variables explicatives, en tenant compte d’une variabilité résiduelle.La régression linéaire permet de modéliser la relation entre une variable réponse continue et une ou plusieurs variables explicatives, en tenant compte d’une variabilité résiduelle.Simuler des données à partir d’un modèle est un excellent moyen de comprendre son fonctionnement et de tester son code.Simuler des données à partir d’un modèle est un excellent moyen de comprendre son fonctionnement et de tester son code.Les lois priori faiblement informatives (comme \\(N(0, 1.5)\\) pour les coefficients ou \\(\\text{Exp}(1)\\) pour \\(\\sigma\\)) aident à encadrer les valeurs réalistes tout en laissant au modèle la liberté d’apprendre des données.Les lois priori faiblement informatives (comme \\(N(0, 1.5)\\) pour les coefficients ou \\(\\text{Exp}(1)\\) pour \\(\\sigma\\)) aident à encadrer les valeurs réalistes tout en laissant au modèle la liberté d’apprendre des données.La validation et la comparaison des modèles peuvent se faire à l’aide de posterior predictive checks et de critères comme le WAIC. Ces outils permettent d’évaluer la qualité du modèle au regard des données, et d’arbitrer entre plusieurs modèles concurrents.La validation et la comparaison des modèles peuvent se faire à l’aide de posterior predictive checks et de critères comme le WAIC. Ces outils permettent d’évaluer la qualité du modèle au regard des données, et d’arbitrer entre plusieurs modèles concurrents.","code":""},{"path":"glms.html","id":"glms","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","text":"","code":""},{"path":"glms.html","id":"introduction-6","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.1 Introduction","text":"Ce chapitre présente l’application de la statistique bayésienne à des extensions du modèle linéaire vu au chapitre précédent, les modèles linéaires généralisés (GLM) et les modèles linéaires généralisés mixtes (GLMM). commencera par un GLM qui nous permettra de revisiter notre exemple fil rouge sur la survie des ragondins et les données binaires. Nous utiliserons ensuite un GLMM pour analyser des données de comptage. Nous utiliserons brms et comparerons avec l’approche fréquentiste (pour NIMBLE, rendez-vous en ligne à https://oliviergimenez.github.io/statistique-bayes/index.html).","code":""},{"path":"glms.html","id":"modèles-linéaires-généralisés-glm","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.2 Modèles linéaires généralisés (GLM)","text":"Dans le Chapitre 5, introduit la régression linéaire \\(y_i \\sim N(\\mu_i,\\sigma^2)\\) avec \\(\\mu_i = \\beta_0 + \\beta_1 x_i\\) où modélise la moyenne \\(\\mu\\) de la variable réponse \\(y\\) en fonction d’une variable explicative \\(x\\). Ce modèle dit linéaire est bien adapté à une variable réponse continue. Mais que se passe-t-il lorsque la variable réponse est discrète ? Revenons à notre exemple sur le ragondin dans lequel étudie le nombre d’animaux qui survivent. Si l’applique la régression linéaire sur ces données, va obtenir un nombre décimal de ragondins, ce qui est un peu embêtant pour un effectif par définition discret. De plus, si l’introduit une variable explicative \\(x_i\\) comme la masse pour expliquer les variations dans le nombre de ragondins qui survivent, peut se retrouver avec une probabilité de survie négative, ou plus grande que un. Pourquoi ? Et bien car rien n’oblige le modèle linéaire à ne considérer que des valeurs positives et plus petites que un.vu au Chapitre 1 la solution. note \\(z_i = 1\\) quand le ragondin \\(\\) survécu, et \\(z_i = 0\\) sinon, et suppose que l’événement de survie est comme une expérience de pile ou face avec une probabilité \\(\\theta\\), autrement dit chaque \\(z_i\\) suit une Bernoulli de paramètre \\(\\theta\\). Si l’suppose que les individus sont indépendants et la même distribution, alors le nombre total de ragondins qui survivent à l’hiver \\(\\displaystyle\\sum_{=1}^n{z_i} = y\\) suit une binomiale \\(y \\sim \\text{Bin}(n, \\theta)\\) avec \\(\\theta\\) la probabilité de survie.aussi vu aux Chapitres 2 et 3 qu’pouvait utiliser la fonction logit pour forcer un paramètre à être bien estimé entre 0 et 1. Il s’agit d’écrire que \\(\\text{logit}(\\theta_i) = \\beta_0 + \\beta_1 x_i\\), comme expliqué dans la Figure 6.1.\nFigure 6.1: À gauche : la fonction logit transforme une probabilité p en une valeur continue non bornée logit(p) qui vit entre moins l’infini et plus l’infini. À droite : la fonction logit inverse transforme une combinaison linéaire de prédicteurs (valeur linéaire sur la figure) en probabilité qui vit entre 0 et 1. La fonction logit est utilisée dans la régression logistique (GLM avec distribution binomiale) pour transformer une probabilité (entre 0 et 1) en une variable continue définie sur l’ensemble des réels. Puis, la fonction logit inverse permet ensuite de revenir à l’échelle des probabilités.\nPour formaliser un peu, :\n\\[\\begin{align}\nz_i &\\sim \\text{Bernoulli}(\\theta_i) &\\text{[vraisemblance]}\\\\\n\\text{logit}(\\theta_i) &= \\beta_0 + \\beta_1 \\; x_i &\\text{[relation linéaire]}\\\\\n\\theta_i &= \\text{logit}^{-1}(\\beta_0 + \\beta_1 \\; x_i) = \\dfrac {e^{\\beta_0 + \\beta_1 \\; x_i}} {1+e^{\\beta_0 + \\beta_1 \\; x_i}} &\\text{[relation transformée]}\\\\\n  \\beta_0, \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur les paramètres]} \\\\\n\\end{align}\\]Pour illustrer tout ça, peut reprendre les données ragondins auxquelles ajoute des données de masse des individus, et pour ce faire, recrée les données brutes, c’est-à-dire les \\(z_i\\) :peut maintenant ajuster les deux modèles avec brms par exemple (obtiendrait la même chose avec NIMBLE), la régression linéaire et la régression logistique :Au passage, l’interprétation des coefficients de la régression logistique n’est pas facile. introduit souvent la notion de rapport des chances pour y aider, mais personnellement, ça ne parle pas plus que ça. Je reviens toujours à une représentation graphique de la relation entre la probabilité de succès (la survie ici) et les variables explicatives (la masse ici), comme dans la Figure 6.3. observe ici une tendance positive, mais elle est due uniquement au hasard de la simulation (puisque les données ont été générées sans effet de la masse). Une autre façon intuitive de s’en sortir est d’utiliser la règle du 4 proposée par Andrew Gelman et ses collègues. L’astuce consiste à diviser la pente de la régression logistique par 4. Cela donne une estimation approximative du changement de probabilité attendu pour une variation d’une unité de la variable explicative, au point où la courbe est la plus pentue. Si la pente est estimée à 0.23 par exemple, alors la pente maximale de la courbe logistique (autour du point d’inflexion, là où elle change de forme) est approximativement de 0.23/4 = 0.06. Cela signifie qu’une augmentation d’une unité de la variable explicative (ici, la masse du ragondin augmente de 1kg) augmente la probabilité de survie d’environ 6% au point où la pente est la plus forte (passe d’une probabilité de survie de 0.5 à 0.53), comme illustré dans la Figure 6.2 :\nFigure 6.2: Illustration de la règle du 4 de Gelman. Ici, approxime l’effet de la masse du ragondin sur la probabilité de survie (la courbe logistique en noir) autour du point d’inflexion par une droite dont la pente est donnée par le coefficient estimé divisé par 4 (la droite en tirets rouge).\nMais je m’égare, revenons au problème de la régression linéaire appliquée à des données binaires. Comme peut le voir dans la Figure 6.3, la régression linéaire consiste à faire passer une droite sans borne dans les données binaires, ce qui peut conduire à des survies plus grandes que 1 (et/ou plus petites que 0 même si ça n’est pas le cas ici). La régression logistique, en revanche, contraint naturellement les prédictions entre 0 et 1 grâce à la transformation logit, ce qui en fait un choix adapté aux variables de type succès/échec. Au passage, j’ai utilisé la formulation Bernoulli pour introduire une variable explicative mesurée à l’échelle de l’individu, mais si ça n’est pas nécessaire, peut repasser à la formulation groupée avec la binomiale comme dans les chapitres précédents.\nFigure 6.3: Comparaison entre une régression linéaire et une régression logistique ajustées sur des données binaires. La régression linéaire (en bleu) produit des prédictions plus grandes que 1 (embêtant pour une probabilité de survie), tandis que la régression logistique (en rouge) garantit une estimation de probabilité valide.\n","code":"\n# Nombre total de ragondins suivis, survivants\nn <- 57\ny <- 19\n\n# Créer les données individuelles (0 = mort, 1 = vivant)\nz <- c(rep(1, y), rep(0, n - y))\n\n# Ajouter une covariable continue (ex : masse)\nset.seed(123)\nmasse <- rnorm(n, mean = 5, sd = 1)  # masse simulée en kg\n\ndf_bern <- data.frame(survie = z, masse = masse)\n# Ajustement de la régression linéaire\nfit_lm <- brm(survie ~ masse, \n              data = df_bern, \n              family = gaussian())\n\n# Ajustement de la régression logistique\nfit_logit <- brm(survie ~ masse, \n                 data = df_bern, \n                 family = bernoulli())"},{"path":"glms.html","id":"modèles-linéaires-généralisés-mixtes-glmm","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3 Modèles linéaires généralisés mixtes (GLMM)","text":"","code":""},{"path":"glms.html","id":"introduction-7","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.1 Introduction","text":"Souvent, les données sont récoltées ou mesurées avec une certaine structure, elles sont hiérarchisées ou groupées, par exemple la relation entre la survie de ragondins et leur masse dans différentes populations de différents bassins versants. Il est alors pertinent de modéliser cette structure dans les données. Cela permet de mieux expliquer la variabilité dans la survie moyenne qui n’est pas expliquée par la masse, et donc d’obtenir de meilleures estimations. Pour ce faire, introduit les modèles linéaires généralisés mixtes (GLMM) qui combinent des effets fixes comme dans les GLM, représentant l’effet moyen d’une variable explicative (la masse dans l’exemple des ragondins), et des effets aléatoires représentant la variabilité entre groupes ou niveaux hiérarchiques.Qu’est-ce qu’un effet aléatoire ? Un effet est aléatoire lorsqu’il représente une sélection aléatoire d’unités dans une population plus vaste, par exemple des sites d’échantillonnage ou des individus ; si l’devait refaire l’expérience, peu importe les sites ou les individus, l’important est de pouvoir généraliser l’interprétation des effets. En ce sens, le sexe des ragondins par exemple ne peut pas être considéré comme un effet aléatoire ; si refait l’expérience, la variable sexe toujours les deux mêmes modalités mâle et femelle. Ou encore, considérer les sites d’une aire d’étude de nos ragondins comme un effet fixe permet seulement de dire des choses sur ces sites précis, sans possibilité de généraliser à la « population » de sites, ou l’aire d’étude.Au passage, vous verrez utiliser les termes modèles hiérarchiques, multi-niveaux ou à effets aléatoires pour GLMM. Parfois il s’agit de la même chose, parfois il s’agit de GLMM un peu modifiés. Pour éviter les confusions, souvenez-vous que les GLMM sont utilisés pour analyser des données qui viennent avec une structure en groupes.","code":""},{"path":"glms.html","id":"exemple","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.2 Exemple","text":"Pour illustrer concrètement un GLMM, imaginez la situation où l’cherche à estimer l’abondance de ragondins dans le bassin versant du Lez, à Montpellier, où le Lez est un fleuve qui traverse la ville. répartit dix transects sur la zone d’étude. Sur chaque transect, compte le nombre de ragondins présents à 10 points espacés régulièrement. s’intéresse à la réponse du nombre de ragondins (comptages) en fonction de la température. Les mesures sont bien hiérarchisées, fait 1 mesure du nombre de ragondins sur chacun des 10 points que contient chacun des 10 transects. Le protocole est illustré dans la Figure 6.4 et s’inspire du livre de mon collègue Jason Matthiopoulos (Matthiopoulos 2011).\nFigure 6.4: Schéma des données sur les ragondins selon un protocole d’échantillonnage avec 10 points dans 10 transects. L’aire d’étude est en noir. En haut le nombre de ragondins, et en bas la température.\npartir de ce protocole, simulons des données avec le script suivant. va corser le tout en supposant que sur nos 10 transects, eu des soucis d’échantillonnage sur 3 d’entre eux pour lesquels n’pu faire que 2 ou 3 points :\nFigure 6.5: Relation entre le nombre de ragondins et la température par transect, avec plusieurs points de comptage (10 pour tous, sauf les transects 4, 5 et 8 pour lesquels 3, 2 et 3 points) par transect.\n","code":"\nset.seed(123) # pour la reproductibilité\ntransects <- 10 # nombre total de transects\nnb_points <- c(10, 10, 10, 3, 2, 10, 10, 3, 10, 10) # nombre de points par transect\ndata <- NULL # objet qui stockera les données simulées\nfor (tr in 1:transects){\n  ref <- rnorm(1, 0, .3) # effet aléatoire du transect (N(0,0.3²))\n  # température simulée le long du transect :\n  # point de départ aléatoire entre 18 et 22 °C puis légère pente par segment\n  t <- runif(1, 18, 22) + runif(1, -0.2, 0.2) * 1:10\n  # intensité attendue (échelle log) : relation linéaire avec la température\n  ans <- exp(ref + 0.2 * t)\n  # comptage Poisson de ragondins pour chaque point\n  an <- rpois(nb_points[tr], ans)\n  # empile les 10 points du transect courant\n  data <- rbind(data, cbind(rep(tr, nb_points[tr]), t[1:nb_points[tr]], an))\n}\n# on met tout dans un data.frame\nsim_simple <- data.frame(\n  Transect    = data[, 1],\n  Temperature = data[, 2],\n  Ragondins    = data[, 3]\n)\nhead(sim_simple)\n#>   Transect Temperature Ragondins\n#> 1        1    19.78911        54\n#> 2        1    19.94232        46\n#> 3        1    20.09553        47\n#> 4        1    20.24874        60\n#> 5        1    20.40194        53\n#> 6        1    20.55515        42"},{"path":"glms.html","id":"lapproche-glm","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.3 L’approche GLM","text":"souhaite analyser ces données. n’pas à faire à des données binaires ici comme dans le début de ce chapitre, mais des données de comptage. Pour modéliser ce type de données, utilise une distribution de Poisson avec une fonction de lien logarithmique \\(\\log(\\theta_i) = \\beta_0 + \\beta_1 \\text{temp}_{}\\) où \\(\\text{temp}_{}\\) est la température :\\[\\begin{align}\n   \\text{y}_i &\\sim \\text{Poisson(}\\theta_i) &\\text{[vraisemblance]}\\\\\n  \\text{log}(\\theta_i) &= \\beta_{0} + \\beta_1 \\; \\text{temp}_{} &\\text{[relation linéaire]} \\\\\n  \\text{}\\theta_i &= e^{\\beta_0 + \\beta_1 \\; \\text{temp}_{}} &\\text{[relation transformée]} \\\\\n  \\beta_0, \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur les paramètres]} \\\\\n\\end{align}\\]Cette distribution est relativement facile à manipuler, puisqu’entre autres, elle un seul paramètre \\(\\theta\\) qui donne le taux d’apparition de l’événement modélisé, et qu’en moyenne, le nombre attendu de ragondins ici devrait être égal à ce paramètre.Dans ce GLM avec distribution de Poisson, les coefficients \\(\\beta_0\\) et \\(\\beta_1\\) s’interprètent sur l’échelle logarithmique. Plus précisément, une variation d’une unité de température entraîne une multiplication du nombre moyen de ragondins par \\(\\exp(\\beta_1)\\). Par exemple, si \\(\\beta_1 = 0.3\\), alors une augmentation d’un degré correspond à une hausse attendue d’environ \\(35\\%\\) du nombre moyen de ragondins, puisque \\(\\exp(0.3) \\approx 1.35\\). peut aussi visualiser graphiquement la relation entre le nombre de ragondins et la température, comme dans les Figures 6.8 et 6.10 à venir.Dans un premier modèle, oublions la structure en groupes/niveaux dans les données, ici les transects. fait passer une seule droite dans le nuage de points, c’est le modèle avec “complete pooling” ou regroupement complet :Les résultats sont les suivants :\nFigure 6.6: Vérification de l’adéquation du modèle avec complete pooling ou regroupement complet. Les distributions simulées (en bleu) sont comparées aux données observées (en noir). Le mauvais recouvrement indique une mauvaise adéquation du modèle aux données.\nPour prendre en compte la structuration des données, peut ajuster un autre modèle dans lequel le transect est traité comme un effet fixe. Autrement dit, ajuste une droite séparée pour chaque transect, avec son propre intercept, mais la même pente :Les résultats sont les suivants :Ici j’ai indiqué à brms de considérer le transect comme une variable catégorielle, un facteur, c’est le .factor(Transect) dans l’appel à la fonction brm(). Par défaut, le premier niveau du facteur (ici le transect 1) est utilisé comme niveau de référence. Cela signifie que l’intercept \\(\\beta_0\\) estimé dans le modèle correspond au transect 1, et que les coefficients associés aux autres transects représentent les écarts (sur l’échelle log) par rapport à ce transect 1. Par exemple, estime \\(\\beta_0\\) à 3.9039221, c’est l’intercept pour le transect 1. estime aussi le décalage entre le transect 1 et le transect 2 à 0.0372134. Alors l’intercept pour le transect 2 est donné par 3.9411355. Ce calcul peut être répété pour chaque transect pour obtenir les intercepts spécifiques, que l’peut ensuite transformer via l’exponentielle pour retrouver le nombre moyen attendu de ragondins (sur l’échelle d’origine) pour une température moyenne (qui vaut 0 ici puisqu’standardisé la variable température) :estime bien un intercept pour chaque transect, donc 10 intercepts, et la pente, c’est-à-dire l’effet de la température, est la même pour tous les transects. Notez aussi que les valeurs obtenues Nombre ici sont des moyennes attendues issues du modèle de Poisson. Ce sont donc des valeurs continues, décimales, bien que les données observées soient des comptages entiers. C’est une caractéristique des modèles de Poisson : la variable à prédire est discrète, mais le modèle s’appuie sur une moyenne continue pour modéliser sa distribution.\nFigure 6.7: Vérification de l’adéquation du modèle avec pooling ou pas de regroupement. Les distributions simulées (en bleu) sont comparées aux données observées (en noir). Le mauvais recouvrement indique une mauvaise adéquation du modèle aux données.\nCe modèle “pooling” fait mieux que le modèle “complete pooling”, comme peut le voir dans la Figure 6.8, mais il reste insatisfaisant. L’approche “pooling” consiste à ajuster un modèle indépendant pour chaque transect, sans partager d’information entre ces groupes. Cela pose deux problèmes : d’une part, ne peut pas généraliser les résultats obtenus à d’autres transects que ceux observés ; d’autre part, ignore des informations potentiellement utiles en supposant que chaque transect n’rien à apprendre des autres. Cette stratégie devient particulièrement inefficace lorsque chaque groupe comporte peu d’observations.\nFigure 6.8: Comparaison entre les modèles complete pooling (noir) et pooling (rouge) pour prédire le nombre de ragondins en fonction de la température, par transect. Le modèle pooling ajuste une courbe indépendante pour chaque transect, tandis que le complete pooling suppose une relation commune.\n","code":"\n# on n'oublie pas de standardiser la covariable température\nsim_simple$Temp <- scale(sim_simple$Temperature)\n\n# modèle avec complete pooling \nfit_complete <- brm(Ragondins ~ Temp,\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nsummary(fit_complete)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: Ragondins ~ Temp \n#>    Data: sim_simple (Number of observations: 78) \n#>   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     4.13      0.01     4.11     4.16 1.00     5374     5177\n#> Temp          0.10      0.01     0.07     0.13 1.00     5936     5368\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n# modèle avec no pooling / pas de regroupement (effet fixe transect)\nfit_nopool <- brm(Ragondins ~ Temp + as.factor(Transect),\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nsummary(fit_nopool)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: Ragondins ~ Temp + as.factor(Transect) \n#>    Data: sim_simple (Number of observations: 78) \n#>   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Regression Coefficients:\n#>                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept               3.90      0.05     3.81     3.99 1.00     3659     4650\n#> Temp                    0.20      0.06     0.08     0.32 1.00     2684     3611\n#> as.factorTransect2      0.04      0.12    -0.21     0.28 1.00     3001     3973\n#> as.factorTransect3     -0.12      0.07    -0.26     0.03 1.00     4207     5527\n#> as.factorTransect4      0.05      0.11    -0.16     0.26 1.00     3737     4859\n#> as.factorTransect5      0.09      0.10    -0.12     0.29 1.00     5687     5484\n#> as.factorTransect6      0.49      0.10     0.29     0.68 1.00     3009     4224\n#> as.factorTransect7      0.19      0.09     0.02     0.37 1.00     3322     4124\n#> as.factorTransect8      0.08      0.09    -0.09     0.26 1.00     5512     5480\n#> as.factorTransect9      0.28      0.08     0.13     0.43 1.00     3452     4601\n#> as.factorTransect10     0.64      0.06     0.53     0.77 1.00     3729     4715\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n# extraire l'intercept (référence = Transect 1)\nbeta0 <- fixef(fit_nopool)[\"Intercept\", \"Estimate\"]\n\n# tous les coefficients du modèle\ncoefs <- fixef(fit_nopool)\n\n# effets associés aux autres transects\ncoefs_transects <- coefs[grep(\"as.factor\", rownames(coefs)), \"Estimate\"]\n\n# calcul des intercepts par transect\nintercepts_log <- c(\n  Transect1 = beta0,\n  beta0 + coefs_transects\n)\n\n# calcul des nombres moyens attendus de ragondins sur l’échelle d’origine\nnombres <- exp(intercepts_log)\n\n# le tableau qui résume\ndf_intercepts <- data.frame(\n  Transect = names(intercepts_log),\n  Intercept_log = round(intercepts_log, 2),\n  Nombre = round(nombres, 2)\n)\n\n# affichage\ndf_intercepts\n#>                                Transect Intercept_log Nombre\n#> Transect1                     Transect1          3.90  49.60\n#> as.factorTransect2   as.factorTransect2          3.94  51.48\n#> as.factorTransect3   as.factorTransect3          3.79  44.15\n#> as.factorTransect4   as.factorTransect4          3.95  51.94\n#> as.factorTransect5   as.factorTransect5          3.99  54.02\n#> as.factorTransect6   as.factorTransect6          4.39  80.75\n#> as.factorTransect7   as.factorTransect7          4.10  60.22\n#> as.factorTransect8   as.factorTransect8          3.98  53.74\n#> as.factorTransect9   as.factorTransect9          4.19  65.76\n#> as.factorTransect10 as.factorTransect10          4.55  94.53"},{"path":"glms.html","id":"lapproche-glmm","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.4 L’approche GLMM","text":"Revenons à notre objectif : évaluer l’effet de la température sur l’abondance des ragondins, tout en prenant en compte la structure hiérarchique des données (segments imbriqués dans des transects). Jusqu’ici, les modèles complete pooling et pooling représentaient deux extrêmes : soit supposait que tous les transects partageaient exactement la même relation température–abondance, soit estimait une relation totalement indépendante pour chacun d’eux (via un intercept spécifique à chaque transect). Les modèles linéaires généralisés mixtes (GLMM), ou partial pooling, permettent un compromis plus réaliste.construit un GLMM dans lequel autorise chaque transect à avoir un intercept propre - c’est-à-dire une abondance moyenne spécifique - mais suppose que ces intercepts ne sont pas totalement indépendants. les considère plutôt comme des variations aléatoires autour d’un intercept moyen \\(\\beta_0\\), issues d’une même distribution normale. Cela revient à dire que nos transects \\(\\beta_{0j}\\) (où \\(j\\) varie de 1 à 10) sont tirés d’une population plus large de transects possibles, dans laquelle l’abondance moyenne varie d’un transect à l’autre. modélise cette variabilité spatiale à l’aide d’un effet aléatoire, noté ici \\(\\beta_{0j} \\sim N(\\beta_0,\\sigma)\\), où \\(\\sigma\\) est la variation entre transects.Autrement dit, chaque intercept par transect \\(\\beta_{0j}\\) peut s’écrire comme une déviation \\(b_j\\) autour de l’intercept global \\(\\beta_{0j} = \\beta_0 + b_j\\) avec \\(b_{j} \\sim N(0,\\sigma)\\) où \\(\\beta_0\\) représente l’intercept moyen (pour un transect “typique”) et \\(\\sigma\\) quantifie la variabilité entre transects. Par exemple, si l’intercept moyen est \\(\\beta_0 = 2\\), mais que le transect 4 un intercept de \\(\\beta_{04} = 3\\), dira que cet effet spécifique \\(b_4 = 1\\) correspond à une abondance plus élevée que la moyenne.Cette modélisation hiérarchique permet de capturer l’hétérogénéité spatiale tout en partageant l’information entre groupes, ce qui est particulièrement utile lorsque certains transects comportent peu d’observations. peut aussi voir le modèle partial pooling (3 paramètres estimés dans l’exemple ragondin : \\(\\beta_0, \\beta_1, \\sigma\\)) comme un compromis entre le modèle complete pooling (2 paramètres estimés dans l’exemple ragondin : \\(\\beta_0, \\beta_1\\)) et le modèle pooling (11 paramètres estimés dans l’exemple ragondin : 10 intercept et 1 pente \\(\\beta_1\\)).Si formalise un peu ça, le GLMM correspondant s’écrit :\\[\\begin{align}\n   \\text{y}_i &\\sim \\text{Poisson(}\\theta_i) &\\text{[vraisemblance]}\\\\\n  \\text{log}(\\theta_i) &= \\beta_{0j} + \\beta_1 \\; \\text{temp}_{} &\\text{[relation linéaire]} \\\\\n  \\beta_{0j} &\\sim \\text{Normale}(\\beta_0, \\sigma) &\\text{[effet aléatoire]} \\\\\n  \\beta_0 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior sur l'intercept moyen]} \\\\\n  \\sigma &\\sim \\text{Exp}(1) &\\text{[prior pour l'erreur standard de l'effet aléatoire]} \\\\\n  \\beta_1 &\\sim \\text{Normale}(0, 1.5) &\\text{[prior pour la pente]} \\\\\n\\end{align}\\]","code":""},{"path":"glms.html","id":"ajustement-du-modèle-en-bayésien-avec-brms","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.4.1 Ajustement du modèle en bayésien avec brms","text":"ajuste d’abord le GLMM avec partial pooling avec brms :Dans la syntaxe, l’effet aléatoire sur l’intercept est spécifié avec (1 | Transect), où le 1 signifie qu’travaille sur l’intercept, et qu’il y un intercept par (c’est le |) transect. Si voulait ajouter un effet aléatoire sur la pente, écrirait (1 + Temp | Transect).Les résultats sont :Ce résumé fournit les estimations posteriori des effets fixes ainsi que des écarts-types des effets aléatoires. La ligne sd(Intercept) donne l’estimation de \\(\\sigma\\), proche du 0.3 utilisé pour simuler les données (l’intervalle de crédibilité contient la vraie valeur). Les lignes Intercept et Temp donnent les estimations de \\(\\beta_0\\) et \\(\\beta_1\\) sur l’échelle log. verra un peu plus tard comment vérifier que ces estimations sont proches des valeurs utilisées pour simuler les données.peut aussi jeter un coup d’oeil aux densités et traces des paramètres (Figure 6.9) :\nFigure 6.9: Vérification de la convergence des chaînes MCMC pour le modèle avec partial pooling.\n\nFigure 6.10: Comparaison entre les modèles complete pooling (noir), pooling (rouge) et partial pooling (bleu) pour prédire le nombre de ragondins en fonction de la température, par transect. Le modèle pooling ajuste une courbe indépendante pour chaque transect, le complete pooling suppose une relation commune, tandis que le partial pooling fournit un compromis grâce à l’effet aléatoire transect.\nvoit que l’ajustement fourni par le partial pooling est très similaire au pooling, et bien meilleur que le complete pooling. Il y une petite différence pour les transects avec peu de points d’échantillonnage, les transects 4, 5 et 8, pour lesquels le partial pooling se rapproche du complete pooling. En l’absence de plus d’information (de données) pour ces transects, il est plutôt raisonnable que les estimations se rapprochent de la moyenne donnée par le modèle avec complete pooling plutôt que vers des valeurs extrêmes, atypiques. Rappelez-vous que dans un GLMM, les niveaux de l’effet aléatoire sont caractéristiques d’une population avec une moyenne commune. C’est ce partage d’information entre les transects avec 10 points d’échantillonnage et ceux avec 2 ou 3 points, parle de “borrowing strength” qui permet d’atténuer, de tamponner, parle de “shrinkage”, la tendance à sur-ajuster du modèle avec pooling ou à effet fixe, et en ce sens parle parfois de “regularization”.\nFigure 6.11: Vérification de l’adéquation du modèle avec partial pooling ou regroupement partiel. Les distributions simulées (en bleu) sont comparées aux données observées (en noir). Le mauvais recouvrement indique une mauvaise adéquation du modèle aux données.\nLorsqu’ajuste un modèle sur une variable standardisée, comme ici la température centrée-réduite, les coefficients estimés (\\(\\beta_0, \\beta_1\\)) s’interprètent sur cette échelle modifiée : \\(\\beta_1\\) représente l’effet d’un écart-type de température, et \\(\\beta_0\\) correspond à la valeur attendue quand la température standardisée est 0, c’est-à-dire à la température moyenne. souvent envie d’exprimer les effets sur des unités compréhensibles, ici les degrés celsius, plutôt qu’en écart-type de température, qui est plus abstrait. Pour revenir à une interprétation sur l’échelle réelle (en degré celsius donc), les coefficients estimés sur la température centrée-réduite peuvent être transformés pour revenir à l’échelle réelle à l’aide des formules suivantes :\\[\n\\beta_1^{\\text{réel}} = \\frac{\\beta_1^{\\text{standardisé}}}{\\text{écart-type de la température}}\n\\]\\[\n\\beta_0^{\\text{réel}} = \\beta_0^{\\text{standardisé}} - \\beta_1^{\\text{standardisé}} \\times \\frac{\\text{moyenne de la température}}{\\text{écart-type de la température}}\n\\]Dans R, vous pouvez utiliser le code suivant :peut alors visualiser les coefficients sur l’échelle originale et comparer à la valeur utilisée pour simuler les données comme dans les Figures 6.12 et 6.13 :\nFigure 6.12: Distribution posteriori de l’intercept moyen (échelle réelle). La ligne rouge indique la vraie valeur (0).\n\nFigure 6.13: Distribution posteriori de l’effet de la température (échelle réelle). La ligne rouge indique la vraie valeur (0.2).\nretrouve les paramètres ayant servi à simuler les données (en rouge). Il ne s’agit que d’une seule simulation, c’est donc normal qu’en moyenne n’obtienne pas exactement la même chose (c’est-à-dire que le trait rouge ne coïncide pas plus à la plus grande valeur de l’histogramme), c’est seulement en répétant l’expérience de simulations un grand nombre de fois que cela se produirait.En bonus, comparons les modèles avec et sans effet de la température. Cela permet de tester la pertinence de la température comme variable explicative :calcule le WAIC pour chaque modèle, et les compare :En conclusion, le modèle incluant la température offre un meilleur ajustement aux données selon le critère WAIC. Et fort heureusement puisqu’simulé selon ce modèle !","code":"\n# modèle avec partial pooling (effet aléatoire transect)\nfit_partial <- brm(Ragondins ~ Temp + (1 | Transect), # relation nombre de ragondins vs température avec effet aléatoire transect sur l'intercept\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nsummary(fit_partial)\n#>  Family: poisson \n#>   Links: mu = log \n#> Formula: Ragondins ~ Temp + (1 | Transect) \n#>    Data: sim_simple (Number of observations: 78) \n#>   Draws: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 8000\n#> \n#> Multilevel Hyperparameters:\n#> ~Transect (Number of levels: 10) \n#>               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sd(Intercept)     0.27      0.08     0.16     0.47 1.00     2119     3183\n#> \n#> Regression Coefficients:\n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept     4.09      0.09     3.92     4.27 1.00     2087     2747\n#> Temp          0.17      0.05     0.06     0.27 1.00     3559     4119\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(fit_partial)\n# on récupère les valeurs simulées dans les distributions a posteriori des paramètres\npost <- as_draws_matrix(fit_partial)\nsbzero <- post[, \"b_Intercept\"]\nsbun <- post[, \"b_Temp\"]\n\n# on récupère moyenne et écart-type de la température\nmu <- attr(scale(sim_simple$Temperature), \"scaled:center\")\nsg <- attr(scale(sim_simple$Temperature), \"scaled:scale\")\n\n# on convertit les coefficients standardisés\nbun   <- sbun / sg # beta1 réel\nbzero <- sbzero - sbun * mu / sg # beta0 réel\ntibble(b0 = bzero) %>%\n  ggplot(aes(x = b0)) +\n  geom_histogram(color = \"white\", fill = \"skyblue\", bins = 30) +\n  geom_vline(xintercept = 0, color = \"red\", linewidth = 1.2) +\n  labs(\n    x = expression(beta[0]),\n    y = \"Fréquence\"\n  ) +\n  theme_minimal()\ntibble(b1 = bun) %>%\n  ggplot(aes(x = b1)) +\n  geom_histogram(color = \"white\", fill = \"skyblue\", bins = 30) +\n  geom_vline(xintercept = 0.2, color = \"red\", linewidth = 1.2) +\n  labs(\n    x = expression(beta[1]),\n    y = \"Fréquence\"\n  ) +\n  theme_minimal()\n# modèle avec partial pooling (effet aléatoire transect)\nfit_partial2 <- brm(Ragondins ~ 1 + (1 | Transect), # un intercept moyen, pas d'effet de la température, avec l'effet aléatoire transect\n                    data = sim_simple, # données simulées\n                    family = poisson(\"log\")) # distribution de Poisson, lien log\nwaic1 <- waic(fit_partial)\nwaic2 <- waic(fit_partial2)\ntibble(\n  Modèle = c(\"Avec température\", \"Sans température\"),\n  WAIC = c(waic1$estimates[\"waic\", \"Estimate\"],\n           waic2$estimates[\"waic\", \"Estimate\"])\n)\n#> # A tibble: 2 × 2\n#>   Modèle            WAIC\n#>   <chr>            <dbl>\n#> 1 Avec température  542.\n#> 2 Sans température  551."},{"path":"glms.html","id":"ajustement-du-modèle-en-fréquentiste-avec-lme4","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.3.4.2 Ajustement du modèle en fréquentiste avec lme4","text":"Pour clôre ce chapitre, je vous propose de faire la même analyse avec le package lme4 en fréquentiste.charge le dit package :Puis applique le GLMM, notez que la syntaxe de brms est inspirée de celle utilisée dans lme4 :Voici les résultats :Comment lire les sorties ?peut noter que les estimations des paramètres obtenus sont très proches des estimations obtenues avec brms.","code":"\nlibrary(lme4)\nfit_lme4 <- glmer(\n  Ragondins ~ Temp + (1 | Transect), # formule complète\n  data   = sim_simple,        # jeu de données simulé précédemment\n  family = poisson      # distribution adaptée à un comptage\n)\nsummary(fit_lme4)\n#> Generalized linear mixed model fit by maximum likelihood (Laplace\n#>   Approximation) [glmerMod]\n#>  Family: poisson  ( log )\n#> Formula: Ragondins ~ Temp + (1 | Transect)\n#>    Data: sim_simple\n#> \n#>       AIC       BIC    logLik -2*log(L)  df.resid \n#>     568.3     575.3    -281.1     562.3        75 \n#> \n#> Scaled residuals: \n#>     Min      1Q  Median      3Q     Max \n#> -1.9501 -0.6223 -0.1098  0.4779  2.3897 \n#> \n#> Random effects:\n#>  Groups   Name        Variance Std.Dev.\n#>  Transect (Intercept) 0.04402  0.2098  \n#> Number of obs: 78, groups:  Transect, 10\n#> \n#> Fixed effects:\n#>             Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept)  4.08804    0.06898  59.266  < 2e-16 ***\n#> Temp         0.15797    0.04863   3.248  0.00116 ** \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Correlation of Fixed Effects:\n#>      (Intr)\n#> Temp -0.106"},{"path":"glms.html","id":"en-résumé-5","chapter":"Chapitre 6 Modèles linéaires généralisés, et généralisés mixtes","heading":"6.4 En résumé","text":"Les modèles linéaires généralisés (GLM) permettent d’étendre les modèles linéaires aux situations où l’ne peut pas supposer une erreur normale.Les modèles linéaires généralisés (GLM) permettent d’étendre les modèles linéaires aux situations où l’ne peut pas supposer une erreur normale.L’idée générale est d’utiliser une distribution adaptée à la variable réponse — Bernoulli ou binomiale pour les variables binaires (0/1), Poisson pour les comptages (0, 1, 2, etc.) - et de relier la moyenne de cette distribution aux variables explicatives par une fonction de lien (comme logit ou log).L’idée générale est d’utiliser une distribution adaptée à la variable réponse — Bernoulli ou binomiale pour les variables binaires (0/1), Poisson pour les comptages (0, 1, 2, etc.) - et de relier la moyenne de cette distribution aux variables explicatives par une fonction de lien (comme logit ou log).L’introduction d’effets aléatoires permet de modéliser des groupes hiérarchiques dans les données (e.g., sites, individus, transects), en tenant compte de leur hétérogénéité tout en partageant l’information entre eux.L’introduction d’effets aléatoires permet de modéliser des groupes hiérarchiques dans les données (e.g., sites, individus, transects), en tenant compte de leur hétérogénéité tout en partageant l’information entre eux.Les modèles linéaires généralisés mixtes (GLMM) permettent d’estimer simultanément des effets fixes (valables pour toute la population), et des effets aléatoires (propres à chaque groupe, mais supposés tirés d’une distribution commune).Les modèles linéaires généralisés mixtes (GLMM) permettent d’estimer simultanément des effets fixes (valables pour toute la population), et des effets aléatoires (propres à chaque groupe, mais supposés tirés d’une distribution commune).Dans un modèle à complete pooling, ignore la structure en groupes : suppose que toutes les données suivent exactement la même relation avec les variables explicatives. Cela peut mener à des conclusions biaisées si les groupes diffèrent réellement. Dans un modèle à pooling, estime une relation distincte pour chaque groupe, sans partage d’information. Cela produit des estimations très variables, surtout si certains groupes ont des tailles d’échantillon faibles. Les modèles à partial pooling, ou GLMM, ou modèles hiérarchiques, représentent un compromis entre ces deux extrêmes : les groupes ont leurs propres paramètres, mais ceux-ci sont liés via une distribution commune. Cela permet d’améliorer la stabilité des estimations tout en respectant les différences entre groupes.Dans un modèle à complete pooling, ignore la structure en groupes : suppose que toutes les données suivent exactement la même relation avec les variables explicatives. Cela peut mener à des conclusions biaisées si les groupes diffèrent réellement. Dans un modèle à pooling, estime une relation distincte pour chaque groupe, sans partage d’information. Cela produit des estimations très variables, surtout si certains groupes ont des tailles d’échantillon faibles. Les modèles à partial pooling, ou GLMM, ou modèles hiérarchiques, représentent un compromis entre ces deux extrêmes : les groupes ont leurs propres paramètres, mais ceux-ci sont liés via une distribution commune. Cela permet d’améliorer la stabilité des estimations tout en respectant les différences entre groupes.","code":""},{"path":"conclusions.html","id":"conclusions","chapter":"Conclusions","heading":"Conclusions","text":"","code":""},{"path":"conclusions.html","id":"ce-quon-a-vu","chapter":"Conclusions","heading":"6.5 Ce qu’on a vu","text":"J’espère avec ce livre avoir démystifié (un peu) la statistique bayésienne et les méthodes MCMC. J’espère aussi vous avoir donné les clés pour comprendre la différence entre les approches fréquentiste et bayésienne, à mieux lire la section « Méthodes » des articles recourant à l’inférence bayésienne, et à acquérir une certaine autonomie dans la conduite d’analyses bayésiennes.Tout au long du livre, nous avons abordé plusieurs étapes essentielles. Nous avons commencé par explorer les motivations qui justifient le recours à l’approche bayésienne. Nous avons ensuite introduit le théorème de Bayes et discuté de son interprétation. Nous avons découvert les méthodes de Monte Carlo par chaînes de Markov (MCMC), puis manipulé brms pour ajuster des modèles complexes (et NIMBLE dans la version enrichie de ce livre, disponible en ligne à https://oliviergimenez.github.io/statistique-bayes/index.html). Une attention particulière été portée au rôle des distributions priori, qu’elles soient non informatives ou informatives, ainsi qu’à l’utilisation de ces approches dans des études de cas autour des GLM et GLMM.","code":""},{"path":"conclusions.html","id":"la-statistique-bayésienne-en-résumé","chapter":"Conclusions","heading":"6.6 La statistique bayésienne, en résumé","text":"L’approche bayésienne offre de nombreux atouts. Elle permet de quantifier l’incertitude de manière cohérente à l’aide de la probabilité, elle autorise l’intégration explicite de connaissances priori, et elle rend possible l’ajustement de modèles complexes via MCMC. De plus, les intervalles de crédibilité bayésiens sont plus intuitifs que les intervalles de confiance fréquentistes.Certaines précautions sont toutefois de mise. La vérification de la convergence des chaînes MCMC est une étape cruciale, mais parfois laborieuse. Le choix des distributions priori nécessite de prendre certaines précautions. L’adéquation du modèle aux données doit être systématiquement évaluée. Enfin, le coût computationnel n’est pas négligeable, en particulier pour les modèles les plus complexes et/ou les gros jeux de données.","code":""},{"path":"conclusions.html","id":"quelques-conseils","chapter":"Conclusions","heading":"6.7 Quelques conseils","text":"Avant de terminer, je voudrais vous laisser avec quelques conseils inspirés de ma propre expérience. Ces conseils ne sont pas forcément spécifiques à la statistique bayésienne, et ils valent ce qu’ils valent.Tout d’abord, prenez le temps de formuler clairement votre question. Cela paraît évident, mais cette étape est essentielle pour rester sur la bonne voie et faire les bons choix, par exemple celui de n’utiliser qu’un sous-ensemble des données pour répondre à une question spécifique.Ensuite, réfléchissez d’abord à votre modèle, à le formaliser soit avec des équations, soit en le dessinant, soit avec des mots. Quelle est la nature de vos données, et donc, si vous êtes dans un cadre de régression, quelle famille de distributions utiliser comme l’vu dans les Chapitres 5 (normale) et 6 (bernoulli/binomiale et Poisson). Ne vous précipitez pas sur le clavier. Vérifiez que vous le comprenez en l’expliquant par exemple à un.e collègue.ce sujet, pensez à faire des simulations. Simuler des données à partir de votre modèle permet souvent de mieux le comprendre, comme dans les Chapitres 5 et 6. C’est une excellente manière de tester vos hypothèses et de diagnostiquer d’éventuels problèmes.Choisissez l’environnement R dans lequel vous êtes à l’aise ; j’ai illustré brms (Chapitre 2) mais d’autres solutions existent (par exemple NIMBLE comme expliqué dans la version enrichie de ce livre disponible en ligne à https://oliviergimenez.github.io/statistique-bayes/).Lors de l’ajustement du modèle, commencez simple. Un modèle avec tous les paramètres constants est une bonne base. Cela permet de s’assurer que les données sont bien lues et formatées, qu’il n’y pas de données aberrantes (un zéro en trop, une virgule mal placée) ou que les priori ne génèrent pas des comportements atypiques (voir Chapitre 4). Cette approche est particulièrement importante pour la statistique bayésienne pour s’assurer des bonnes performances et de la convergence de l’algorithme MCMC (Chapitre 2), tout en se faisant une idée du temps nécessaire à faire tourner l’analyse. Une fois que tous les voyants sont au vert, ajoutez de la complexité progressivement, des effets aléatoires par exemple (Chapitre 6), jusqu’à parvenir à la structure de modèle qui vous semble la plus adaptée pour répondre à votre question. Cela sous-entend sûrement que vous devrez faire plusieurs itérations des différentes étapes d’ajustement, de comparaison et de validation de vos modèles (Chapitres 5 et 6).Pour approfondir ces aspects pratiques, je recommande la lecture des articles « Ten quick tips get started Bayesian statistics » (Gimenez et al. 2025) et « Bayesian workflow » (Andrew Gelman et al. 2020).","code":""},{"path":"conclusions.html","id":"en-conclusion","chapter":"Conclusions","heading":"6.8 En conclusion","text":"En résumé, adoptez une approche pragmatique. Le choix de l’approche statistique (fréquentiste ou bayésienne) dépend de vos objectifs, qu’il s’agisse de la rapidité, de la complexité du modèle ou du type d’incertitude que vous souhaitez quantifier. Discutez de vos options avec des collègues plus expérimenté.e.s si besoin. Le bayésien n’est pas un dogme : c’est un outil puissant parmi d’autres dans votre boîte à outils.Merci pour votre attention. N’hésitez pas à m’écrire si vous avez des questions ou si vous voudriez voir un aspect particulier développé dans une nouvelle édition de cet ouvrage. Et bonne découverte de la statistique bayésienne !","code":""},{"path":"références.html","id":"références","chapter":"Références","heading":"Références","text":"","code":""}]
