# Mise en oeuvre pratique {#logiciels}

## Introduction

Dans ce chapitre, nous découvrirons `brms` un outil très pratique pour faire de la statistique bayésienne sans trop d’efforts. Dans le version enrichie en ligne à <https://oliviergimenez.github.io/statistique-bayes/logiciels.html>, vous trouverez aussi une introduction à `NIMBLE`. Il s'agit de deux packages `R` qui implémentent pour vous les algorithmes MCMC. Concrètement, il vous suffit de spécifier une vraisemblance et des priors pour que le théorème de Bayes s'applique automatiquement. Grâce à une syntaxe proche de celle de `R`, les deux packages rendent cette étape relativement simple, même pour des modèles complexes.  

## `brms`

`brms` signifie **B**ayesian **R**egression **M**odels using **S**tan. Ce package permet de formuler et d’estimer des modèles de régression (voir la section suivante et les Chapitres \@ref(lms) et \@ref(glms)) de manière intuitive grâce à une syntaxe proche de celle du package `lme4` (la référence `R` pour les modèles mixtes), tout en s’appuyant sur `Stan`. Le package est en constant développement, rendez-vous à <https://paul-buerkner.github.io/brms/>. Vous pouvez obtenir de l'aide via <https://discourse.mc-stan.org/>. 

Pour utiliser `brms`, on commence par préparer les données :
```{r}
dat <- data.frame(y = 19, n = 57)
```

<!-- ### Estimation classique (fréquentiste) -->

<!-- ```{r} -->
<!-- mle <- glm(cbind(alive, total - alive) ~ 1, -->
<!--            family = binomial("logit"), -->
<!--            data = dat) -->
<!-- plogis(coef(mle))  # retour à l'échelle [0,1] -->
<!-- ``` -->

Sans oublier de charger `brms` :
```{r}
library(brms)
```

La vraisemblance est binomiale dans notre exemple fil rouge. Dans `brms`, on peut exprimer cela simplement :
```{r, message = FALSE, warning = FALSE, include = FALSE}
bayes.brms <- brm(y | trials(n) ~ 1,
                  family = binomial("logit"),
                  data = dat,
                  chains = 3,
                  iter = 2000,
                  warmup = 300,
                  thin = 1,
                  refresh = 0)
```

```{r, message = FALSE, warning = FALSE, eval = FALSE}
bayes.brms <- brm(
  y | trials(n) ~ 1, # le nombre de succès est fonction d'un intercept
  family = binomial("logit"), # famille binomiale avec fonction de lien logit
  data = dat, # données utilisées
  chains = 3, # nombre de chaînes MCMC
  iter = 2000, # nombre total d'itérations par chaîne
  warmup = 300, # nombre d'itérations burn-in
  thin = 1 # pas de sous-échantillonnage (chaque itération est conservée)
)
```

La syntaxe est relativement simple mais nécessite quelques explications. L'argument `y | trials(n) ~ 1` permet de spécifier un modèle dans lequel on a $y$ succès parmi $n$ essais, et on estime une ordonnée à l'origine ou intercept seulement, le `1` après `~`. Pourquoi un intercept ici? Pourquoi pas directement la survie $\theta$. Parce qu'on utilise `family = binomial("logit")` à la ligne d'après pour spécifier à `brms` que la variable réponse suit une loi binomiale. Autrement dit on a un modèle linéaire généralisé (voir le Chapitre \@ref(glms)) avec $\text{logit}(\theta) = \beta$ et on estime $\beta$ l'intercept. Les arguments `iter = 2000`, `warmup = 300` et `chains = 3` stipulent à `brms` d'utiliser 300 itérations pour l’adaptation (burn-in), et les 1700 suivantes pour l’inférence, avec 3 chaînes. 
<!-- - `seed = 666` : fixe la graine aléatoire pour assurer la reproductibilité. -->
<!-- - `prior(beta(1, 1), class = "Intercept")` : spécifie une loi bêta(1,1), équivalente à une loi uniforme sur [0,1], sur l'échelle de probabilité. -->

Jetons un coup d'oeil aux résultats : 
```{r}
summary(bayes.brms)
```

```{r include=FALSE}
library(posterior)
draws_fit <- as_draws_matrix(bayes.brms)
```

Cette commande affiche un tableau récapitulatif des estimations postérieures pour chaque paramètre du modèle. On y trouve :

- `Estimate` est la moyenne a posteriori.
- `Est.Error` est l'écart-type de cette estimation.
- `l-95% CI` et `u-95% CI` sont les bornes de l'intervalle de crédibilité à 95%.
- Le diagnostic de convergence `Rhat`.
- Et `Bulk_ESS` la taille effective d'échantillon (`Tail_ESS` est une autre mesure de la taille effective d'échantillon qu'on n'utilisera pas ici). 

La moyenne a posteriori vaut `r mean(draws_fit[,'Intercept'])` bien loin de la proportion de ragondins qui ont survécu à l'hiver ($19/57 \approx 0.33$). Comme toujours dans `R` et l'implémentation des modèles linéaires généralisés (voir Chapitre \@ref(glms)), les estimations des paramètres sont données sur l'échelle de la fonction de lien. Ici l'intercept estimé est exprimé sur l’échelle logit. Pour le convertir en probabilité de survie (entre 0 et 1), on extrait d'abord les valeurs générées dans la distribution a posteriori de l'intercept $\beta$ avec la fonction `brms::as_draws_matrix()` : 
```{r}
draws_fit <- as_draws_matrix(bayes.brms)
```

Puis on applique la fonction logistique réciproque `plogis()` sur chacune de ces valeurs pour obtenir tout un tas de valeurs simulées dans la distribution a posteriori de la survie $\theta$ :
```{r}
beta <- draws_fit[,'Intercept'] # sélectionne la colonne intercept
theta <- plogis(beta)  # conversion logit -> [0,1]
```

On obtient ainsi une estimation directe de la moyenne a posteriori de la probabilité de survie, accompagnée de son intervalle de crédibilité à 95% :
```{r}
mean(theta)
quantile(theta, probas = c(2.5,97.5)/100)
```

Ou plus directement avec la fonction `posterior::summarise_draws()` :
```{r}
summarise_draws(theta)
```

Pour visualiser la distribution a posteriori de la probabilité de survie, il suffit d'utiliser (Figure \@ref(fig:hist-surviebrms)) :
```{r hist-surviebrms, fig.cap = "Histogramme de la distribution a posteriori de la probabilité de survie (\\(\\theta\\)) sur l'échelle logit.", dpi = 600}
draws_fit %>%
  ggplot(aes(x = theta)) +
  geom_histogram(color = "white", fill = "steelblue", bins = 30) +
  labs(x = "Probabilité de survie", y = "Fréquence")
```

Dans `brms`, on peut évaluer la convergence des chaînes MCMC (Figure \@ref(fig:trace-surviebrms)) :
```{r trace-surviebrms, fig.cap = "Trace plot et densité a posteriori de la probabilité de survie (\\(\\theta\\)).", dpi = 600}
plot(bayes.brms)
```

Ce graphique affiche les trace plots (à droite) ainsi que les densités a posteriori (à gauche). 
Au passage, pour déterminer de la longueur de la période de pré-chauffage ou burn-in, il suffit de faire tourner `brms` avec `warmup = 0` pour quelques centaines ou milliers d'itérations et d'examiner la trace du paramètre pour décider du nombre d'itérations à utiliser pour atteindre la convergence.  

Un avantage majeur des méthodes MCMC est qu'elles permettent d'obtenir la distribution a posteriori de n’importe quelle fonction des paramètres en appliquant cette fonction aux valeurs tirées dans les distributions a posteriori de ces paramètres. A noter qu'ici on estime l'intercept $\beta$ et on a donc déjà utilisé cette idée pour obtenir la distribution a posteriori de la probabilité de survie en appliquant la fonction logit réciproque. Comme autre exemple, disons que j'aimerais calculer l'espérance de vie des ragondins, celle-ci étant donnée par $\lambda = -1/\log(\theta)$ :
```{r}
beta <- draws_fit[,'Intercept'] # sélectionne la colonne intercept
theta <- plogis(beta)  # conversion logit -> [0,1]
lambda <- -1 / log(theta) # transforme survie en espérance de vie
summarize_draws(lambda) # résumé des tirages : moyenne, médiane, intervalles
```

L'espérance de vie est d'un an approximativement. On peut également visualiser la distribution a posteriori de l’espérance de vie (Figure \@ref(fig:hist-life)) :
```{r hist-life, fig.cap = "Histogramme de la distribution a posteriori de l'espérance de vie.", dpi = 600}
lambda %>%
  as_tibble() %>%
  ggplot() +
  geom_histogram(aes(x = Intercept), color = "white") +
  labs(x = "Espérance de vie")
```

Il y a tout un tas de paramètres qui sont fixés par défaut dans `brms`, il est important d'en être conscient. Ca concerne les priors en particulier. Dans `brms`, les priors par défaut sont souvent non informatifs ou faiblement informatifs, mais il est toujours bon de les examiner explicitement. La commande suivante permet d’afficher le résumé des priors utilisés dans un modèle déjà ajusté :
```{r}
prior_summary(bayes.brms)
```

Le package `brms` utilise comme a priori faiblement informatif une loi de Student à 3 degrés de liberté, centrée en 0, avec un écart-type de 2.5. Les 3 degrés de liberté donnent une distribution avec des queues plus épaisses qu'une normale, permettant une certaine robustesse aux valeurs extrêmes. Le centre en 0 traduit une absence d'a priori fort sur la valeur de l’intercept. La largeur 2.5 autorise une variation raisonnablement large de l'intercept sans être complètement non-informatif.

Dans certains cas, il est pertinent de définir soi-même un prior, par exemple pour refléter des connaissances issues de la littérature ou pour contraindre d'avantage l’estimation (prior informatif). Ici, on propose un prior normal centré en 0 avec un écart-type de 1.5 sur l’intercept, on en reparlera au Chapitre \@ref(prior) :
```{r}
nlprior <- prior(normal(0, 1.5), class = "Intercept")
```

On peut ensuite l’utiliser dans la spécification du modèle :
```{r, include = FALSE}
bayes.brms <- brm(y | trials(n) ~ 1,
                  family = binomial("logit"),
                  data = dat,
                  prior = nlprior, 
                  chains = 3,
                  iter = 2000,
                  warmup = 300,
                  thin = 1,
                  refresh = 0)
```

```{r, eval = FALSE}
bayes.brms <- brm(y | trials(n) ~ 1,
                  family = binomial("logit"),
                  data = dat,
                  prior = nlprior, # nos propres priors
                  chains = 3,
                  iter = 2000,
                  warmup = 300,
                  thin = 1)
```

Vous pouvez vérifier que les résultats sont proches de ceux obtenus avec le prior par défaut :
```{r}
summary(bayes.brms)
```

## En résumé

- `brms` permet de tirer parti des méthodes MCMC sans avoir à écrire le modèle soi-même (la vraisemblance en particulier).

- Sa syntaxe est simple et proche de celle de `lme4`, ce qui le rend particulièrement adapté pour les modèles linéaires généralisés (mixtes ou pas ; voir Chapitre \@ref(glms)).

- En contrepartie, `brms` repose sur des composants préprogrammés (familles de modèles, etc.), et il est important d’être attentif aux choix faits par défaut, notamment en ce qui concerne les distributions a priori.

- Ce chapitre propose ainsi une première approche concrète de l’implémentation des modèles bayésiens, avant d’aborder des modèles plus riches, comme les modèles mixtes.
